{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2303b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Envs.pendulum import PendulumEnv\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import TimeLimit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494268cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PendulumEnv()\n",
    "env = TimeLimit(env, max_episode_steps=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fba20c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.76838493, -0.63998795,  0.81405437], dtype=float32), {})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eec815b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2024f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MBEnvs.mb_pendulum2 import MB_PendulumEnv\n",
    "env_models = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MB_env = MB_PendulumEnv(env_models, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07c32890",
   "metadata": {},
   "outputs": [],
   "source": [
    "Global_RL = PPO(\"MlpPolicy\", MB_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24c97b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_sb3 = SB3Agent(policy_net=Global_RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10c62b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_client = FRLClient(env=env,agent=agent_sb3, lr=0.0001, hidden_size= 256, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a500b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_client.sample_data(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4875b2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.322894</td>\n",
       "      <td>0.946435</td>\n",
       "      <td>-0.989896</td>\n",
       "      <td>[-1.0409824]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.302177</td>\n",
       "      <td>0.953252</td>\n",
       "      <td>-0.436217</td>\n",
       "      <td>[-0.6262884]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.310971</td>\n",
       "      <td>0.950420</td>\n",
       "      <td>0.184779</td>\n",
       "      <td>[0.17797917]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.354546</td>\n",
       "      <td>0.935039</td>\n",
       "      <td>0.924290</td>\n",
       "      <td>[0.090897225]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.429906</td>\n",
       "      <td>0.902874</td>\n",
       "      <td>1.639204</td>\n",
       "      <td>[-0.5123889]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-0.598818</td>\n",
       "      <td>-0.800885</td>\n",
       "      <td>-1.669427</td>\n",
       "      <td>[0.70794886]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.681799</td>\n",
       "      <td>-0.731539</td>\n",
       "      <td>-2.163898</td>\n",
       "      <td>[0.0085118115]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.774411</td>\n",
       "      <td>-0.632683</td>\n",
       "      <td>-2.711276</td>\n",
       "      <td>[-0.112191804]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.865383</td>\n",
       "      <td>-0.501111</td>\n",
       "      <td>-3.202617</td>\n",
       "      <td>[0.9892371]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.938209</td>\n",
       "      <td>-0.346070</td>\n",
       "      <td>-3.430064</td>\n",
       "      <td>[-0.71530473]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         actions\n",
       "0  -0.322894  0.946435 -0.989896    [-1.0409824]\n",
       "1  -0.302177  0.953252 -0.436217    [-0.6262884]\n",
       "2  -0.310971  0.950420  0.184779    [0.17797917]\n",
       "3  -0.354546  0.935039  0.924290   [0.090897225]\n",
       "4  -0.429906  0.902874  1.639204    [-0.5123889]\n",
       "..       ...       ...       ...             ...\n",
       "94 -0.598818 -0.800885 -1.669427    [0.70794886]\n",
       "95 -0.681799 -0.731539 -2.163898  [0.0085118115]\n",
       "96 -0.774411 -0.632683 -2.711276  [-0.112191804]\n",
       "97 -0.865383 -0.501111 -3.202617     [0.9892371]\n",
       "98 -0.938209 -0.346070 -3.430064   [-0.71530473]\n",
       "\n",
       "[99 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_client.dataset_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a891705a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020718</td>\n",
       "      <td>0.006817</td>\n",
       "      <td>0.553679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.008794</td>\n",
       "      <td>-0.002832</td>\n",
       "      <td>0.620996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.043576</td>\n",
       "      <td>-0.015381</td>\n",
       "      <td>0.739511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.075360</td>\n",
       "      <td>-0.032165</td>\n",
       "      <td>0.714913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.098196</td>\n",
       "      <td>-0.053693</td>\n",
       "      <td>0.600297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-0.082981</td>\n",
       "      <td>0.069346</td>\n",
       "      <td>-0.494471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.092611</td>\n",
       "      <td>0.098856</td>\n",
       "      <td>-0.547378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.090972</td>\n",
       "      <td>0.131572</td>\n",
       "      <td>-0.491341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.072826</td>\n",
       "      <td>0.155041</td>\n",
       "      <td>-0.227448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.048450</td>\n",
       "      <td>0.183265</td>\n",
       "      <td>-0.366848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.020718  0.006817  0.553679\n",
       "1  -0.008794 -0.002832  0.620996\n",
       "2  -0.043576 -0.015381  0.739511\n",
       "3  -0.075360 -0.032165  0.714913\n",
       "4  -0.098196 -0.053693  0.600297\n",
       "..       ...       ...       ...\n",
       "94 -0.082981  0.069346 -0.494471\n",
       "95 -0.092611  0.098856 -0.547378\n",
       "96 -0.090972  0.131572 -0.491341\n",
       "97 -0.072826  0.155041 -0.227448\n",
       "98 -0.048450  0.183265 -0.366848\n",
       "\n",
       "[99 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_client.dataset_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfdeb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aed97cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c69c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib import TRPO\n",
    "from Client_diff import FRLClient\n",
    "from Agent import SB3Agent\n",
    "import copy\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1f4b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29110c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc0bbb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------\n",
      "round: 0\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.09677656704870363!\n",
      "Avg loss: 0.07015586787485517!\n",
      "Avg loss: 0.04730734085353712!\n",
      "Avg loss: 0.030482896285053962!\n",
      "Avg loss: 0.018819304870751997!\n",
      "Avg loss: 0.009563239624064105!\n",
      "Avg loss: 0.005105818427400663!\n",
      "Avg loss: 0.004595879271510057!\n",
      "Avg loss: 0.0047878739884617974!\n",
      "Avg loss: 0.003952470326961096!\n",
      "Avg loss: 0.0037547514090450324!\n",
      "Avg loss: 0.0037353936982981394!\n",
      "Avg loss: 0.003291534914606018!\n",
      "Avg loss: 0.002192283471425374!\n",
      "Avg loss: 0.001625417570345841!\n",
      "Avg loss: 0.0016835247261284773!\n",
      "Avg loss: 0.001959851173908949!\n",
      "Avg loss: 0.0019289238159399247!\n",
      "Avg loss: 0.0018305774985613729!\n",
      "Avg loss: 0.0019161201479785935!\n",
      "Avg loss: 0.0020821858830822747!\n",
      "Avg loss: 0.002057912137194459!\n",
      "Avg loss: 0.001954764022533103!\n",
      "Avg loss: 0.0019344172135667274!\n",
      "Avg loss: 0.0019631054442046055!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.11701234047029478!\n",
      "Avg loss: 0.09269894062036958!\n",
      "Avg loss: 0.07138766135826397!\n",
      "Avg loss: 0.05608097755194952!\n",
      "Avg loss: 0.04469980534651161!\n",
      "Avg loss: 0.03490649288096999!\n",
      "Avg loss: 0.0278825778401612!\n",
      "Avg loss: 0.0244262618011453!\n",
      "Avg loss: 0.023703428823749467!\n",
      "Avg loss: 0.02330767451351373!\n",
      "Avg loss: 0.0229367079109943!\n",
      "Avg loss: 0.022900630093172367!\n",
      "Avg loss: 0.022975436763893718!\n",
      "Avg loss: 0.022809103828816055!\n",
      "Avg loss: 0.022694818455250544!\n",
      "Avg loss: 0.022971056420986617!\n",
      "Avg loss: 0.023191300836527564!\n",
      "Avg loss: 0.023251154287863757!\n",
      "Avg loss: 0.023349879924723305!\n",
      "Avg loss: 0.02332724172017758!\n",
      "Avg loss: 0.02324326294579805!\n",
      "Avg loss: 0.023183690063609295!\n",
      "Avg loss: 0.023087663264820247!\n",
      "Avg loss: 0.022997293763361692!\n",
      "Avg loss: 0.022949433606092196!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.08202619177444527!\n",
      "Avg loss: 0.06344543300491447!\n",
      "Avg loss: 0.0482226536651918!\n",
      "Avg loss: 0.036131866302263616!\n",
      "Avg loss: 0.02354330818585974!\n",
      "Avg loss: 0.014568085118371528!\n",
      "Avg loss: 0.008416834379883463!\n",
      "Avg loss: 0.00565669626686334!\n",
      "Avg loss: 0.004265842896566028!\n",
      "Avg loss: 0.002972080554548787!\n",
      "Avg loss: 0.0029763956877710976!\n",
      "Avg loss: 0.003002618433565658!\n",
      "Avg loss: 0.0027120084283402926!\n",
      "Avg loss: 0.002511225518634698!\n",
      "Avg loss: 0.0023995700288166216!\n",
      "Avg loss: 0.002365955874774954!\n",
      "Avg loss: 0.0022466882554484377!\n",
      "Avg loss: 0.002201587805514767!\n",
      "Avg loss: 0.0022125241595288493!\n",
      "Avg loss: 0.002149144736219265!\n",
      "Avg loss: 0.002158721074980955!\n",
      "Avg loss: 0.002174949219430952!\n",
      "Avg loss: 0.0021296515890571756!\n",
      "Avg loss: 0.0021200009317302224!\n",
      "Avg loss: 0.0021462242898511855!\n",
      "Avg loss: 0.0020926423084286702!\n",
      "Avg loss: 0.0020497945196196574!\n",
      "Avg loss: 0.0020336176461084204!\n",
      "Avg loss: 0.0020116274645465637!\n",
      "Avg loss: 0.002023544772093828!\n",
      "Avg loss: 0.0020657977005294013!\n",
      "Avg loss: 0.0020752643353929064!\n",
      "Avg loss: 0.002062184976833426!\n",
      "Avg loss: 0.0020730069569253828!\n",
      "Avg loss: 0.0020904387138944!\n",
      "Avg loss: 0.0021153945516653038!\n",
      "Avg loss: 0.002114004421861561!\n",
      "Avg loss: 0.002110798702685012!\n",
      "Avg loss: 0.0021047337224831607!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -884     |\n",
      "| time/              |          |\n",
      "|    fps             | 298      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -955     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 306      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 13       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.000849 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0086   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 1        |\n",
      "|    policy_objective       | 0.0079   |\n",
      "|    std                    | 1        |\n",
      "|    value_loss             | 6.18e+03 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.02e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 311       |\n",
      "|    iterations             | 3         |\n",
      "|    time_elapsed           | 19        |\n",
      "|    total_timesteps        | 6144      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -0.038    |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00582   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 2         |\n",
      "|    policy_objective       | 0.00542   |\n",
      "|    std                    | 0.99      |\n",
      "|    value_loss             | 6.26e+03  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -948     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 315      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 25       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.011    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00832  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 3        |\n",
      "|    policy_objective       | 0.0111   |\n",
      "|    std                    | 1.01     |\n",
      "|    value_loss             | 8.56e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -935     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 328      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 31       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.00661  |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00665  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 4        |\n",
      "|    policy_objective       | 0.00526  |\n",
      "|    std                    | 1.03     |\n",
      "|    value_loss             | 4.65e+03 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1269.0388372687623\n",
      "------------------------------\n",
      "round: 1\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.004725577053322922!\n",
      "Avg loss: 0.00390276768037135!\n",
      "Avg loss: 0.005330365389988098!\n",
      "Avg loss: 0.003245797453658573!\n",
      "Avg loss: 0.003745883344866646!\n",
      "Avg loss: 0.003608668855279878!\n",
      "Avg loss: 0.003715497708496211!\n",
      "Avg loss: 0.0031481926394917536!\n",
      "Avg loss: 0.0029722894560351657!\n",
      "Avg loss: 0.0035163732889729243!\n",
      "Avg loss: 0.0029279939812840894!\n",
      "Avg loss: 0.00274510562424742!\n",
      "Avg loss: 0.0030160449048950494!\n",
      "Avg loss: 0.002756519045166594!\n",
      "Avg loss: 0.002554343257070286!\n",
      "Avg loss: 0.0027002088238320234!\n",
      "Avg loss: 0.002662639587336647!\n",
      "Avg loss: 0.002576252302897046!\n",
      "Avg loss: 0.002665853633128184!\n",
      "Avg loss: 0.0026402792921362563!\n",
      "Avg loss: 0.0025449013676431304!\n",
      "Avg loss: 0.002675414690187002!\n",
      "Avg loss: 0.0026401259693860386!\n",
      "Avg loss: 0.0026150792295932964!\n",
      "Avg loss: 0.00258068790958229!\n",
      "Avg loss: 0.0025774249494982843!\n",
      "Avg loss: 0.0025631515744680656!\n",
      "Avg loss: 0.0026290890578638936!\n",
      "Avg loss: 0.0025732435476129465!\n",
      "Avg loss: 0.002563675037545181!\n",
      "Avg loss: 0.0025871762869064696!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.007057138069455201!\n",
      "Avg loss: 0.006493528743546146!\n",
      "Avg loss: 0.005385051123739686!\n",
      "Avg loss: 0.0044204702257290285!\n",
      "Avg loss: 0.004883254615536619!\n",
      "Avg loss: 0.004506536426439804!\n",
      "Avg loss: 0.004374459204118466!\n",
      "Avg loss: 0.004007300232260604!\n",
      "Avg loss: 0.004190988500219343!\n",
      "Avg loss: 0.0038577432168070422!\n",
      "Avg loss: 0.0038463935309482624!\n",
      "Avg loss: 0.003710112139233388!\n",
      "Avg loss: 0.003716429503874679!\n",
      "Avg loss: 0.0036457128928547413!\n",
      "Avg loss: 0.003652940945700417!\n",
      "Avg loss: 0.0036230613639175622!\n",
      "Avg loss: 0.0036120904159846153!\n",
      "Avg loss: 0.003604626806527449!\n",
      "Avg loss: 0.0036129772301198198!\n",
      "Avg loss: 0.0036586137489575776!\n",
      "Avg loss: 0.003690929862344395!\n",
      "Avg loss: 0.0036616744519960775!\n",
      "Avg loss: 0.0036246543364298607!\n",
      "Avg loss: 0.00360512691463858!\n",
      "Avg loss: 0.0036152280741331803!\n",
      "Avg loss: 0.0036227992111525966!\n",
      "Avg loss: 0.0036326777530014927!\n",
      "Avg loss: 0.0036474643979636312!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.008392256879645477!\n",
      "Avg loss: 0.005526859945506051!\n",
      "Avg loss: 0.006358900041207865!\n",
      "Avg loss: 0.004639380736759146!\n",
      "Avg loss: 0.005481995593484801!\n",
      "Avg loss: 0.004610928687531365!\n",
      "Avg loss: 0.00483932928576299!\n",
      "Avg loss: 0.004471357513443764!\n",
      "Avg loss: 0.004673390761745395!\n",
      "Avg loss: 0.004550715702980597!\n",
      "Avg loss: 0.004617303843307733!\n",
      "Avg loss: 0.00460684336598509!\n",
      "Avg loss: 0.00458560146860691!\n",
      "Avg loss: 0.0045264220272171465!\n",
      "Avg loss: 0.004489086678086096!\n",
      "Avg loss: 0.0045870522905655286!\n",
      "Avg loss: 0.0045636711214441066!\n",
      "Avg loss: 0.0045456896860938895!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1.1e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 363      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.06e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 321       |\n",
      "|    iterations             | 2         |\n",
      "|    time_elapsed           | 12        |\n",
      "|    total_timesteps        | 4096      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.0115    |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00743   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 6         |\n",
      "|    policy_objective       | 0.00604   |\n",
      "|    std                    | 1.01      |\n",
      "|    value_loss             | 7.31e+03  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -997     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 331      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 18       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.00125  |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00925  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 7        |\n",
      "|    policy_objective       | 0.00572  |\n",
      "|    std                    | 1.07     |\n",
      "|    value_loss             | 6.05e+03 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.02e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 341       |\n",
      "|    iterations             | 4         |\n",
      "|    time_elapsed           | 23        |\n",
      "|    total_timesteps        | 8192      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.00106   |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00843   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 8         |\n",
      "|    policy_objective       | 0.00588   |\n",
      "|    std                    | 1.15      |\n",
      "|    value_loss             | 6.01e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.06e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 346       |\n",
      "|    iterations             | 5         |\n",
      "|    time_elapsed           | 29        |\n",
      "|    total_timesteps        | 10240     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.00139   |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00859   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 9         |\n",
      "|    policy_objective       | 0.00776   |\n",
      "|    std                    | 1.06      |\n",
      "|    value_loss             | 6.6e+03   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1167.533584973216\n",
      "------------------------------\n",
      "round: 2\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.045638864110029924!\n",
      "Avg loss: 0.04058444035341381!\n",
      "Avg loss: 0.04200477829290321!\n",
      "Avg loss: 0.03865174622204601!\n",
      "Avg loss: 0.04239344896321806!\n",
      "Avg loss: 0.037668802958287416!\n",
      "Avg loss: 0.03777992352554672!\n",
      "Avg loss: 0.03791844716891622!\n",
      "Avg loss: 0.03790207412018693!\n",
      "Avg loss: 0.03664851506412863!\n",
      "Avg loss: 0.036394394914779395!\n",
      "Avg loss: 0.037243007976550564!\n",
      "Avg loss: 0.03637302260454211!\n",
      "Avg loss: 0.03609345805890068!\n",
      "Avg loss: 0.03647167681926173!\n",
      "Avg loss: 0.03637959940380824!\n",
      "Avg loss: 0.03592641264424552!\n",
      "Avg loss: 0.035899569028936186!\n",
      "Avg loss: 0.036101883476482424!\n",
      "Avg loss: 0.035864711240465114!\n",
      "Avg loss: 0.035996666796078595!\n",
      "Avg loss: 0.0361150896196826!\n",
      "Avg loss: 0.035883537325088734!\n",
      "Avg loss: 0.03581396050254019!\n",
      "Avg loss: 0.035823383354951756!\n",
      "Avg loss: 0.03567140844721204!\n",
      "Avg loss: 0.0356966543370072!\n",
      "Avg loss: 0.03565496567860161!\n",
      "Avg loss: 0.03556920381752813!\n",
      "Avg loss: 0.03551321445052281!\n",
      "Avg loss: 0.0354790760322112!\n",
      "Avg loss: 0.035474161513081415!\n",
      "Avg loss: 0.035511237695282034!\n",
      "Avg loss: 0.03544572709897087!\n",
      "Avg loss: 0.035423220687497786!\n",
      "Avg loss: 0.03536332873688176!\n",
      "Avg loss: 0.03525830865464134!\n",
      "Avg loss: 0.035240446108722005!\n",
      "Avg loss: 0.03526446167996861!\n",
      "Avg loss: 0.03524395878407025!\n",
      "Avg loss: 0.03522856492431856!\n",
      "Avg loss: 0.035186275128523146!\n",
      "Avg loss: 0.035055842436452926!\n",
      "Avg loss: 0.035077302668601075!\n",
      "Avg loss: 0.035027831611890485!\n",
      "Avg loss: 0.03497599090243663!\n",
      "Avg loss: 0.03500860143174274!\n",
      "Avg loss: 0.03489525913866601!\n",
      "Avg loss: 0.0349317320271454!\n",
      "Avg loss: 0.034855991803019605!\n",
      "Avg loss: 0.034864149521426954!\n",
      "Avg loss: 0.03487144247403497!\n",
      "Avg loss: 0.034796411441860374!\n",
      "Avg loss: 0.034897534216912995!\n",
      "Avg loss: 0.03475611761525064!\n",
      "Avg loss: 0.03473288798774774!\n",
      "Avg loss: 0.03466517910958677!\n",
      "Avg loss: 0.03461702817203597!\n",
      "Avg loss: 0.0346158393969957!\n",
      "Avg loss: 0.03462479326048538!\n",
      "Avg loss: 0.03458162782001485!\n",
      "Avg loss: 0.03462273038822029!\n",
      "Avg loss: 0.03444977046711908!\n",
      "Avg loss: 0.03451637578090261!\n",
      "Avg loss: 0.034479642187975515!\n",
      "Avg loss: 0.034433774839875086!\n",
      "Avg loss: 0.03435246756221507!\n",
      "Avg loss: 0.034374395965789215!\n",
      "Avg loss: 0.03437349002060425!\n",
      "Avg loss: 0.034354621236265835!\n",
      "Avg loss: 0.034294048654004046!\n",
      "Avg loss: 0.03425411769101553!\n",
      "Avg loss: 0.03426778456186791!\n",
      "Avg loss: 0.03427231278036061!\n",
      "Avg loss: 0.0341943747444581!\n",
      "Avg loss: 0.03416203310303521!\n",
      "Avg loss: 0.034108135008227694!\n",
      "Avg loss: 0.03407008744719406!\n",
      "Avg loss: 0.034121978831851724!\n",
      "Avg loss: 0.03411529603892935!\n",
      "Avg loss: 0.034116752469860026!\n",
      "Avg loss: 0.03398926756212556!\n",
      "Avg loss: 0.03403320319378205!\n",
      "Avg loss: 0.03395076167120275!\n",
      "Avg loss: 0.033915456463734964!\n",
      "Avg loss: 0.03391961261121196!\n",
      "Avg loss: 0.03390692347934419!\n",
      "Avg loss: 0.03394191543830478!\n",
      "Avg loss: 0.0339215588801494!\n",
      "Avg loss: 0.03392647375262717!\n",
      "Avg loss: 0.03372848822610952!\n",
      "Avg loss: 0.03390289428238096!\n",
      "Avg loss: 0.03381218951730564!\n",
      "Avg loss: 0.03393896976415514!\n",
      "Avg loss: 0.033675282804041064!\n",
      "Avg loss: 0.03377669525253888!\n",
      "Avg loss: 0.03359645838123773!\n",
      "Avg loss: 0.03399295413715246!\n",
      "Avg loss: 0.03369639217921001!\n",
      "Avg loss: 0.033892339822540786!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.017749776598551155!\n",
      "Avg loss: 0.01793226902387687!\n",
      "Avg loss: 0.016598430031129586!\n",
      "Avg loss: 0.01606791799605465!\n",
      "Avg loss: 0.016429055269309174!\n",
      "Avg loss: 0.01698170056272223!\n",
      "Avg loss: 0.01647262089319459!\n",
      "Avg loss: 0.016040066505448747!\n",
      "Avg loss: 0.015976490495607624!\n",
      "Avg loss: 0.016259463202707897!\n",
      "Avg loss: 0.016413007623441445!\n",
      "Avg loss: 0.01614033806505025!\n",
      "Avg loss: 0.015996030086297044!\n",
      "Avg loss: 0.016102627824226754!\n",
      "Avg loss: 0.016323351525021887!\n",
      "Avg loss: 0.01633130401638482!\n",
      "Avg loss: 0.016218593779764586!\n",
      "Avg loss: 0.016195487309617722!\n",
      "Avg loss: 0.01623394281566713!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0675245324143422!\n",
      "Avg loss: 0.06508966653959457!\n",
      "Avg loss: 0.0640016560296984!\n",
      "Avg loss: 0.062274101127428975!\n",
      "Avg loss: 0.06335811448356253!\n",
      "Avg loss: 0.06142739459042787!\n",
      "Avg loss: 0.06119229709698023!\n",
      "Avg loss: 0.06170587410617979!\n",
      "Avg loss: 0.06133091496589865!\n",
      "Avg loss: 0.06071809640042678!\n",
      "Avg loss: 0.06065959702852221!\n",
      "Avg loss: 0.060823403958881195!\n",
      "Avg loss: 0.06020183978214997!\n",
      "Avg loss: 0.060031410660909994!\n",
      "Avg loss: 0.06006651735026026!\n",
      "Avg loss: 0.05980556640384748!\n",
      "Avg loss: 0.059543822371312366!\n",
      "Avg loss: 0.059522663350580846!\n",
      "Avg loss: 0.059430124702569934!\n",
      "Avg loss: 0.05923011503693791!\n",
      "Avg loss: 0.05914079211015026!\n",
      "Avg loss: 0.05901759361270706!\n",
      "Avg loss: 0.05885255899501696!\n",
      "Avg loss: 0.058773915530761466!\n",
      "Avg loss: 0.058647999279410216!\n",
      "Avg loss: 0.05846763992996178!\n",
      "Avg loss: 0.05831999968451782!\n",
      "Avg loss: 0.05818751316704341!\n",
      "Avg loss: 0.05803645081433691!\n",
      "Avg loss: 0.05792703497483065!\n",
      "Avg loss: 0.05774323870686203!\n",
      "Avg loss: 0.05762319361348394!\n",
      "Avg loss: 0.05753892480782573!\n",
      "Avg loss: 0.05747499403588942!\n",
      "Avg loss: 0.05738038870242841!\n",
      "Avg loss: 0.05723354366659502!\n",
      "Avg loss: 0.0570123565280907!\n",
      "Avg loss: 0.05688586355227623!\n",
      "Avg loss: 0.056754180897878544!\n",
      "Avg loss: 0.05670225187222968!\n",
      "Avg loss: 0.0565914362011002!\n",
      "Avg loss: 0.056491377217438035!\n",
      "Avg loss: 0.05633640070527084!\n",
      "Avg loss: 0.056186353736447925!\n",
      "Avg loss: 0.056132730528370305!\n",
      "Avg loss: 0.056020238244618666!\n",
      "Avg loss: 0.05586791525489995!\n",
      "Avg loss: 0.05574607460142336!\n",
      "Avg loss: 0.05569986599891612!\n",
      "Avg loss: 0.05563477872464318!\n",
      "Avg loss: 0.055431016026474635!\n",
      "Avg loss: 0.05537307753267062!\n",
      "Avg loss: 0.05523999098274241!\n",
      "Avg loss: 0.055231138918519114!\n",
      "Avg loss: 0.055025403786852015!\n",
      "Avg loss: 0.05495505509900492!\n",
      "Avg loss: 0.05479484793289885!\n",
      "Avg loss: 0.0547698624921001!\n",
      "Avg loss: 0.054675232774364604!\n",
      "Avg loss: 0.05459708090462603!\n",
      "Avg loss: 0.054415930228921446!\n",
      "Avg loss: 0.05427081479528776!\n",
      "Avg loss: 0.0541900688487173!\n",
      "Avg loss: 0.05414410831319401!\n",
      "Avg loss: 0.05401690993081502!\n",
      "Avg loss: 0.05390883592613136!\n",
      "Avg loss: 0.053781761097582904!\n",
      "Avg loss: 0.05377518718593213!\n",
      "Avg loss: 0.053592492058581534!\n",
      "Avg loss: 0.05361494609028341!\n",
      "Avg loss: 0.05341660508178696!\n",
      "Avg loss: 0.05349040056069498!\n",
      "Avg loss: 0.053214220056391544!\n",
      "Avg loss: 0.05325355769314229!\n",
      "Avg loss: 0.053040793160155315!\n",
      "Avg loss: 0.05318077386239869!\n",
      "Avg loss: 0.05294837796749107!\n",
      "Avg loss: 0.053041377800764164!\n",
      "Avg loss: 0.05276896319328443!\n",
      "Avg loss: 0.05290033499114846!\n",
      "Avg loss: 0.05262386702530421!\n",
      "Avg loss: 0.05276948791245559!\n",
      "Avg loss: 0.05251414569034144!\n",
      "Avg loss: 0.05267581917032506!\n",
      "Avg loss: 0.05238803039905179!\n",
      "Avg loss: 0.05251309204786594!\n",
      "Avg loss: 0.05225819166350751!\n",
      "Avg loss: 0.052471762806890185!\n",
      "Avg loss: 0.05220643529416217!\n",
      "Avg loss: 0.05236340040926734!\n",
      "Avg loss: 0.05203423549241658!\n",
      "Avg loss: 0.05232256722769913!\n",
      "Avg loss: 0.052078445794631986!\n",
      "Avg loss: 0.052296411295756115!\n",
      "Avg loss: 0.0519302028314208!\n",
      "Avg loss: 0.052236491317938394!\n",
      "Avg loss: 0.05172061892530716!\n",
      "Avg loss: 0.051872932944485604!\n",
      "Avg loss: 0.051247236310910015!\n",
      "Avg loss: 0.05166845351089175!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.06e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 354       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 5         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -933     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 333      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 12       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.000915 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00813  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 11       |\n",
      "|    policy_objective       | 0.00713  |\n",
      "|    std                    | 1.13     |\n",
      "|    value_loss             | 5.82e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -958     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 338      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 18       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.000461 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00868  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 12       |\n",
      "|    policy_objective       | 0.00271  |\n",
      "|    std                    | 1.08     |\n",
      "|    value_loss             | 3.86e+03 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -944     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 335      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 24       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.0019   |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.009    |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 13       |\n",
      "|    policy_objective       | 0.011    |\n",
      "|    std                    | 1.15     |\n",
      "|    value_loss             | 5.16e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -974     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 332      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 30       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.00113  |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00938  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 14       |\n",
      "|    policy_objective       | 0.0117   |\n",
      "|    std                    | 1.18     |\n",
      "|    value_loss             | 4.58e+03 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1158.7312382165342\n",
      "------------------------------\n",
      "round: 3\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.003409306312884534!\n",
      "Avg loss: 0.002528925080575088!\n",
      "Avg loss: 0.011573645865816313!\n",
      "Avg loss: 0.0030754885171942682!\n",
      "Avg loss: 0.0030909851124548975!\n",
      "Avg loss: 0.002864939764931478!\n",
      "Avg loss: 0.005322177289732887!\n",
      "Avg loss: 0.001768086271968059!\n",
      "Avg loss: 0.0017608903756869646!\n",
      "Avg loss: 0.0031666519501474494!\n",
      "Avg loss: 0.0025362699476803147!\n",
      "Avg loss: 0.001754332396267273!\n",
      "Avg loss: 0.002289690732880748!\n",
      "Avg loss: 0.0026914928245241753!\n",
      "Avg loss: 0.0019301567174867765!\n",
      "Avg loss: 0.00209199778278465!\n",
      "Avg loss: 0.0025076556355876772!\n",
      "Avg loss: 0.001995045357101238!\n",
      "Avg loss: 0.00204481373963669!\n",
      "Avg loss: 0.002322211585797049!\n",
      "Avg loss: 0.0021121149401430255!\n",
      "Avg loss: 0.0021082342059647393!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.018074076006402418!\n",
      "Avg loss: 0.018109499973036992!\n",
      "Avg loss: 0.01708331717506856!\n",
      "Avg loss: 0.016495030619795823!\n",
      "Avg loss: 0.016939911712018633!\n",
      "Avg loss: 0.016255658835308773!\n",
      "Avg loss: 0.01626618952544201!\n",
      "Avg loss: 0.015954800100316788!\n",
      "Avg loss: 0.016218706668835996!\n",
      "Avg loss: 0.01599370005005767!\n",
      "Avg loss: 0.016073164886282333!\n",
      "Avg loss: 0.015955079916985446!\n",
      "Avg loss: 0.016093157935282154!\n",
      "Avg loss: 0.01598598334561454!\n",
      "Avg loss: 0.015952047512643428!\n",
      "Avg loss: 0.015929482592212024!\n",
      "Avg loss: 0.015953949216541332!\n",
      "Avg loss: 0.01585949458668286!\n",
      "Avg loss: 0.015845019480337518!\n",
      "Avg loss: 0.015881781578730547!\n",
      "Avg loss: 0.015862622963850298!\n",
      "Avg loss: 0.015832316588766843!\n",
      "Avg loss: 0.015814659575657686!\n",
      "Avg loss: 0.015825990487448205!\n",
      "Avg loss: 0.015805573998466875!\n",
      "Avg loss: 0.01580162620774312!\n",
      "Avg loss: 0.01581463205384883!\n",
      "Avg loss: 0.015801331429740155!\n",
      "Avg loss: 0.01579525723691442!\n",
      "Avg loss: 0.015797411696766517!\n",
      "Avg loss: 0.015797137054542342!\n",
      "Avg loss: 0.015794900476376293!\n",
      "Avg loss: 0.01579549211507962!\n",
      "Avg loss: 0.015791615623514114!\n",
      "Avg loss: 0.015786072456499673!\n",
      "Avg loss: 0.015786527170366754!\n",
      "Avg loss: 0.015781790905123216!\n",
      "Avg loss: 0.015787716206640046!\n",
      "Avg loss: 0.01577967390672711!\n",
      "Avg loss: 0.015774077926010554!\n",
      "Avg loss: 0.01576401729178902!\n",
      "Avg loss: 0.015776987110854557!\n",
      "Avg loss: 0.015780128361286453!\n",
      "Avg loss: 0.015775914920584454!\n",
      "Avg loss: 0.01577822662963854!\n",
      "Avg loss: 0.015787017240380313!\n",
      "Avg loss: 0.015781495382065316!\n",
      "Avg loss: 0.01577921736038358!\n",
      "Avg loss: 0.015781218423591856!\n",
      "Avg loss: 0.015791750731801432!\n",
      "Avg loss: 0.0157748472597738!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.14169879199757512!\n",
      "Avg loss: 0.1453422299364441!\n",
      "Avg loss: 0.152399819951!\n",
      "Avg loss: 0.14545797797039994!\n",
      "Avg loss: 0.14397218856262042!\n",
      "Avg loss: 0.14426864431963624!\n",
      "Avg loss: 0.14747889093327105!\n",
      "Avg loss: 0.14377901981305816!\n",
      "Avg loss: 0.1427198998212892!\n",
      "Avg loss: 0.14464554040878283!\n",
      "Avg loss: 0.1451927563348454!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -999     |\n",
      "| time/              |          |\n",
      "|    fps             | 336      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.13e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 353       |\n",
      "|    iterations             | 2         |\n",
      "|    time_elapsed           | 11        |\n",
      "|    total_timesteps        | 4096      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.00131   |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00863   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 16        |\n",
      "|    policy_objective       | 0.0124    |\n",
      "|    std                    | 1.13      |\n",
      "|    value_loss             | 4.11e+03  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -1.1e+03 |\n",
      "| time/                     |          |\n",
      "|    fps                    | 360      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.0463   |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00447  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 17       |\n",
      "|    policy_objective       | 0.00365  |\n",
      "|    std                    | 1.11     |\n",
      "|    value_loss             | 5.24e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -983     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 367      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 22       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.153    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00872  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 18       |\n",
      "|    policy_objective       | 0.00916  |\n",
      "|    std                    | 1.13     |\n",
      "|    value_loss             | 3.86e+03 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.01e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 366       |\n",
      "|    iterations             | 5         |\n",
      "|    time_elapsed           | 27        |\n",
      "|    total_timesteps        | 10240     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.484     |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00928   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 19        |\n",
      "|    policy_objective       | 0.00582   |\n",
      "|    std                    | 1.19      |\n",
      "|    value_loss             | 2.3e+03   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1228.8602546133102\n",
      "------------------------------\n",
      "round: 4\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.1643475453557524!\n",
      "Avg loss: 0.15794534383848563!\n",
      "Avg loss: 0.15469655744503447!\n",
      "Avg loss: 0.1555987290294191!\n",
      "Avg loss: 0.158597077924472!\n",
      "Avg loss: 0.15400842806317996!\n",
      "Avg loss: 0.1537402785443798!\n",
      "Avg loss: 0.1563517858541066!\n",
      "Avg loss: 0.15559829000232034!\n",
      "Avg loss: 0.15444059458745263!\n",
      "Avg loss: 0.15493907651295102!\n",
      "Avg loss: 0.15487573009279004!\n",
      "Avg loss: 0.15494545248589323!\n",
      "Avg loss: 0.15429878203591216!\n",
      "Avg loss: 0.15440125435157218!\n",
      "Avg loss: 0.15476275004134246!\n",
      "Avg loss: 0.1548610659218078!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.00885215488053897!\n",
      "Avg loss: 0.007585348767412749!\n",
      "Avg loss: 0.006480358012631768!\n",
      "Avg loss: 0.00682442158125923!\n",
      "Avg loss: 0.004519472423368522!\n",
      "Avg loss: 0.00470334163842684!\n",
      "Avg loss: 0.0040242712119652425!\n",
      "Avg loss: 0.004731065232457089!\n",
      "Avg loss: 0.003868184757405591!\n",
      "Avg loss: 0.0037149410268527087!\n",
      "Avg loss: 0.00364309368464698!\n",
      "Avg loss: 0.0037635176291890577!\n",
      "Avg loss: 0.0036421755707245515!\n",
      "Avg loss: 0.003490707463473276!\n",
      "Avg loss: 0.003434938432352889!\n",
      "Avg loss: 0.0035313938692828136!\n",
      "Avg loss: 0.003422105184630103!\n",
      "Avg loss: 0.0033205450736447043!\n",
      "Avg loss: 0.0033031594513886374!\n",
      "Avg loss: 0.0033014442897426003!\n",
      "Avg loss: 0.0032131244728831614!\n",
      "Avg loss: 0.0031579188991357416!\n",
      "Avg loss: 0.00320169596490814!\n",
      "Avg loss: 0.0032125348330191627!\n",
      "Avg loss: 0.003168480424125543!\n",
      "Avg loss: 0.00315638905743981!\n",
      "Avg loss: 0.0031573525532636875!\n",
      "Avg loss: 0.003159680662029132!\n",
      "Avg loss: 0.003132296579503115!\n",
      "Avg loss: 0.003125845656459205!\n",
      "Avg loss: 0.0031672502944972316!\n",
      "Avg loss: 0.003120118607043878!\n",
      "Avg loss: 0.0030678493137020267!\n",
      "Avg loss: 0.00308629185987229!\n",
      "Avg loss: 0.0031040241796290503!\n",
      "Avg loss: 0.0030941602701659576!\n",
      "Avg loss: 0.003097909826092291!\n",
      "Avg loss: 0.0031534979049683896!\n",
      "Avg loss: 0.0031240407830470454!\n",
      "Avg loss: 0.003101498297319267!\n",
      "Avg loss: 0.0030859574377518585!\n",
      "Avg loss: 0.003094661925024411!\n",
      "Avg loss: 0.003119450702286789!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.05814941540151873!\n",
      "Avg loss: 0.05889911071479825!\n",
      "Avg loss: 0.058614358843963904!\n",
      "Avg loss: 0.056271903072071534!\n",
      "Avg loss: 0.05779118561860135!\n",
      "Avg loss: 0.05701140662919594!\n",
      "Avg loss: 0.056832436422519096!\n",
      "Avg loss: 0.05651576382690109!\n",
      "Avg loss: 0.05735294631459207!\n",
      "Avg loss: 0.05685328455864995!\n",
      "Avg loss: 0.05707421494211303!\n",
      "Avg loss: 0.05718211978498099!\n",
      "Avg loss: 0.05708441141456205!\n",
      "Avg loss: 0.057180813942159146!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.01e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 383       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 5         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -916     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 378      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 10       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.614    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00722  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 21       |\n",
      "|    policy_objective       | 0.00658  |\n",
      "|    std                    | 1.15     |\n",
      "|    value_loss             | 3.74e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -826     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 374      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 16       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.715    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00605  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 22       |\n",
      "|    policy_objective       | 0.00984  |\n",
      "|    std                    | 1.14     |\n",
      "|    value_loss             | 2.71e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -813     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 373      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 21       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.753    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00833  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 23       |\n",
      "|    policy_objective       | 0.00553  |\n",
      "|    std                    | 1.13     |\n",
      "|    value_loss             | 2.09e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -837     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 365      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 27       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.785    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00829  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 24       |\n",
      "|    policy_objective       | 0.00691  |\n",
      "|    std                    | 1.05     |\n",
      "|    value_loss             | 2.53e+03 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1367.5842231348156\n",
      "------------------------------\n",
      "round: 5\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.10023965090125178!\n",
      "Avg loss: 0.08023461091374581!\n",
      "Avg loss: 0.08687886675033951!\n",
      "Avg loss: 0.08150165693448798!\n",
      "Avg loss: 0.08665898822890691!\n",
      "Avg loss: 0.07946988842852686!\n",
      "Avg loss: 0.07986952317697918!\n",
      "Avg loss: 0.08233519859523464!\n",
      "Avg loss: 0.0813041020395273!\n",
      "Avg loss: 0.07956898282701634!\n",
      "Avg loss: 0.07936479059765891!\n",
      "Avg loss: 0.08129151882533431!\n",
      "Avg loss: 0.07942385632021796!\n",
      "Avg loss: 0.07930223400753068!\n",
      "Avg loss: 0.0805092158925072!\n",
      "Avg loss: 0.07999561766509335!\n",
      "Avg loss: 0.07931799208848436!\n",
      "Avg loss: 0.07973925264380645!\n",
      "Avg loss: 0.07977315062909081!\n",
      "Avg loss: 0.07923912030302745!\n",
      "Avg loss: 0.07966202736244062!\n",
      "Avg loss: 0.07974444111334984!\n",
      "Avg loss: 0.07943062376161833!\n",
      "Avg loss: 0.07962122254505327!\n",
      "Avg loss: 0.07950980549093704!\n",
      "Avg loss: 0.07932751366268954!\n",
      "Avg loss: 0.07956332922960428!\n",
      "Avg loss: 0.07938925306060507!\n",
      "Avg loss: 0.07940012105059092!\n",
      "Avg loss: 0.07950879215699085!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.09236394254844829!\n",
      "Avg loss: 0.08285509808517721!\n",
      "Avg loss: 0.08267550261797926!\n",
      "Avg loss: 0.08367019477962458!\n",
      "Avg loss: 0.08358949281044867!\n",
      "Avg loss: 0.07966912135239303!\n",
      "Avg loss: 0.07905449343301976!\n",
      "Avg loss: 0.08152793611174275!\n",
      "Avg loss: 0.07793588105105907!\n",
      "Avg loss: 0.07745770142316663!\n",
      "Avg loss: 0.07875073082824505!\n",
      "Avg loss: 0.07810549478707496!\n",
      "Avg loss: 0.07726820269502241!\n",
      "Avg loss: 0.07792367611698259!\n",
      "Avg loss: 0.07770806471583759!\n",
      "Avg loss: 0.07703073291547602!\n",
      "Avg loss: 0.07747220788702786!\n",
      "Avg loss: 0.07722285606259902!\n",
      "Avg loss: 0.07691663519050053!\n",
      "Avg loss: 0.0771186250827183!\n",
      "Avg loss: 0.0768903124105691!\n",
      "Avg loss: 0.07685321524097162!\n",
      "Avg loss: 0.07683645595244494!\n",
      "Avg loss: 0.07664577984917136!\n",
      "Avg loss: 0.0766581298522336!\n",
      "Avg loss: 0.07671446241189793!\n",
      "Avg loss: 0.07670758860005056!\n",
      "Avg loss: 0.0766304759381698!\n",
      "Avg loss: 0.07661835758488147!\n"
     ]
    }
   ],
   "source": [
    "# initialize the client and server\n",
    "timesteps_real_per_round = 500\n",
    "timesteps_fc_per_round = timesteps_real_per_round * 20\n",
    "epoch_per_round = 100\n",
    "CLIENTS_NUM = 3\n",
    "rounds_num = 20\n",
    "batch_size_env_model = 128\n",
    "\n",
    "env_models = []\n",
    "MB_env = TimeLimit(MB_PendulumEnv(env_models,device), max_episode_steps = 200)\n",
    "\n",
    "# Global_RL = PPO(\"MlpPolicy\", MB_env, verbose=1)\n",
    "Global_RL = TRPO(\"MlpPolicy\", MB_env, verbose=1)\n",
    "\n",
    "env_theta = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "real_envs = []\n",
    "Clients = []\n",
    "for i in range(CLIENTS_NUM):\n",
    "    real_envs.append( TimeLimit(PendulumEnv(), max_episode_steps=200) )\n",
    "    policy_net = Global_RL\n",
    "    agent = SB3Agent(policy_net)\n",
    "    client = FRLClient(real_envs[i], agent, lr = 3e-4, hidden_size = 256, device = device)\n",
    "    Clients.append(client)\n",
    "    env_model = copy.deepcopy(client.model)\n",
    "    env_models.append(env_model)\n",
    "    \n",
    "\n",
    "Global_RL.env.models = env_models\n",
    "\n",
    "\n",
    "rewards_log = []\n",
    "\n",
    "env_models = []\n",
    "for round_idx in range(rounds_num):\n",
    "    print('------------------------------')\n",
    "    print(\"round: \" + str(round_idx))\n",
    "    for client_idx in range(len(Clients)):\n",
    "        print('------------------------------')\n",
    "        print(\"client: \" + str(client_idx))\n",
    "        # update policy\n",
    "        Clients[client_idx].agent.policy_net = Global_RL\n",
    "        # train prediction models\n",
    "        Clients[client_idx].learn(timesteps_real_per_round, epoch_per_round, batch_size_env_model)\n",
    "        #\n",
    "        env_model = Clients[client_idx].get_prediction_model()\n",
    "        env_models.append(env_model)\n",
    "    \n",
    "#     Server.update_env_models(env_models)\n",
    "    Global_RL.env.models = env_models\n",
    "    #\n",
    "    Global_RL.learn(total_timesteps=timesteps_fc_per_round)\n",
    "    \n",
    "#     Server.learn(timesteps_real_per_round = 10000)\n",
    "    # test performance\n",
    "    mean_reward, std_reward = evaluate_policy(Global_RL, real_envs[1], n_eval_episodes=10)\n",
    "    rewards_log.append(mean_reward)\n",
    "    print(\"mean_reward in real env:\" + str(mean_reward))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f748ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs,_ = Clients[0].env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "200357a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.80263555,  0.5964697 , -0.84910995], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02079844",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clients[0].agent.act(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22093d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.30735433], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clients[0].agent.policy_net.predict(obs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bbe53a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1699efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: -93.15121025741101 +/- 109.2765889131137\n"
     ]
    }
   ],
   "source": [
    "# mean_reward, std_reward = evaluate_policy(Global_RL, real_envs[1], n_eval_episodes=10)\n",
    "mean_reward, std_reward = evaluate_policy(Global_RL, MB_env, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9285a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib import TRPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1ac5563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "TRPO_model = TRPO(\"MlpPolicy\", env=real_envs[0], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23e35f65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -829     |\n",
      "| time/              |          |\n",
      "|    fps             | 520      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -847     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 478      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 8        |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.715    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00696  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 50       |\n",
      "|    policy_objective       | 0.0147   |\n",
      "|    std                    | 0.809    |\n",
      "|    value_loss             | 433      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -893     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 481      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 12       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.749    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00777  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 51       |\n",
      "|    policy_objective       | 0.0188   |\n",
      "|    std                    | 0.789    |\n",
      "|    value_loss             | 629      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -890     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 470      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.759    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00865  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 52       |\n",
      "|    policy_objective       | 0.0126   |\n",
      "|    std                    | 0.762    |\n",
      "|    value_loss             | 857      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -875     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 470      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 21       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.8      |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00702  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 53       |\n",
      "|    policy_objective       | 0.0123   |\n",
      "|    std                    | 0.769    |\n",
      "|    value_loss             | 679      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -860     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 465      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 26       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.825    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00762  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 54       |\n",
      "|    policy_objective       | 0.0143   |\n",
      "|    std                    | 0.757    |\n",
      "|    value_loss             | 660      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -832     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 467      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 30       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.851    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00773  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 55       |\n",
      "|    policy_objective       | 0.0167   |\n",
      "|    std                    | 0.743    |\n",
      "|    value_loss             | 428      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -808     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 470      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 34       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.881    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00726  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 56       |\n",
      "|    policy_objective       | 0.0213   |\n",
      "|    std                    | 0.72     |\n",
      "|    value_loss             | 291      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -794     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 472      |\n",
      "|    iterations             | 9        |\n",
      "|    time_elapsed           | 39       |\n",
      "|    total_timesteps        | 18432    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.876    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00698  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 57       |\n",
      "|    policy_objective       | 0.0147   |\n",
      "|    std                    | 0.728    |\n",
      "|    value_loss             | 506      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -758     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 471      |\n",
      "|    iterations             | 10       |\n",
      "|    time_elapsed           | 43       |\n",
      "|    total_timesteps        | 20480    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.914    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00761  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 58       |\n",
      "|    policy_objective       | 0.0205   |\n",
      "|    std                    | 0.72     |\n",
      "|    value_loss             | 376      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -734     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 472      |\n",
      "|    iterations             | 11       |\n",
      "|    time_elapsed           | 47       |\n",
      "|    total_timesteps        | 22528    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.883    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00787  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 59       |\n",
      "|    policy_objective       | 0.0231   |\n",
      "|    std                    | 0.698    |\n",
      "|    value_loss             | 250      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -690     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 473      |\n",
      "|    iterations             | 12       |\n",
      "|    time_elapsed           | 51       |\n",
      "|    total_timesteps        | 24576    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.927    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00787  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 60       |\n",
      "|    policy_objective       | 0.0255   |\n",
      "|    std                    | 0.692    |\n",
      "|    value_loss             | 283      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -644     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 473      |\n",
      "|    iterations             | 13       |\n",
      "|    time_elapsed           | 56       |\n",
      "|    total_timesteps        | 26624    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.928    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00833  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 61       |\n",
      "|    policy_objective       | 0.0195   |\n",
      "|    std                    | 0.681    |\n",
      "|    value_loss             | 334      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -604     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 473      |\n",
      "|    iterations             | 14       |\n",
      "|    time_elapsed           | 60       |\n",
      "|    total_timesteps        | 28672    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.884    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00801  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 62       |\n",
      "|    policy_objective       | 0.0296   |\n",
      "|    std                    | 0.677    |\n",
      "|    value_loss             | 282      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -550     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 474      |\n",
      "|    iterations             | 15       |\n",
      "|    time_elapsed           | 64       |\n",
      "|    total_timesteps        | 30720    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.927    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00836  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 63       |\n",
      "|    policy_objective       | 0.0263   |\n",
      "|    std                    | 0.654    |\n",
      "|    value_loss             | 260      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -499     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 474      |\n",
      "|    iterations             | 16       |\n",
      "|    time_elapsed           | 69       |\n",
      "|    total_timesteps        | 32768    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.926    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00848  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 64       |\n",
      "|    policy_objective       | 0.0303   |\n",
      "|    std                    | 0.638    |\n",
      "|    value_loss             | 274      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -445     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 473      |\n",
      "|    iterations             | 17       |\n",
      "|    time_elapsed           | 73       |\n",
      "|    total_timesteps        | 34816    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.954    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00868  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 65       |\n",
      "|    policy_objective       | 0.0229   |\n",
      "|    std                    | 0.639    |\n",
      "|    value_loss             | 202      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mTRPO_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\sb3_contrib\\trpo\\trpo.py:412\u001b[0m, in \u001b[0;36mTRPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTRPO,\n\u001b[0;32m    405\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    410\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    411\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTRPO:\n\u001b[1;32m--> 412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:259\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 259\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:169\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Convert to pytorch tensor or to TensorDict\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     obs_tensor \u001b[38;5;241m=\u001b[39m obs_as_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 169\u001b[0m     actions, values, log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\policies.py:619\u001b[0m, in \u001b[0;36mActorCriticPolicy.forward\u001b[1;34m(self, obs, deterministic)\u001b[0m\n\u001b[0;32m    617\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_features(obs)\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor:\n\u001b[1;32m--> 619\u001b[0m     latent_pi, latent_vf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m     pi_features, vf_features \u001b[38;5;241m=\u001b[39m features\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\torch_layers.py:222\u001b[0m, in \u001b[0;36mMlpExtractor.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[th\u001b[38;5;241m.\u001b[39mTensor, th\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m    :return: latent_policy, latent_value of the specified network.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m        If all layers are shared, then ``latent_policy == latent_value``\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_actor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_critic(features)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\torch_layers.py:225\u001b[0m, in \u001b[0;36mMlpExtractor.forward_actor\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_actor\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\activation.py:356\u001b[0m, in \u001b[0;36mTanh.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRPO_model.learn(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db1039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

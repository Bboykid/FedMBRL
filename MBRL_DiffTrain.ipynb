{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2303b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Envs.pendulum import PendulumEnv\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import TimeLimit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494268cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PendulumEnv()\n",
    "env = TimeLimit(env, max_episode_steps=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fba20c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.9434946, -0.3313878, -0.5660853], dtype=float32), {})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec815b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2024f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MBEnvs.mb_pendulum2 import MB_PendulumEnv\n",
    "env_models = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MB_env = MB_PendulumEnv(env_models, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c32890",
   "metadata": {},
   "outputs": [],
   "source": [
    "Global_RL = PPO(\"MlpPolicy\", MB_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c97b36",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SB3Agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m agent_sb3 \u001b[38;5;241m=\u001b[39m \u001b[43mSB3Agent\u001b[49m(policy_net\u001b[38;5;241m=\u001b[39mGlobal_RL)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SB3Agent' is not defined"
     ]
    }
   ],
   "source": [
    "agent_sb3 = SB3Agent(policy_net=Global_RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c62b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_client = FRLClient(env=env,agent=agent_sb3, lr=0.0001, hidden_size= 256, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a500b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_client.sample_data(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4875b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_client.dataset_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_client.dataset_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfdeb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aed97cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c69c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib import TRPO\n",
    "from Client_diff import FRLClient\n",
    "from Agent import SB3Agent\n",
    "import copy\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d1f4b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Envs.pendulum import PendulumEnv\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "from MBEnvs.mb_pendulum2 import MB_PendulumEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e29110c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc0bbb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------\n",
      "round: 0\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.04868310136526512!\n",
      "Avg loss: 0.044924415900022725!\n",
      "Avg loss: 0.03592031486579799!\n",
      "Avg loss: 0.028088284618218797!\n",
      "Avg loss: 0.024023949964612257!\n",
      "Avg loss: 0.01961558230448039!\n",
      "Avg loss: 0.01582214093775595!\n",
      "Avg loss: 0.0136429249152449!\n",
      "Avg loss: 0.011391439223558942!\n",
      "Avg loss: 0.010200884459894345!\n",
      "Avg loss: 0.009813459757563881!\n",
      "Avg loss: 0.00922204474969476!\n",
      "Avg loss: 0.009200138067390071!\n",
      "Avg loss: 0.009022898784041899!\n",
      "Avg loss: 0.008806581991987817!\n",
      "Avg loss: 0.008776119028402718!\n",
      "Avg loss: 0.008708367624747856!\n",
      "Avg loss: 0.008671851732908636!\n",
      "Avg loss: 0.00859090020147202!\n",
      "Avg loss: 0.008574432661339415!\n",
      "Avg loss: 0.008541021096710514!\n",
      "Avg loss: 0.008531650050093351!\n",
      "Avg loss: 0.00853083459862925!\n",
      "Avg loss: 0.00853476422660909!\n",
      "Avg loss: 0.008525802299852028!\n",
      "Avg loss: 0.008511673956184799!\n",
      "Avg loss: 0.008497655833637813!\n",
      "Avg loss: 0.00847168022679701!\n",
      "Avg loss: 0.008459022284896492!\n",
      "Avg loss: 0.0084539049843382!\n",
      "Avg loss: 0.008439319202469354!\n",
      "Avg loss: 0.008427212671660224!\n",
      "Avg loss: 0.008411689001565416!\n",
      "Avg loss: 0.008401063973557636!\n",
      "Avg loss: 0.00839060563166792!\n",
      "Avg loss: 0.008383225089154015!\n",
      "Avg loss: 0.008378394382946984!\n",
      "Avg loss: 0.008376239004570987!\n",
      "Avg loss: 0.008372090261119259!\n",
      "Avg loss: 0.00836695175229996!\n",
      "Avg loss: 0.008360676639358643!\n",
      "Avg loss: 0.00835281825427766!\n",
      "Avg loss: 0.008353843148829582!\n",
      "Avg loss: 0.008344046988164943!\n",
      "Avg loss: 0.008341341603692551!\n",
      "Avg loss: 0.008335331130645045!\n",
      "Avg loss: 0.00833444551910058!\n",
      "Avg loss: 0.008324968892418383!\n",
      "Avg loss: 0.008327714967258544!\n",
      "Avg loss: 0.008324603053507266!\n",
      "Avg loss: 0.00832392745510712!\n",
      "Avg loss: 0.008320641975333653!\n",
      "Avg loss: 0.00832265214555908!\n",
      "Avg loss: 0.00832432789229794!\n",
      "Avg loss: 0.008324884173806215!\n",
      "Avg loss: 0.008322209055633797!\n",
      "Avg loss: 0.0083199017633198!\n",
      "Avg loss: 0.008316026979013789!\n",
      "Avg loss: 0.008318826377289572!\n",
      "Avg loss: 0.008326238605863713!\n",
      "Avg loss: 0.008333300167712044!\n",
      "Avg loss: 0.008329454916479335!\n",
      "Avg loss: 0.00832434816215861!\n",
      "Avg loss: 0.008327577748304974!\n",
      "Avg loss: 0.008330439222243058!\n",
      "Avg loss: 0.008328529919082636!\n",
      "Avg loss: 0.008330882104819845!\n",
      "Avg loss: 0.008342105917044667!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.09968186271512726!\n",
      "Avg loss: 0.08002265345344009!\n",
      "Avg loss: 0.05207727048740101!\n",
      "Avg loss: 0.030952812489607216!\n",
      "Avg loss: 0.019572983748027278!\n",
      "Avg loss: 0.00916473214388437!\n",
      "Avg loss: 0.004447570528815656!\n",
      "Avg loss: 0.003361891051463317!\n",
      "Avg loss: 0.0030945185191467318!\n",
      "Avg loss: 0.0037711484558773617!\n",
      "Avg loss: 0.0035171847002978514!\n",
      "Avg loss: 0.0030007648742806244!\n",
      "Avg loss: 0.0022087317534411947!\n",
      "Avg loss: 0.0016527743307475854!\n",
      "Avg loss: 0.0013100371722005852!\n",
      "Avg loss: 0.0011661019266224078!\n",
      "Avg loss: 0.0010125910989518161!\n",
      "Avg loss: 0.000994085594563027!\n",
      "Avg loss: 0.0009178287945481618!\n",
      "Avg loss: 0.0008567238695953468!\n",
      "Avg loss: 0.0007845831736085529!\n",
      "Avg loss: 0.0007667209955616272!\n",
      "Avg loss: 0.0007427589928799231!\n",
      "Avg loss: 0.0007482694407493303!\n",
      "Avg loss: 0.0007478397110480728!\n",
      "Avg loss: 0.0007400396792187773!\n",
      "Avg loss: 0.0007291787613803535!\n",
      "Avg loss: 0.0007024544227715524!\n",
      "Avg loss: 0.0006763120907332147!\n",
      "Avg loss: 0.000662975949265577!\n",
      "Avg loss: 0.0006458678374110605!\n",
      "Avg loss: 0.0006331992580423199!\n",
      "Avg loss: 0.0006277664271328831!\n",
      "Avg loss: 0.0006196194639202683!\n",
      "Avg loss: 0.0006163716254377505!\n",
      "Avg loss: 0.0006182935224812051!\n",
      "Avg loss: 0.0006170810240776821!\n",
      "Avg loss: 0.000612250383085969!\n",
      "Avg loss: 0.0006093918333590409!\n",
      "Avg loss: 0.000601735369968992!\n",
      "Avg loss: 0.0005975421747431635!\n",
      "Avg loss: 0.0005982803051695859!\n",
      "Avg loss: 0.0005921651942329239!\n",
      "Avg loss: 0.0005932671711434522!\n",
      "Avg loss: 0.0005892537351292049!\n",
      "Avg loss: 0.0005852642956021252!\n",
      "Avg loss: 0.0005851178564944349!\n",
      "Avg loss: 0.0005834835587969186!\n",
      "Avg loss: 0.0005848789569419447!\n",
      "Avg loss: 0.0005857984557731773!\n",
      "Avg loss: 0.0005863343474932966!\n",
      "Avg loss: 0.0005858724370273194!\n",
      "Avg loss: 0.0005854009964544578!\n",
      "Avg loss: 0.0005873862379212369!\n",
      "Avg loss: 0.0005865703826339086!\n",
      "Avg loss: 0.00058695332396231!\n",
      "Avg loss: 0.0005869705654981772!\n",
      "Avg loss: 0.0005879017772895168!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.14549746310260767!\n",
      "Avg loss: 0.12247070425966133!\n",
      "Avg loss: 0.09959233326216539!\n",
      "Avg loss: 0.08085828231958052!\n",
      "Avg loss: 0.06972972831300771!\n",
      "Avg loss: 0.06341538528193875!\n",
      "Avg loss: 0.05906877472472843!\n",
      "Avg loss: 0.057963973463726386!\n",
      "Avg loss: 0.05785833746573189!\n",
      "Avg loss: 0.0572516385873314!\n",
      "Avg loss: 0.05701966029921702!\n",
      "Avg loss: 0.0566071974701966!\n",
      "Avg loss: 0.055509919254012254!\n",
      "Avg loss: 0.054921837479341776!\n",
      "Avg loss: 0.05466559657783364!\n",
      "Avg loss: 0.05441442654311686!\n",
      "Avg loss: 0.05418813328274458!\n",
      "Avg loss: 0.05392466339522798!\n",
      "Avg loss: 0.053782099626211374!\n",
      "Avg loss: 0.053720035423660495!\n",
      "Avg loss: 0.05350502710537209!\n",
      "Avg loss: 0.053328745781703525!\n",
      "Avg loss: 0.053284182260152496!\n",
      "Avg loss: 0.05326371390258525!\n",
      "Avg loss: 0.053157273164652!\n",
      "Avg loss: 0.05305772596373269!\n",
      "Avg loss: 0.05301356298591903!\n",
      "Avg loss: 0.05295579491347477!\n",
      "Avg loss: 0.052858975374083454!\n",
      "Avg loss: 0.05278897802044564!\n",
      "Avg loss: 0.05276501967757213!\n",
      "Avg loss: 0.05273238342740873!\n",
      "Avg loss: 0.05270028106066093!\n",
      "Avg loss: 0.05265496993919821!\n",
      "Avg loss: 0.05264321721221677!\n",
      "Avg loss: 0.052630169503075495!\n",
      "Avg loss: 0.05256687418958298!\n",
      "Avg loss: 0.05252359333942726!\n",
      "Avg loss: 0.0525103812426111!\n",
      "Avg loss: 0.05250690110029154!\n",
      "Avg loss: 0.05247474623546319!\n",
      "Avg loss: 0.05244892047324811!\n",
      "Avg loss: 0.05244463690992689!\n",
      "Avg loss: 0.05238067741356341!\n",
      "Avg loss: 0.05238156591095049!\n",
      "Avg loss: 0.052397923590660866!\n",
      "Avg loss: 0.052427856418586695!\n",
      "Avg loss: 0.05241470798715151!\n",
      "Avg loss: 0.052376930162841596!\n",
      "Avg loss: 0.05239760135076646!\n",
      "Avg loss: 0.05236321343305917!\n",
      "Avg loss: 0.052374657951136216!\n",
      "Avg loss: 0.0523638788769252!\n",
      "Avg loss: 0.05234521272188961!\n",
      "Avg loss: 0.052327667155741435!\n",
      "Avg loss: 0.052293541619463514!\n",
      "Avg loss: 0.05229626133729198!\n",
      "Avg loss: 0.05224121977038673!\n",
      "Avg loss: 0.05217318798497369!\n",
      "Avg loss: 0.052171914357541024!\n",
      "Avg loss: 0.05217808644133432!\n",
      "Avg loss: 0.05215944686406753!\n",
      "Avg loss: 0.05224001784112033!\n",
      "Avg loss: 0.052233545251364526!\n",
      "Avg loss: 0.05220411226371046!\n",
      "Avg loss: 0.05225517622708897!\n",
      "Avg loss: 0.05219466759636134!\n",
      "Avg loss: 0.05211287838874796!\n",
      "Avg loss: 0.0521308221046426!\n",
      "Avg loss: 0.05215296005909901!\n",
      "Avg loss: 0.05212624064949371!\n",
      "Avg loss: 0.05217036288662484!\n",
      "Avg loss: 0.05217298179415707!\n",
      "Avg loss: 0.05211551820228351!\n",
      "Avg loss: 0.05213367308833076!\n",
      "Avg loss: 0.052143648180142464!\n",
      "Avg loss: 0.05210747145105017!\n",
      "Avg loss: 0.05209322979049129!\n",
      "Avg loss: 0.05211546279230106!\n",
      "Avg loss: 0.0521133908536414!\n",
      "Avg loss: 0.05209905563091581!\n",
      "Avg loss: 0.05207695013072149!\n",
      "Avg loss: 0.052028279227624805!\n",
      "Avg loss: 0.05202503352447593!\n",
      "Avg loss: 0.05206710683445635!\n",
      "Avg loss: 0.05212254899935336!\n",
      "Avg loss: 0.0521106633476082!\n",
      "Avg loss: 0.052068891879859316!\n",
      "Avg loss: 0.05203668186121831!\n",
      "Avg loss: 0.05201509699296518!\n",
      "Avg loss: 0.0520779712571948!\n",
      "Avg loss: 0.052096019866913444!\n",
      "Avg loss: 0.052094932259204446!\n",
      "Avg loss: 0.05206852758990105!\n",
      "Avg loss: 0.05211524900564958!\n",
      "Avg loss: 0.05212677945029403!\n",
      "Avg loss: 0.052145476623564564!\n",
      "Avg loss: 0.05217453215947671!\n",
      "Avg loss: 0.05214215187716945!\n",
      "Avg loss: 0.052146054109559636!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.36e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 408       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 5         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.29e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 387       |\n",
      "|    iterations             | 2         |\n",
      "|    time_elapsed           | 10        |\n",
      "|    total_timesteps        | 4096      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.0023    |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00938   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 1         |\n",
      "|    policy_objective       | 0.00787   |\n",
      "|    std                    | 1.02      |\n",
      "|    value_loss             | 1.06e+04  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.23e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 374       |\n",
      "|    iterations             | 3         |\n",
      "|    time_elapsed           | 16        |\n",
      "|    total_timesteps        | 6144      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.104     |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00585   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 2         |\n",
      "|    policy_objective       | 0.00286   |\n",
      "|    std                    | 0.988     |\n",
      "|    value_loss             | 8.24e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.26e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 367       |\n",
      "|    iterations             | 4         |\n",
      "|    time_elapsed           | 22        |\n",
      "|    total_timesteps        | 8192      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.00979   |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00829   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 3         |\n",
      "|    policy_objective       | 0.00614   |\n",
      "|    std                    | 1         |\n",
      "|    value_loss             | 6.74e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.26e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 368       |\n",
      "|    iterations             | 5         |\n",
      "|    time_elapsed           | 27        |\n",
      "|    total_timesteps        | 10240     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.00193   |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00819   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 4         |\n",
      "|    policy_objective       | 0.00656   |\n",
      "|    std                    | 1.05      |\n",
      "|    value_loss             | 9e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.26e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 366       |\n",
      "|    iterations             | 6         |\n",
      "|    time_elapsed           | 33        |\n",
      "|    total_timesteps        | 12288     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.00323   |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00914   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 5         |\n",
      "|    policy_objective       | 0.0101    |\n",
      "|    std                    | 1.1       |\n",
      "|    value_loss             | 8.23e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.24e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 368       |\n",
      "|    iterations             | 7         |\n",
      "|    time_elapsed           | 38        |\n",
      "|    total_timesteps        | 14336     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.00088   |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00874   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 6         |\n",
      "|    policy_objective       | 0.0107    |\n",
      "|    std                    | 1.11      |\n",
      "|    value_loss             | 7.15e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.22e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 367       |\n",
      "|    iterations             | 8         |\n",
      "|    time_elapsed           | 44        |\n",
      "|    total_timesteps        | 16384     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.000842  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00853   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 7         |\n",
      "|    policy_objective       | 0.00974   |\n",
      "|    std                    | 1.16      |\n",
      "|    value_loss             | 6.05e+03  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-970.8002081733197\n",
      "------------------------------\n",
      "round: 1\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.06627273318152826!\n",
      "Avg loss: 0.06480540659918915!\n",
      "Avg loss: 0.0708619611239313!\n",
      "Avg loss: 0.06605237186638988!\n",
      "Avg loss: 0.06447621269226754!\n",
      "Avg loss: 0.06678620818939332!\n",
      "Avg loss: 0.06697490413793275!\n",
      "Avg loss: 0.06564920134653221!\n",
      "Avg loss: 0.06538953432984423!\n",
      "Avg loss: 0.06635129690348548!\n",
      "Avg loss: 0.06594208235880311!\n",
      "Avg loss: 0.06549720621177887!\n",
      "Avg loss: 0.0658978603505481!\n",
      "Avg loss: 0.06564643836732936!\n",
      "Avg loss: 0.0656654613414139!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.004166742545997598!\n",
      "Avg loss: 0.002900009418456951!\n",
      "Avg loss: 0.007681064587328971!\n",
      "Avg loss: 0.0038525863432490345!\n",
      "Avg loss: 0.002771797629654126!\n",
      "Avg loss: 0.003844517233471076!\n",
      "Avg loss: 0.00494996280194755!\n",
      "Avg loss: 0.0029949685269093605!\n",
      "Avg loss: 0.0028080201640477754!\n",
      "Avg loss: 0.004186754163583828!\n",
      "Avg loss: 0.003415331378976892!\n",
      "Avg loss: 0.00278397765609346!\n",
      "Avg loss: 0.003294743868582373!\n",
      "Avg loss: 0.003595407304201217!\n",
      "Avg loss: 0.0028041406103632956!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.007967350306765486!\n",
      "Avg loss: 0.0033000361217636965!\n",
      "Avg loss: 0.004485457388485278!\n",
      "Avg loss: 0.0059219267195415645!\n",
      "Avg loss: 0.0045982917227835665!\n",
      "Avg loss: 0.002980328917425747!\n",
      "Avg loss: 0.00309428833653025!\n",
      "Avg loss: 0.0038536950723998113!\n",
      "Avg loss: 0.003964114711961884!\n",
      "Avg loss: 0.003218021702717427!\n",
      "Avg loss: 0.003117039985597027!\n",
      "Avg loss: 0.003671513576984277!\n",
      "Avg loss: 0.004076393043178541!\n",
      "Avg loss: 0.0036254994152780757!\n",
      "Avg loss: 0.003362931766193166!\n",
      "Avg loss: 0.003648367692124642!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -973     |\n",
      "| time/              |          |\n",
      "|    fps             | 383      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.03e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 375       |\n",
      "|    iterations             | 2         |\n",
      "|    time_elapsed           | 10        |\n",
      "|    total_timesteps        | 4096      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.000134  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00951   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 9         |\n",
      "|    policy_objective       | 0.00863   |\n",
      "|    std                    | 1.11      |\n",
      "|    value_loss             | 4.03e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.04e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 360       |\n",
      "|    iterations             | 3         |\n",
      "|    time_elapsed           | 17        |\n",
      "|    total_timesteps        | 6144      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.000435  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00683   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 10        |\n",
      "|    policy_objective       | 0.00794   |\n",
      "|    std                    | 1.09      |\n",
      "|    value_loss             | 4.55e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.05e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 356       |\n",
      "|    iterations             | 4         |\n",
      "|    time_elapsed           | 22        |\n",
      "|    total_timesteps        | 8192      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.000192  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00543   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 11        |\n",
      "|    policy_objective       | 0.00596   |\n",
      "|    std                    | 1.06      |\n",
      "|    value_loss             | 4.35e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.06e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 351       |\n",
      "|    iterations             | 5         |\n",
      "|    time_elapsed           | 29        |\n",
      "|    total_timesteps        | 10240     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -0.00489  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00811   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 12        |\n",
      "|    policy_objective       | 0.00922   |\n",
      "|    std                    | 1.06      |\n",
      "|    value_loss             | 4.35e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.06e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 348       |\n",
      "|    iterations             | 6         |\n",
      "|    time_elapsed           | 35        |\n",
      "|    total_timesteps        | 12288     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.000559  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00921   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 13        |\n",
      "|    policy_objective       | 0.0125    |\n",
      "|    std                    | 1.09      |\n",
      "|    value_loss             | 3.94e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.05e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 345       |\n",
      "|    iterations             | 7         |\n",
      "|    time_elapsed           | 41        |\n",
      "|    total_timesteps        | 14336     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.000109  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00774   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 14        |\n",
      "|    policy_objective       | 0.0105    |\n",
      "|    std                    | 1.08      |\n",
      "|    value_loss             | 4.02e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.05e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 341       |\n",
      "|    iterations             | 8         |\n",
      "|    time_elapsed           | 47        |\n",
      "|    total_timesteps        | 16384     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 6.62e-05  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00861   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 15        |\n",
      "|    policy_objective       | 0.00873   |\n",
      "|    std                    | 1         |\n",
      "|    value_loss             | 3.13e+03  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1123.6436900161207\n",
      "------------------------------\n",
      "round: 2\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.04595727012188339!\n",
      "Avg loss: 0.04513329592044708!\n",
      "Avg loss: 0.04371459782497065!\n",
      "Avg loss: 0.043524599199061716!\n",
      "Avg loss: 0.04497609506921435!\n",
      "Avg loss: 0.04373236365103367!\n",
      "Avg loss: 0.0430247428365692!\n",
      "Avg loss: 0.04279135617208643!\n",
      "Avg loss: 0.043667421449763426!\n",
      "Avg loss: 0.0434352506453079!\n",
      "Avg loss: 0.04294429743931839!\n",
      "Avg loss: 0.04314505370807789!\n",
      "Avg loss: 0.04359112812998016!\n",
      "Avg loss: 0.04321202044197283!\n",
      "Avg loss: 0.043059611376550795!\n",
      "Avg loss: 0.04324812638800836!\n",
      "Avg loss: 0.04323747132383384!\n",
      "Avg loss: 0.0430552755831953!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.0033712965163916427!\n",
      "Avg loss: 0.0030140623851427034!\n",
      "Avg loss: 0.004273183082308!\n",
      "Avg loss: 0.006035199996149459!\n",
      "Avg loss: 0.002575412921808796!\n",
      "Avg loss: 0.002218861856381409!\n",
      "Avg loss: 0.003219299943278505!\n",
      "Avg loss: 0.004272769116105337!\n",
      "Avg loss: 0.002687604777214195!\n",
      "Avg loss: 0.0025339284917815044!\n",
      "Avg loss: 0.0031081601706925235!\n",
      "Avg loss: 0.0036146584222236317!\n",
      "Avg loss: 0.002861342663606289!\n",
      "Avg loss: 0.00268135029549588!\n",
      "Avg loss: 0.0030744159320996306!\n",
      "Avg loss: 0.003292335551056264!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.012230655288440175!\n",
      "Avg loss: 0.009449028098072935!\n",
      "Avg loss: 0.0029178475617663933!\n",
      "Avg loss: 0.0022631132053114317!\n",
      "Avg loss: 0.007340075677687612!\n",
      "Avg loss: 0.005332131247754054!\n",
      "Avg loss: 0.0023035099965515353!\n",
      "Avg loss: 0.002194540673796534!\n",
      "Avg loss: 0.004086070758518569!\n",
      "Avg loss: 0.004308664471294226!\n",
      "Avg loss: 0.0024142575132767284!\n",
      "Avg loss: 0.002065954720819718!\n",
      "Avg loss: 0.0031066254361212485!\n",
      "Avg loss: 0.003371595762752501!\n",
      "Avg loss: 0.002344260978449408!\n",
      "Avg loss: 0.0021274720692114595!\n",
      "Avg loss: 0.002741089905490905!\n",
      "Avg loss: 0.0027486449235342054!\n",
      "Avg loss: 0.002202533374390138!\n",
      "Avg loss: 0.00223295272133934!\n",
      "Avg loss: 0.002639868423372415!\n",
      "Avg loss: 0.002538437365789529!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1e+03   |\n",
      "| time/              |          |\n",
      "|    fps             | 395      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -991     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 385      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 10       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 8.17e-05 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00732  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 17       |\n",
      "|    policy_objective       | 0.00568  |\n",
      "|    std                    | 0.96     |\n",
      "|    value_loss             | 2.94e+03 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.02e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 374       |\n",
      "|    iterations             | 3         |\n",
      "|    time_elapsed           | 16        |\n",
      "|    total_timesteps        | 6144      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 4.43e-05  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00553   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 18        |\n",
      "|    policy_objective       | 0.00843   |\n",
      "|    std                    | 0.938     |\n",
      "|    value_loss             | 2.56e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.03e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 364       |\n",
      "|    iterations             | 4         |\n",
      "|    time_elapsed           | 22        |\n",
      "|    total_timesteps        | 8192      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 5.18e-05  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00976   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 19        |\n",
      "|    policy_objective       | 0.00781   |\n",
      "|    std                    | 0.9       |\n",
      "|    value_loss             | 2.89e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.03e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 364       |\n",
      "|    iterations             | 5         |\n",
      "|    time_elapsed           | 28        |\n",
      "|    total_timesteps        | 10240     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 2.78e-05  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.0085    |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 20        |\n",
      "|    policy_objective       | 0.00891   |\n",
      "|    std                    | 0.887     |\n",
      "|    value_loss             | 2.95e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.03e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 360       |\n",
      "|    iterations             | 6         |\n",
      "|    time_elapsed           | 34        |\n",
      "|    total_timesteps        | 12288     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -2.61e-05 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00765   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 21        |\n",
      "|    policy_objective       | 0.0127    |\n",
      "|    std                    | 0.848     |\n",
      "|    value_loss             | 2.3e+03   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.02e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 362       |\n",
      "|    iterations             | 7         |\n",
      "|    time_elapsed           | 39        |\n",
      "|    total_timesteps        | 14336     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 2.69e-05  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00543   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 22        |\n",
      "|    policy_objective       | 0.0059    |\n",
      "|    std                    | 0.821     |\n",
      "|    value_loss             | 2.4e+03   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.02e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 360       |\n",
      "|    iterations             | 8         |\n",
      "|    time_elapsed           | 45        |\n",
      "|    total_timesteps        | 16384     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 1.78e-05  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.0076    |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 23        |\n",
      "|    policy_objective       | 0.00834   |\n",
      "|    std                    | 0.86      |\n",
      "|    value_loss             | 2.03e+03  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1136.0690905712545\n",
      "------------------------------\n",
      "round: 3\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.08860730226054632!\n",
      "Avg loss: 0.0872106190736425!\n",
      "Avg loss: 0.09186412328365501!\n",
      "Avg loss: 0.08850939928113803!\n",
      "Avg loss: 0.08807924521187184!\n",
      "Avg loss: 0.08895508353252202!\n",
      "Avg loss: 0.08935901745885834!\n",
      "Avg loss: 0.08781970243418982!\n",
      "Avg loss: 0.0880679602356031!\n",
      "Avg loss: 0.08783331077774771!\n",
      "Avg loss: 0.08726306064212622!\n",
      "Avg loss: 0.08729015557394026!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.023115810132197413!\n",
      "Avg loss: 0.021476460115857965!\n",
      "Avg loss: 0.022528968557683885!\n",
      "Avg loss: 0.02572127637756542!\n",
      "Avg loss: 0.025192270344947854!\n",
      "Avg loss: 0.022284037851447162!\n",
      "Avg loss: 0.022766560738840175!\n",
      "Avg loss: 0.024529357165920373!\n",
      "Avg loss: 0.025667055798664174!\n",
      "Avg loss: 0.024594352347448875!\n",
      "Avg loss: 0.023621905737333387!\n",
      "Avg loss: 0.023823051412728093!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.17691852111505188!\n",
      "Avg loss: 0.16985134052212136!\n",
      "Avg loss: 0.17219073341810145!\n",
      "Avg loss: 0.1669027883842379!\n",
      "Avg loss: 0.17128174121215126!\n",
      "Avg loss: 0.16682164165044622!\n",
      "Avg loss: 0.16717992578875662!\n",
      "Avg loss: 0.16707190784964648!\n",
      "Avg loss: 0.1675000386399309!\n",
      "Avg loss: 0.166039904259657!\n",
      "Avg loss: 0.16656477891973434!\n",
      "Avg loss: 0.16676949425866042!\n",
      "Avg loss: 0.16623184844315497!\n",
      "Avg loss: 0.16607692531717475!\n",
      "Avg loss: 0.16605362080893732!\n",
      "Avg loss: 0.16617758290884013!\n",
      "Avg loss: 0.16570356228129943!\n",
      "Avg loss: 0.16594293980302305!\n",
      "Avg loss: 0.16590631269792236!\n",
      "Avg loss: 0.16572754103736315!\n",
      "Avg loss: 0.16565606485557813!\n",
      "Avg loss: 0.16582206132243907!\n",
      "Avg loss: 0.16550911418209277!\n",
      "Avg loss: 0.16563908206905278!\n",
      "Avg loss: 0.1655548290536702!\n",
      "Avg loss: 0.1654933799867437!\n",
      "Avg loss: 0.1654297244581706!\n",
      "Avg loss: 0.16558444615146073!\n",
      "Avg loss: 0.16536469985617563!\n",
      "Avg loss: 0.16552265183208267!\n",
      "Avg loss: 0.16533804540002772!\n",
      "Avg loss: 0.1654448851025245!\n",
      "Avg loss: 0.16535095732615748!\n",
      "Avg loss: 0.16540979011319148!\n",
      "Avg loss: 0.16526800576995812!\n",
      "Avg loss: 0.16540320478234813!\n",
      "Avg loss: 0.16528120916581732!\n",
      "Avg loss: 0.16532443406045785!\n",
      "Avg loss: 0.1652457202668529!\n",
      "Avg loss: 0.16527893757956613!\n",
      "Avg loss: 0.16527555316282816!\n",
      "Avg loss: 0.16525556549953763!\n",
      "Avg loss: 0.1652349485423277!\n",
      "Avg loss: 0.1651991428481051!\n",
      "Avg loss: 0.16522917588547748!\n",
      "Avg loss: 0.16518655500137128!\n",
      "Avg loss: 0.16518709730144412!\n",
      "Avg loss: 0.16515512044869182!\n",
      "Avg loss: 0.16518167736614486!\n",
      "Avg loss: 0.1651794253379573!\n",
      "Avg loss: 0.16514729280610557!\n",
      "Avg loss: 0.16518008129528503!\n",
      "Avg loss: 0.16515747680670378!\n",
      "Avg loss: 0.1651509874366684!\n",
      "Avg loss: 0.16510516040154016!\n",
      "Avg loss: 0.16508876522294713!\n",
      "Avg loss: 0.16511913115548094!\n",
      "Avg loss: 0.1650964938935734!\n",
      "Avg loss: 0.16510278311200333!\n",
      "Avg loss: 0.16507163926776533!\n",
      "Avg loss: 0.1650420804097189!\n",
      "Avg loss: 0.16506912652305117!\n",
      "Avg loss: 0.16503751139744813!\n",
      "Avg loss: 0.16501088116530355!\n",
      "Avg loss: 0.16501997230265109!\n",
      "Avg loss: 0.16497204103469207!\n",
      "Avg loss: 0.16500802270029757!\n",
      "Avg loss: 0.16499952942657273!\n",
      "Avg loss: 0.16496512854674317!\n",
      "Avg loss: 0.16492647824115161!\n",
      "Avg loss: 0.1649402405437619!\n",
      "Avg loss: 0.1649043940629781!\n",
      "Avg loss: 0.1648854061187664!\n",
      "Avg loss: 0.16494092129331572!\n",
      "Avg loss: 0.16492613439522605!\n",
      "Avg loss: 0.1649047651838911!\n",
      "Avg loss: 0.164878900118368!\n",
      "Avg loss: 0.1649277858875227!\n",
      "Avg loss: 0.16491744142604375!\n",
      "Avg loss: 0.1649907854766343!\n",
      "Avg loss: 0.16499326049394009!\n",
      "Avg loss: 0.16493374334723437!\n",
      "Avg loss: 0.16490920954734367!\n",
      "Avg loss: 0.16494346111431696!\n",
      "Avg loss: 0.1648762794560677!\n",
      "Avg loss: 0.16483698158854318!\n",
      "Avg loss: 0.16490249704880322!\n",
      "Avg loss: 0.16492157460297222!\n",
      "Avg loss: 0.16483526539446833!\n",
      "Avg loss: 0.16482790683024404!\n",
      "Avg loss: 0.16490457226391414!\n",
      "Avg loss: 0.16491047186665658!\n",
      "Avg loss: 0.16481526384870523!\n",
      "Avg loss: 0.1648164496445103!\n",
      "Avg loss: 0.1648771351076376!\n",
      "Avg loss: 0.1649122856082378!\n",
      "Avg loss: 0.1648499050650263!\n",
      "Avg loss: 0.16484022725595043!\n",
      "Avg loss: 0.1649085774267659!\n",
      "Avg loss: 0.16488420450953697!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.02e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 382       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 5         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.02e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 352       |\n",
      "|    iterations             | 2         |\n",
      "|    time_elapsed           | 11        |\n",
      "|    total_timesteps        | 4096      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 3.34e-05  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00872   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 25        |\n",
      "|    policy_objective       | 0.00664   |\n",
      "|    std                    | 0.86      |\n",
      "|    value_loss             | 1.83e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.03e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 352       |\n",
      "|    iterations             | 3         |\n",
      "|    time_elapsed           | 17        |\n",
      "|    total_timesteps        | 6144      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -7.15e-07 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00579   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 26        |\n",
      "|    policy_objective       | 0.00907   |\n",
      "|    std                    | 0.838     |\n",
      "|    value_loss             | 1.76e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.01e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 353       |\n",
      "|    iterations             | 4         |\n",
      "|    time_elapsed           | 23        |\n",
      "|    total_timesteps        | 8192      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 1.5e-05   |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00986   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 27        |\n",
      "|    policy_objective       | 0.00796   |\n",
      "|    std                    | 0.801     |\n",
      "|    value_loss             | 2.2e+03   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.01e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 348       |\n",
      "|    iterations             | 5         |\n",
      "|    time_elapsed           | 29        |\n",
      "|    total_timesteps        | 10240     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 1.23e-05  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00664   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 28        |\n",
      "|    policy_objective       | 0.0116    |\n",
      "|    std                    | 0.78      |\n",
      "|    value_loss             | 1.44e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.01e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 350       |\n",
      "|    iterations             | 6         |\n",
      "|    time_elapsed           | 35        |\n",
      "|    total_timesteps        | 12288     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 9.72e-06  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00615   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 29        |\n",
      "|    policy_objective       | 0.00716   |\n",
      "|    std                    | 0.761     |\n",
      "|    value_loss             | 1.55e+03  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.01e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 350       |\n",
      "|    iterations             | 7         |\n",
      "|    time_elapsed           | 40        |\n",
      "|    total_timesteps        | 14336     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -1.1e-05  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00495   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 30        |\n",
      "|    policy_objective       | 0.00934   |\n",
      "|    std                    | 0.774     |\n",
      "|    value_loss             | 1.48e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.02e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 349       |\n",
      "|    iterations             | 8         |\n",
      "|    time_elapsed           | 46        |\n",
      "|    total_timesteps        | 16384     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 2.8e-06   |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00649   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 31        |\n",
      "|    policy_objective       | 0.00872   |\n",
      "|    std                    | 0.738     |\n",
      "|    value_loss             | 1.6e+03   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1126.5493662536144\n",
      "------------------------------\n",
      "round: 4\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.009991101540642073!\n",
      "Avg loss: 0.0023528850590658597!\n",
      "Avg loss: 0.004359021072014002!\n",
      "Avg loss: 0.008585107101098402!\n",
      "Avg loss: 0.005926899896670269!\n",
      "Avg loss: 0.0035123391749948495!\n",
      "Avg loss: 0.0038919977982974766!\n",
      "Avg loss: 0.006058044485798746!\n",
      "Avg loss: 0.006198889290632602!\n",
      "Avg loss: 0.004616945587101024!\n",
      "Avg loss: 0.004219700316704499!\n",
      "Avg loss: 0.0049035749223730815!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.013727035904448712!\n",
      "Avg loss: 0.013734596206377318!\n",
      "Avg loss: 0.006057380173782197!\n",
      "Avg loss: 0.004869298914957957!\n",
      "Avg loss: 0.009247097374585185!\n",
      "Avg loss: 0.005402114289014813!\n",
      "Avg loss: 0.003244352648810794!\n",
      "Avg loss: 0.0036176234932281657!\n",
      "Avg loss: 0.005487214900519272!\n",
      "Avg loss: 0.0033476310387747315!\n",
      "Avg loss: 0.0027795328909572467!\n",
      "Avg loss: 0.0037546656179983985!\n",
      "Avg loss: 0.004120575644453008!\n",
      "Avg loss: 0.002934298696712479!\n",
      "Avg loss: 0.0027585740907185635!\n",
      "Avg loss: 0.003458154906005196!\n",
      "Avg loss: 0.003330669857144433!\n",
      "Avg loss: 0.002775891963237124!\n",
      "Avg loss: 0.002902312343515708!\n",
      "Avg loss: 0.0031435500221111095!\n",
      "Avg loss: 0.002827758979118092!\n",
      "Avg loss: 0.002742199861681911!\n",
      "Avg loss: 0.0029230859953402917!\n",
      "Avg loss: 0.0027548908531188467!\n",
      "Avg loss: 0.002599743385731017!\n",
      "Avg loss: 0.0027148940263289965!\n",
      "Avg loss: 0.0026919415901511456!\n",
      "Avg loss: 0.002557848007678937!\n",
      "Avg loss: 0.0025056741342996246!\n",
      "Avg loss: 0.0025916886707652033!\n",
      "Avg loss: 0.0026215611785467747!\n",
      "Avg loss: 0.00252315524767558!\n",
      "Avg loss: 0.0025334366957243523!\n",
      "Avg loss: 0.0024396876892872872!\n",
      "Avg loss: 0.0024050412102375653!\n",
      "Avg loss: 0.002512249736795032!\n",
      "Avg loss: 0.002472466695852139!\n",
      "Avg loss: 0.002501147790618082!\n",
      "Avg loss: 0.0024242614755985415!\n",
      "Avg loss: 0.002444645964844767!\n",
      "Avg loss: 0.002514822885262523!\n",
      "Avg loss: 0.0024436313078437404!\n",
      "Avg loss: 0.0023615431164216716!\n",
      "Avg loss: 0.0024025995223867845!\n",
      "Avg loss: 0.0022853664296872012!\n",
      "Avg loss: 0.002450773025119209!\n",
      "Avg loss: 0.00248475549608429!\n",
      "Avg loss: 0.0023244431121399126!\n",
      "Avg loss: 0.002429605319524247!\n",
      "Avg loss: 0.002367945473965847!\n",
      "Avg loss: 0.0024209035866048605!\n",
      "Avg loss: 0.0025428201086318343!\n",
      "Avg loss: 0.002396077121511553!\n",
      "Avg loss: 0.002428110382406885!\n",
      "Avg loss: 0.0023926625959438752!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.27494251600592784!\n",
      "Avg loss: 0.27097721565146154!\n",
      "Avg loss: 0.25605053587098764!\n",
      "Avg loss: 0.2580805366230743!\n",
      "Avg loss: 0.2711078092865743!\n",
      "Avg loss: 0.26077069157344035!\n",
      "Avg loss: 0.25470285241729773!\n",
      "Avg loss: 0.2582302063007743!\n",
      "Avg loss: 0.26459472553226077!\n",
      "Avg loss: 0.2588007882854693!\n",
      "Avg loss: 0.2568402988692681!\n",
      "Avg loss: 0.2611404721322966!\n",
      "Avg loss: 0.26214244978826173!\n",
      "Avg loss: 0.2583411372934794!\n",
      "Avg loss: 0.2588983583785254!\n",
      "Avg loss: 0.26131023747419024!\n",
      "Avg loss: 0.25946498513709987!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -988     |\n",
      "| time/              |          |\n",
      "|    fps             | 384      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -978     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 382      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 10       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 8.23e-06 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0077   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 33       |\n",
      "|    policy_objective       | 0.0138   |\n",
      "|    std                    | 0.725    |\n",
      "|    value_loss             | 1.07e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -984     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 372      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 16       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 1.04e-05 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00683  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 34       |\n",
      "|    policy_objective       | 0.0147   |\n",
      "|    std                    | 0.706    |\n",
      "|    value_loss             | 944      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -985     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 370      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 22       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 9.18e-06 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00999  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 35       |\n",
      "|    policy_objective       | 0.00978  |\n",
      "|    std                    | 0.696    |\n",
      "|    value_loss             | 1.05e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -973     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 370      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 27       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 6.74e-06 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00765  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 36       |\n",
      "|    policy_objective       | 0.0104   |\n",
      "|    std                    | 0.713    |\n",
      "|    value_loss             | 869      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -964     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 369      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 33       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 1.35e-05 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00675  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 37       |\n",
      "|    policy_objective       | 0.0121   |\n",
      "|    std                    | 0.702    |\n",
      "|    value_loss             | 796      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -971     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 369      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 38       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 1.73e-06 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00517  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 38       |\n",
      "|    policy_objective       | 0.00828  |\n",
      "|    std                    | 0.699    |\n",
      "|    value_loss             | 665      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -978     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 369      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 44       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 6.74e-06 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00945  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 39       |\n",
      "|    policy_objective       | 0.0146   |\n",
      "|    std                    | 0.739    |\n",
      "|    value_loss             | 1.07e+03 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1142.3008359141647\n",
      "------------------------------\n",
      "round: 5\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.0499108149697228!\n",
      "Avg loss: 0.04813748634031072!\n",
      "Avg loss: 0.051862983946155815!\n",
      "Avg loss: 0.04701341919346305!\n",
      "Avg loss: 0.04825683764189307!\n",
      "Avg loss: 0.0479135777943399!\n",
      "Avg loss: 0.0481203679110331!\n",
      "Avg loss: 0.046983335471437994!\n",
      "Avg loss: 0.04791914197370109!\n",
      "Avg loss: 0.04743778847231321!\n",
      "Avg loss: 0.047343134480518835!\n",
      "Avg loss: 0.04761655584172937!\n",
      "Avg loss: 0.04727557324219257!\n",
      "Avg loss: 0.04721976918111371!\n",
      "Avg loss: 0.04732324165794125!\n",
      "Avg loss: 0.0471144146883186!\n",
      "Avg loss: 0.04711599996463822!\n",
      "Avg loss: 0.04714602555027037!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.1323634121505408!\n",
      "Avg loss: 0.13192354168639212!\n",
      "Avg loss: 0.14278564000395513!\n",
      "Avg loss: 0.13551677178499327!\n",
      "Avg loss: 0.13262570529914836!\n",
      "Avg loss: 0.13303395645389704!\n",
      "Avg loss: 0.13784535979907864!\n",
      "Avg loss: 0.13378749619843197!\n",
      "Avg loss: 0.13185960188051013!\n",
      "Avg loss: 0.13290289281731626!\n",
      "Avg loss: 0.1350441290131918!\n",
      "Avg loss: 0.13283328301458217!\n",
      "Avg loss: 0.13208328931922855!\n",
      "Avg loss: 0.13348239458474004!\n",
      "Avg loss: 0.13360293090388192!\n",
      "Avg loss: 0.13225081017548596!\n",
      "Avg loss: 0.13244725974768548!\n",
      "Avg loss: 0.13334724384978774!\n",
      "Avg loss: 0.13277349314301926!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0036729902834243453!\n",
      "Avg loss: 0.00302397112721034!\n",
      "Avg loss: 0.008178171366428918!\n",
      "Avg loss: 0.0029381337680964253!\n",
      "Avg loss: 0.003153383867508334!\n",
      "Avg loss: 0.005003388397276467!\n",
      "Avg loss: 0.004893233680359117!\n",
      "Avg loss: 0.0033321730534468467!\n",
      "Avg loss: 0.0039039411110510023!\n",
      "Avg loss: 0.00493083175410599!\n",
      "Avg loss: 0.004115249562958828!\n",
      "Avg loss: 0.004007934360561194!\n",
      "Avg loss: 0.004878561325376722!\n",
      "Avg loss: 0.00475835792803385!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.01e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 372       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 5         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.01e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 346       |\n",
      "|    iterations             | 2         |\n",
      "|    time_elapsed           | 11        |\n",
      "|    total_timesteps        | 4096      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 2.44e-06  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00805   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 41        |\n",
      "|    policy_objective       | 0.00929   |\n",
      "|    std                    | 0.759     |\n",
      "|    value_loss             | 820       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -993     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 342      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 4.41e-06 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00738  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 42       |\n",
      "|    policy_objective       | 0.011    |\n",
      "|    std                    | 0.75     |\n",
      "|    value_loss             | 1.01e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -998     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 335      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 24       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 6.5e-06  |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00891  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 43       |\n",
      "|    policy_objective       | 0.0116   |\n",
      "|    std                    | 0.718    |\n",
      "|    value_loss             | 729      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -992     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 334      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 30       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 1.79e-06 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00557  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 44       |\n",
      "|    policy_objective       | 0.0112   |\n",
      "|    std                    | 0.698    |\n",
      "|    value_loss             | 792      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -985     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 334      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 36       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 2.03e-06 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00517  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 45       |\n",
      "|    policy_objective       | 0.0102   |\n",
      "|    std                    | 0.706    |\n",
      "|    value_loss             | 618      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -981     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 338      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 42       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 1.91e-06 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00584  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 46       |\n",
      "|    policy_objective       | 0.0101   |\n",
      "|    std                    | 0.684    |\n",
      "|    value_loss             | 789      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -981     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 339      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 48       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 4.77e-07 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00859  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 47       |\n",
      "|    policy_objective       | 0.0115   |\n",
      "|    std                    | 0.677    |\n",
      "|    value_loss             | 849      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1095.7273782581092\n",
      "------------------------------\n",
      "round: 6\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.0050675059112836604!\n",
      "Avg loss: 0.005986756579404755!\n",
      "Avg loss: 0.003971439682451698!\n",
      "Avg loss: 0.0029047839202879307!\n",
      "Avg loss: 0.005543308122481297!\n",
      "Avg loss: 0.0037737169814742325!\n",
      "Avg loss: 0.0029607450207307312!\n",
      "Avg loss: 0.0027131790677716104!\n",
      "Avg loss: 0.0038297942307447858!\n",
      "Avg loss: 0.0034663595476680104!\n",
      "Avg loss: 0.002861779459429575!\n",
      "Avg loss: 0.002890797284138292!\n",
      "Avg loss: 0.003544277207329287!\n",
      "Avg loss: 0.002974836674754139!\n",
      "Avg loss: 0.0027579818621961748!\n",
      "Avg loss: 0.002992909755130313!\n",
      "Avg loss: 0.003136406140680871!\n",
      "Avg loss: 0.002887586079329291!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.010792828941678939!\n",
      "Avg loss: 0.007445375104871346!\n",
      "Avg loss: 0.007977934902301058!\n",
      "Avg loss: 0.003695523758651689!\n",
      "Avg loss: 0.003841831229995781!\n",
      "Avg loss: 0.00491855194986177!\n",
      "Avg loss: 0.00393740349016601!\n",
      "Avg loss: 0.0037215578003088013!\n",
      "Avg loss: 0.003397481470662266!\n",
      "Avg loss: 0.004398284154303838!\n",
      "Avg loss: 0.0034555653597271884!\n",
      "Avg loss: 0.003180831445364068!\n",
      "Avg loss: 0.003948263752345155!\n",
      "Avg loss: 0.0037803060420446856!\n",
      "Avg loss: 0.0034690493661279713!\n",
      "Avg loss: 0.0037734044161394802!\n",
      "Avg loss: 0.003767198407567776!\n",
      "Avg loss: 0.0035669855806857716!\n",
      "Avg loss: 0.0036886923227151176!\n",
      "Avg loss: 0.003886869404339753!\n",
      "Avg loss: 0.0038562953343595535!\n",
      "Avg loss: 0.0037624225551191634!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.12939250301317468!\n",
      "Avg loss: 0.12606474033816387!\n",
      "Avg loss: 0.13124039815404104!\n",
      "Avg loss: 0.1253518103656279!\n",
      "Avg loss: 0.12541080679404937!\n",
      "Avg loss: 0.12673403585988732!\n",
      "Avg loss: 0.12612809916039017!\n",
      "Avg loss: 0.12479790270771748!\n",
      "Avg loss: 0.1263433826559837!\n",
      "Avg loss: 0.12615766191501887!\n",
      "Avg loss: 0.12514805666744602!\n",
      "Avg loss: 0.12579609567066655!\n",
      "Avg loss: 0.12629086356895033!\n",
      "Avg loss: 0.12519207691420245!\n",
      "Avg loss: 0.12604778326663865!\n",
      "Avg loss: 0.12579291101844925!\n",
      "Avg loss: 0.12542733089802824!\n",
      "Avg loss: 0.12544118535000356!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -910     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -933     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 343      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 11       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 2.8e-06  |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00674  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 49       |\n",
      "|    policy_objective       | 0.00904  |\n",
      "|    std                    | 0.675    |\n",
      "|    value_loss             | 514      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -958     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 342      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 2.26e-06 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00974  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 50       |\n",
      "|    policy_objective       | 0.00824  |\n",
      "|    std                    | 0.687    |\n",
      "|    value_loss             | 499      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -962     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 351      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 23       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 3.28e-06 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00776  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 51       |\n",
      "|    policy_objective       | 0.00874  |\n",
      "|    std                    | 0.67     |\n",
      "|    value_loss             | 933      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -953     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 347      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 29       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 3.34e-06 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00841  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 52       |\n",
      "|    policy_objective       | 0.0109   |\n",
      "|    std                    | 0.664    |\n",
      "|    value_loss             | 670      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -942      |\n",
      "| time/                     |           |\n",
      "|    fps                    | 349       |\n",
      "|    iterations             | 6         |\n",
      "|    time_elapsed           | 35        |\n",
      "|    total_timesteps        | 12288     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -7.15e-07 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00614   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 53        |\n",
      "|    policy_objective       | 0.0123    |\n",
      "|    std                    | 0.672     |\n",
      "|    value_loss             | 449       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -940     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 353      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 40       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 3.93e-06 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00775  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 54       |\n",
      "|    policy_objective       | 0.0113   |\n",
      "|    std                    | 0.659    |\n",
      "|    value_loss             | 421      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -944     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 354      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 46       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 5.07e-06 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00585  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 55       |\n",
      "|    policy_objective       | 0.0086   |\n",
      "|    std                    | 0.63     |\n",
      "|    value_loss             | 692      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1022.6560384841636\n",
      "------------------------------\n",
      "round: 7\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.005259376554725653!\n",
      "Avg loss: 0.003034152673280914!\n",
      "Avg loss: 0.005268055121705402!\n",
      "Avg loss: 0.0027004986609487484!\n",
      "Avg loss: 0.0034987571225125673!\n",
      "Avg loss: 0.0020378075984687407!\n",
      "Avg loss: 0.003251292070975372!\n",
      "Avg loss: 0.0021852122948682034!\n",
      "Avg loss: 0.0025097840183661902!\n",
      "Avg loss: 0.0022383992202230727!\n",
      "Avg loss: 0.0024318222595259916!\n",
      "Avg loss: 0.00210106112704428!\n",
      "Avg loss: 0.002267907666634225!\n",
      "Avg loss: 0.0022800786177352467!\n",
      "Avg loss: 0.0021445172311238517!\n",
      "Avg loss: 0.002236195196743438!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.0030630467683658933!\n",
      "Avg loss: 0.0024966324371416704!\n",
      "Avg loss: 0.004897893477900653!\n",
      "Avg loss: 0.004101042602487723!\n",
      "Avg loss: 0.002013695229761652!\n",
      "Avg loss: 0.0021178682658804368!\n",
      "Avg loss: 0.003220096918069733!\n",
      "Avg loss: 0.0031343683070736007!\n",
      "Avg loss: 0.0023454766972099608!\n",
      "Avg loss: 0.002446731722587477!\n",
      "Avg loss: 0.002603517382109809!\n",
      "Avg loss: 0.0027370554258717068!\n",
      "Avg loss: 0.002491143624556571!\n",
      "Avg loss: 0.002518313167741629!\n",
      "Avg loss: 0.002545846043264343!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.19549615929931558!\n",
      "Avg loss: 0.19381375795288477!\n",
      "Avg loss: 0.1997885751580058!\n",
      "Avg loss: 0.19498828602088905!\n",
      "Avg loss: 0.19436480879065735!\n",
      "Avg loss: 0.19582774915913737!\n",
      "Avg loss: 0.1972800103677461!\n",
      "Avg loss: 0.1961192383456364!\n",
      "Avg loss: 0.1954161127016596!\n",
      "Avg loss: 0.19643948556544275!\n",
      "Avg loss: 0.19682012247732322!\n",
      "Avg loss: 0.1961563402310761!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -993     |\n",
      "| time/              |          |\n",
      "|    fps             | 386      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -954     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 331      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 12       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 9.06e-06 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00792  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 57       |\n",
      "|    policy_objective       | 0.0136   |\n",
      "|    std                    | 0.626    |\n",
      "|    value_loss             | 488      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -949      |\n",
      "| time/                     |           |\n",
      "|    fps                    | 334       |\n",
      "|    iterations             | 3         |\n",
      "|    time_elapsed           | 18        |\n",
      "|    total_timesteps        | 6144      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -1.31e-06 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.007     |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 58        |\n",
      "|    policy_objective       | 0.0109    |\n",
      "|    std                    | 0.607     |\n",
      "|    value_loss             | 676       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -958     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 333      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 24       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 1.52e-05 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00808  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 59       |\n",
      "|    policy_objective       | 0.0109   |\n",
      "|    std                    | 0.58     |\n",
      "|    value_loss             | 388      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -967     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 330      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 30       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | -0.0437  |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00804  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 60       |\n",
      "|    policy_objective       | 0.0128   |\n",
      "|    std                    | 0.6      |\n",
      "|    value_loss             | 881      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -966     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 326      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 37       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 7.33e-05 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00657  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 61       |\n",
      "|    policy_objective       | 0.01     |\n",
      "|    std                    | 0.582    |\n",
      "|    value_loss             | 573      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -948     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 330      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 43       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 9.33e-05 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00676  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 62       |\n",
      "|    policy_objective       | 0.0168   |\n",
      "|    std                    | 0.6      |\n",
      "|    value_loss             | 546      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -952     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 325      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 50       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.000134 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00725  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 63       |\n",
      "|    policy_objective       | 0.01     |\n",
      "|    std                    | 0.61     |\n",
      "|    value_loss             | 766      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1020.4520503315958\n",
      "------------------------------\n",
      "round: 8\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.17242476063751383!\n",
      "Avg loss: 0.16829496057682264!\n",
      "Avg loss: 0.17739168899463645!\n",
      "Avg loss: 0.1732916169846673!\n",
      "Avg loss: 0.16791130539689522!\n",
      "Avg loss: 0.1682524582074287!\n",
      "Avg loss: 0.17112923449099982!\n",
      "Avg loss: 0.17106371217112004!\n",
      "Avg loss: 0.16808926704564026!\n",
      "Avg loss: 0.16874493147140887!\n",
      "Avg loss: 0.170227430347821!\n",
      "Avg loss: 0.17028857337156902!\n",
      "Avg loss: 0.16919656020688612!\n",
      "Avg loss: 0.1693425441270271!\n",
      "Avg loss: 0.17006859540211886!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.10890450232778676!\n",
      "Avg loss: 0.09929357118421953!\n",
      "Avg loss: 0.10243792172254568!\n",
      "Avg loss: 0.10071307512972756!\n",
      "Avg loss: 0.10213453028777925!\n",
      "Avg loss: 0.09985272162291342!\n",
      "Avg loss: 0.09958882458316415!\n",
      "Avg loss: 0.10085328080031711!\n",
      "Avg loss: 0.0997370120240521!\n",
      "Avg loss: 0.0992850353111794!\n",
      "Avg loss: 0.099267377435602!\n",
      "Avg loss: 0.09998131395926672!\n",
      "Avg loss: 0.09939178301614675!\n",
      "Avg loss: 0.0993821345826988!\n",
      "Avg loss: 0.10000156426588547!\n",
      "Avg loss: 0.09970272174788306!\n",
      "Avg loss: 0.0995027944425874!\n",
      "Avg loss: 0.09971164058163595!\n",
      "Avg loss: 0.09979632782262267!\n",
      "Avg loss: 0.0995890346528798!\n",
      "Avg loss: 0.0997145477496315!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0034603912239981583!\n",
      "Avg loss: 0.003685337018523569!\n",
      "Avg loss: 0.005568102768538665!\n",
      "Avg loss: 0.004281358981315862!\n",
      "Avg loss: 0.0033034808952894915!\n",
      "Avg loss: 0.0030197320017638653!\n",
      "Avg loss: 0.004396567757163817!\n",
      "Avg loss: 0.0038577686695255883!\n",
      "Avg loss: 0.003268614742507149!\n",
      "Avg loss: 0.00322677673219611!\n",
      "Avg loss: 0.003953698985436252!\n",
      "Avg loss: 0.0035154986038105564!\n",
      "Avg loss: 0.0033089661841889514!\n",
      "Avg loss: 0.0035281014294772225!\n",
      "Avg loss: 0.0039052280683851376!\n",
      "Avg loss: 0.0037592728984282074!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -897     |\n",
      "| time/              |          |\n",
      "|    fps             | 340      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -879     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 343      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 11       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.142    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00667  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 65       |\n",
      "|    policy_objective       | 0.0133   |\n",
      "|    std                    | 0.592    |\n",
      "|    value_loss             | 469      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -903     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 352      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.415    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00738  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 66       |\n",
      "|    policy_objective       | 0.0136   |\n",
      "|    std                    | 0.595    |\n",
      "|    value_loss             | 456      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -887     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 352      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 23       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.478    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00945  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 67       |\n",
      "|    policy_objective       | 0.013    |\n",
      "|    std                    | 0.583    |\n",
      "|    value_loss             | 540      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -937     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 354      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 28       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.621    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00635  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 68       |\n",
      "|    policy_objective       | 0.0139   |\n",
      "|    std                    | 0.599    |\n",
      "|    value_loss             | 383      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -952     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 357      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 34       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | -0.214   |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00897  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 69       |\n",
      "|    policy_objective       | 0.0101   |\n",
      "|    std                    | 0.612    |\n",
      "|    value_loss             | 384      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -970     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 356      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 40       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.192    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00815  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 70       |\n",
      "|    policy_objective       | 0.0137   |\n",
      "|    std                    | 0.619    |\n",
      "|    value_loss             | 409      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -964     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 358      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 45       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.549    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00701  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 71       |\n",
      "|    policy_objective       | 0.0113   |\n",
      "|    std                    | 0.593    |\n",
      "|    value_loss             | 581      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1029.3009487275035\n",
      "------------------------------\n",
      "round: 9\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.2431542877231065!\n",
      "Avg loss: 0.24000696286138312!\n",
      "Avg loss: 0.23054179640896716!\n",
      "Avg loss: 0.2339604713061999!\n",
      "Avg loss: 0.2414405180605172!\n",
      "Avg loss: 0.23375023199053732!\n",
      "Avg loss: 0.23217269447801905!\n",
      "Avg loss: 0.2371032289016633!\n",
      "Avg loss: 0.23700928439518368!\n",
      "Avg loss: 0.23308301002051546!\n",
      "Avg loss: 0.23470196753581754!\n",
      "Avg loss: 0.2368432907180492!\n",
      "Avg loss: 0.2342056244334314!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.11006164325150167!\n",
      "Avg loss: 0.11432497401496221!\n",
      "Avg loss: 0.12174957427237434!\n",
      "Avg loss: 0.11213023792336116!\n",
      "Avg loss: 0.11075206601145814!\n",
      "Avg loss: 0.11677014032969359!\n",
      "Avg loss: 0.11451520024737268!\n",
      "Avg loss: 0.11053886185773384!\n",
      "Avg loss: 0.11243682674483656!\n",
      "Avg loss: 0.11543119225234628!\n",
      "Avg loss: 0.1129111437556215!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.05927252690986885!\n",
      "Avg loss: 0.053052028179590704!\n",
      "Avg loss: 0.05635388848361496!\n",
      "Avg loss: 0.05373985698497563!\n",
      "Avg loss: 0.05471968159542788!\n",
      "Avg loss: 0.052827361977450284!\n",
      "Avg loss: 0.05316044915872529!\n",
      "Avg loss: 0.053570387622288156!\n",
      "Avg loss: 0.052877716028090924!\n",
      "Avg loss: 0.052547760997267684!\n",
      "Avg loss: 0.05304606078028276!\n",
      "Avg loss: 0.05270786950219796!\n",
      "Avg loss: 0.05267158545170181!\n",
      "Avg loss: 0.05261018928677004!\n",
      "Avg loss: 0.052834595310359875!\n",
      "Avg loss: 0.052446062500143095!\n",
      "Avg loss: 0.052555431603152174!\n",
      "Avg loss: 0.05268407359316295!\n",
      "Avg loss: 0.05247976255851597!\n",
      "Avg loss: 0.05248919597535254!\n",
      "Avg loss: 0.05263340596773029!\n",
      "Avg loss: 0.052550890283961656!\n",
      "Avg loss: 0.05254792157249843!\n",
      "Avg loss: 0.05267134490818686!\n",
      "Avg loss: 0.05246570830630769!\n",
      "Avg loss: 0.052607245716022814!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.04e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 416       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 4         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -950     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 397      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 10       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.696    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00732  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 73       |\n",
      "|    policy_objective       | 0.01     |\n",
      "|    std                    | 0.578    |\n",
      "|    value_loss             | 307      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -933     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 389      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 15       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.581    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00912  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 74       |\n",
      "|    policy_objective       | 0.0189   |\n",
      "|    std                    | 0.583    |\n",
      "|    value_loss             | 317      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -883     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 377      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 21       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.743    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00848  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 75       |\n",
      "|    policy_objective       | 0.016    |\n",
      "|    std                    | 0.565    |\n",
      "|    value_loss             | 391      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -882     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 374      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 27       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.762    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00773  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 76       |\n",
      "|    policy_objective       | 0.0204   |\n",
      "|    std                    | 0.574    |\n",
      "|    value_loss             | 328      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -875     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 358      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 34       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.723    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00607  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 77       |\n",
      "|    policy_objective       | 0.0106   |\n",
      "|    std                    | 0.572    |\n",
      "|    value_loss             | 439      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -859     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 341      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 41       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.826    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00784  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 78       |\n",
      "|    policy_objective       | 0.0143   |\n",
      "|    std                    | 0.57     |\n",
      "|    value_loss             | 284      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -864     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 330      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 49       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.745    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00962  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 79       |\n",
      "|    policy_objective       | 0.0115   |\n",
      "|    std                    | 0.581    |\n",
      "|    value_loss             | 576      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-871.6724438581557\n",
      "------------------------------\n",
      "round: 10\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.05470757217437495!\n",
      "Avg loss: 0.05627352830426995!\n",
      "Avg loss: 0.05493397419227525!\n",
      "Avg loss: 0.055231456938211826!\n",
      "Avg loss: 0.05436321891545958!\n",
      "Avg loss: 0.054955451802670724!\n",
      "Avg loss: 0.053686688085351764!\n",
      "Avg loss: 0.05393445657854803!\n",
      "Avg loss: 0.05352991520293168!\n",
      "Avg loss: 0.05368410542282921!\n",
      "Avg loss: 0.0533523303852174!\n",
      "Avg loss: 0.053116783270779705!\n",
      "Avg loss: 0.05297077568979148!\n",
      "Avg loss: 0.05288250386607312!\n",
      "Avg loss: 0.05285149769768964!\n",
      "Avg loss: 0.052773759373767465!\n",
      "Avg loss: 0.05278365434099063!\n",
      "Avg loss: 0.052731690818757976!\n",
      "Avg loss: 0.05267730394404225!\n",
      "Avg loss: 0.05260481536320034!\n",
      "Avg loss: 0.05263871326355381!\n",
      "Avg loss: 0.05274371925715457!\n",
      "Avg loss: 0.052785305508058024!\n",
      "Avg loss: 0.05273004563247544!\n",
      "Avg loss: 0.05270445368809305!\n",
      "Avg loss: 0.052688745575361885!\n",
      "Avg loss: 0.05264217835047551!\n",
      "Avg loss: 0.05261450193183407!\n",
      "Avg loss: 0.05262124616165693!\n",
      "Avg loss: 0.05264752458396894!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.1916691594973478!\n",
      "Avg loss: 0.19188354300463592!\n",
      "Avg loss: 0.20111298017560936!\n",
      "Avg loss: 0.1927510151498912!\n",
      "Avg loss: 0.1913375212666324!\n",
      "Avg loss: 0.1963544967991341!\n",
      "Avg loss: 0.19469304911928817!\n",
      "Avg loss: 0.19189738507973364!\n",
      "Avg loss: 0.19402758815980026!\n",
      "Avg loss: 0.1952678372443946!\n",
      "Avg loss: 0.1922076401240641!\n",
      "Avg loss: 0.19240020991487805!\n",
      "Avg loss: 0.19449910715294208!\n",
      "Avg loss: 0.19327316083131033!\n",
      "Avg loss: 0.19261346735385512!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0038242567665171616!\n",
      "Avg loss: 0.0029411453154110255!\n",
      "Avg loss: 0.0016573573228379245!\n",
      "Avg loss: 0.0014867063901677587!\n",
      "Avg loss: 0.0017928200443202513!\n",
      "Avg loss: 0.0019652188264687237!\n",
      "Avg loss: 0.00085711386842983!\n",
      "Avg loss: 0.001187748540554215!\n",
      "Avg loss: 0.0008076155526108172!\n",
      "Avg loss: 0.0012126413558750451!\n",
      "Avg loss: 0.0009048063615364299!\n",
      "Avg loss: 0.0007287915490367899!\n",
      "Avg loss: 0.0006889774839449577!\n",
      "Avg loss: 0.0009166384957385768!\n",
      "Avg loss: 0.0008255492659114339!\n",
      "Avg loss: 0.0006908133987781185!\n",
      "Avg loss: 0.0007296407487289495!\n",
      "Avg loss: 0.0008261306896656606!\n",
      "Avg loss: 0.0008057163536780838!\n",
      "Avg loss: 0.0007573411999843908!\n",
      "Avg loss: 0.0007569693906822294!\n",
      "Avg loss: 0.0007801347673785131!\n",
      "Avg loss: 0.0007585687373375549!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -814     |\n",
      "| time/              |          |\n",
      "|    fps             | 345      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -756     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 359      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 11       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.763    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00606  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 81       |\n",
      "|    policy_objective       | 0.0121   |\n",
      "|    std                    | 0.564    |\n",
      "|    value_loss             | 364      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -776     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 344      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.808    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00788  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 82       |\n",
      "|    policy_objective       | 0.0133   |\n",
      "|    std                    | 0.58     |\n",
      "|    value_loss             | 452      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -796     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 328      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 24       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.778    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00783  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 83       |\n",
      "|    policy_objective       | 0.0176   |\n",
      "|    std                    | 0.555    |\n",
      "|    value_loss             | 248      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -789     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 331      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 30       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.838    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0049   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 84       |\n",
      "|    policy_objective       | 0.00737  |\n",
      "|    std                    | 0.546    |\n",
      "|    value_loss             | 369      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -785     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 326      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 37       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.765    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00647  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 85       |\n",
      "|    policy_objective       | 0.0171   |\n",
      "|    std                    | 0.536    |\n",
      "|    value_loss             | 331      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -778     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 323      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 44       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.737    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00832  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 86       |\n",
      "|    policy_objective       | 0.0142   |\n",
      "|    std                    | 0.513    |\n",
      "|    value_loss             | 441      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -778     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 326      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 50       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.818    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00868  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 87       |\n",
      "|    policy_objective       | 0.016    |\n",
      "|    std                    | 0.527    |\n",
      "|    value_loss             | 525      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-558.7193391416222\n",
      "------------------------------\n",
      "round: 11\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.03171844042449569!\n",
      "Avg loss: 0.03233653821589542!\n",
      "Avg loss: 0.031778455290962786!\n",
      "Avg loss: 0.03160091962691998!\n",
      "Avg loss: 0.031815146347325934!\n",
      "Avg loss: 0.03185568731342452!\n",
      "Avg loss: 0.031189510112092953!\n",
      "Avg loss: 0.031044901121689086!\n",
      "Avg loss: 0.030968582985507663!\n",
      "Avg loss: 0.031034849760538538!\n",
      "Avg loss: 0.030998594226227093!\n",
      "Avg loss: 0.03091512646121752!\n",
      "Avg loss: 0.030925324342624662!\n",
      "Avg loss: 0.03091784794187182!\n",
      "Avg loss: 0.030928885986010454!\n",
      "Avg loss: 0.030902504377418913!\n",
      "Avg loss: 0.0309297667228869!\n",
      "Avg loss: 0.030906897726104034!\n",
      "Avg loss: 0.030941323019898544!\n",
      "Avg loss: 0.030943417796920586!\n",
      "Avg loss: 0.03092819542995585!\n",
      "Avg loss: 0.030895171535171358!\n",
      "Avg loss: 0.03091109517496174!\n",
      "Avg loss: 0.030991483801889975!\n",
      "Avg loss: 0.030969561689513134!\n",
      "Avg loss: 0.030946514039107267!\n",
      "Avg loss: 0.030914157686595067!\n",
      "Avg loss: 0.03098192944635836!\n",
      "Avg loss: 0.031027362407809657!\n",
      "Avg loss: 0.031073193869722977!\n",
      "Avg loss: 0.031000615211640555!\n",
      "Avg loss: 0.03102339814062892!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.015609448140312452!\n",
      "Avg loss: 0.014484111507505682!\n",
      "Avg loss: 0.0136692291291547!\n",
      "Avg loss: 0.012559006550727645!\n",
      "Avg loss: 0.013935125449934275!\n",
      "Avg loss: 0.01286197086114953!\n",
      "Avg loss: 0.012811331733804157!\n",
      "Avg loss: 0.012617297950411437!\n",
      "Avg loss: 0.01323747190278785!\n",
      "Avg loss: 0.012649704649872244!\n",
      "Avg loss: 0.012703156126359924!\n",
      "Avg loss: 0.01285440790140304!\n",
      "Avg loss: 0.01309186731910207!\n",
      "Avg loss: 0.012790254397047344!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0013404669344405798!\n",
      "Avg loss: 0.0022270315106531296!\n",
      "Avg loss: 0.0013743817922841116!\n",
      "Avg loss: 0.0012642617154597247!\n",
      "Avg loss: 0.001084701866608763!\n",
      "Avg loss: 0.0013027307367641091!\n",
      "Avg loss: 0.001007319407566077!\n",
      "Avg loss: 0.0009188530659594108!\n",
      "Avg loss: 0.0007411649556585568!\n",
      "Avg loss: 0.0008419255213175347!\n",
      "Avg loss: 0.0007416942556786429!\n",
      "Avg loss: 0.000672606725741692!\n",
      "Avg loss: 0.000633757869618421!\n",
      "Avg loss: 0.0006554151384527055!\n",
      "Avg loss: 0.0006375437193870917!\n",
      "Avg loss: 0.000615892602590975!\n",
      "Avg loss: 0.0006305583078998703!\n",
      "Avg loss: 0.0006603846890660255!\n",
      "Avg loss: 0.0006512647789395487!\n",
      "Avg loss: 0.0006510536625887653!\n",
      "Avg loss: 0.0006634059140840994!\n",
      "Avg loss: 0.0006574889415249648!\n",
      "Avg loss: 0.0006597649485797774!\n",
      "Avg loss: 0.0006658757137294439!\n",
      "Avg loss: 0.0006722036439547689!\n",
      "Avg loss: 0.0006661504137093744!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -716     |\n",
      "| time/              |          |\n",
      "|    fps             | 400      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -738     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 384      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 10       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.838    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00652  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 89       |\n",
      "|    policy_objective       | 0.0112   |\n",
      "|    std                    | 0.516    |\n",
      "|    value_loss             | 384      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -778     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 380      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 16       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.836    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00763  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 90       |\n",
      "|    policy_objective       | 0.018    |\n",
      "|    std                    | 0.519    |\n",
      "|    value_loss             | 253      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -798     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 382      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 21       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.809    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00805  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 91       |\n",
      "|    policy_objective       | 0.0169   |\n",
      "|    std                    | 0.495    |\n",
      "|    value_loss             | 346      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -762     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 371      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 27       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.785    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00801  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 92       |\n",
      "|    policy_objective       | 0.0117   |\n",
      "|    std                    | 0.493    |\n",
      "|    value_loss             | 386      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -743     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 357      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 34       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.775    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0069   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 93       |\n",
      "|    policy_objective       | 0.0143   |\n",
      "|    std                    | 0.484    |\n",
      "|    value_loss             | 274      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -727     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 356      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 40       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.84     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00841  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 94       |\n",
      "|    policy_objective       | 0.015    |\n",
      "|    std                    | 0.494    |\n",
      "|    value_loss             | 209      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -734     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 354      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 46       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.784    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00812  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 95       |\n",
      "|    policy_objective       | 0.0141   |\n",
      "|    std                    | 0.488    |\n",
      "|    value_loss             | 521      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-425.7675370226032\n",
      "------------------------------\n",
      "round: 12\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.006029936587243961!\n",
      "Avg loss: 0.006606213541017496!\n",
      "Avg loss: 0.00602817701847016!\n",
      "Avg loss: 0.005859213543626538!\n",
      "Avg loss: 0.005666340176788557!\n",
      "Avg loss: 0.005672399624581885!\n",
      "Avg loss: 0.0051766633602316385!\n",
      "Avg loss: 0.005208948550040684!\n",
      "Avg loss: 0.0050405655408466525!\n",
      "Avg loss: 0.0051479638594173595!\n",
      "Avg loss: 0.004982291946352764!\n",
      "Avg loss: 0.005024522510242046!\n",
      "Avg loss: 0.005042876985245736!\n",
      "Avg loss: 0.005064151243860711!\n",
      "Avg loss: 0.0049917583190237265!\n",
      "Avg loss: 0.004990171153879525!\n",
      "Avg loss: 0.005042669266667114!\n",
      "Avg loss: 0.004996407382477628!\n",
      "Avg loss: 0.004961487037876301!\n",
      "Avg loss: 0.004961827056270446!\n",
      "Avg loss: 0.0049757711763902535!\n",
      "Avg loss: 0.00494702385116625!\n",
      "Avg loss: 0.0049504965095400165!\n",
      "Avg loss: 0.004982513747743553!\n",
      "Avg loss: 0.004981047912656702!\n",
      "Avg loss: 0.004948736253565945!\n",
      "Avg loss: 0.004946616284246185!\n",
      "Avg loss: 0.004961861181496564!\n",
      "Avg loss: 0.004973503983160299!\n",
      "Avg loss: 0.004969973696807605!\n",
      "Avg loss: 0.004972564115451709!\n",
      "Avg loss: 0.00495875560063657!\n",
      "Avg loss: 0.004970264546893759!\n",
      "Avg loss: 0.004963462330748219!\n",
      "Avg loss: 0.004979112508229567!\n",
      "Avg loss: 0.004985386056968461!\n",
      "Avg loss: 0.005009728546732504!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.06978060804307461!\n",
      "Avg loss: 0.06851530781141871!\n",
      "Avg loss: 0.06913462600493707!\n",
      "Avg loss: 0.06839324583842729!\n",
      "Avg loss: 0.06733638236818781!\n",
      "Avg loss: 0.06749294998206702!\n",
      "Avg loss: 0.06707777483821702!\n",
      "Avg loss: 0.06704646892569448!\n",
      "Avg loss: 0.0669150798984462!\n",
      "Avg loss: 0.0669707013928587!\n",
      "Avg loss: 0.06669389213334095!\n",
      "Avg loss: 0.06658191093104505!\n",
      "Avg loss: 0.06681496223391757!\n",
      "Avg loss: 0.06682293090570435!\n",
      "Avg loss: 0.06668637339120778!\n",
      "Avg loss: 0.06657678321046812!\n",
      "Avg loss: 0.06658430414142383!\n",
      "Avg loss: 0.06653012347301!\n",
      "Avg loss: 0.0663871289743497!\n",
      "Avg loss: 0.06631017544460899!\n",
      "Avg loss: 0.06629038708621844!\n",
      "Avg loss: 0.06633126547937081!\n",
      "Avg loss: 0.06637800737345705!\n",
      "Avg loss: 0.06640742881774865!\n",
      "Avg loss: 0.06648176471121493!\n",
      "Avg loss: 0.06650238579033385!\n",
      "Avg loss: 0.0664069545009382!\n",
      "Avg loss: 0.06633977781718006!\n",
      "Avg loss: 0.06634297065994815!\n",
      "Avg loss: 0.06625749403965131!\n",
      "Avg loss: 0.06623061270062958!\n",
      "Avg loss: 0.06633274176997701!\n",
      "Avg loss: 0.06629551466788418!\n",
      "Avg loss: 0.06622781575750954!\n",
      "Avg loss: 0.06624876775405786!\n",
      "Avg loss: 0.06628753339386056!\n",
      "Avg loss: 0.0663086749959111!\n",
      "Avg loss: 0.06640019739284071!\n",
      "Avg loss: 0.06635186041069242!\n",
      "Avg loss: 0.06626569773724346!\n",
      "Avg loss: 0.06626135258808441!\n",
      "Avg loss: 0.06628977074955932!\n",
      "Avg loss: 0.06632814896466693!\n",
      "Avg loss: 0.06645622102260622!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.003932817479071673!\n",
      "Avg loss: 0.003409113700023833!\n",
      "Avg loss: 0.003521524100106035!\n",
      "Avg loss: 0.003115409976647546!\n",
      "Avg loss: 0.0026046802349143643!\n",
      "Avg loss: 0.0030943713645804867!\n",
      "Avg loss: 0.00251782657434281!\n",
      "Avg loss: 0.0027224206563482766!\n",
      "Avg loss: 0.002546526075587584!\n",
      "Avg loss: 0.002588856051819069!\n",
      "Avg loss: 0.0025151777360103247!\n",
      "Avg loss: 0.0024977280715559875!\n",
      "Avg loss: 0.0025539511435552715!\n",
      "Avg loss: 0.002521907590232028!\n",
      "Avg loss: 0.002520304613620586!\n",
      "Avg loss: 0.002526719553824629!\n",
      "Avg loss: 0.0024759693488605686!\n",
      "Avg loss: 0.002500768342197072!\n",
      "Avg loss: 0.002525189814020526!\n",
      "Avg loss: 0.002486753791730886!\n",
      "Avg loss: 0.002486452793348235!\n",
      "Avg loss: 0.002501029964098507!\n",
      "Avg loss: 0.0024919490109967532!\n",
      "Avg loss: 0.0024898999022965047!\n",
      "Avg loss: 0.002495663493600091!\n",
      "Avg loss: 0.002488179853002824!\n",
      "Avg loss: 0.002500513282810554!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -718     |\n",
      "| time/              |          |\n",
      "|    fps             | 350      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -734     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 353      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 11       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.63     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0081   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 97       |\n",
      "|    policy_objective       | 0.0121   |\n",
      "|    std                    | 0.47     |\n",
      "|    value_loss             | 338      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -714     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 354      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.82     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00855  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 98       |\n",
      "|    policy_objective       | 0.0213   |\n",
      "|    std                    | 0.474    |\n",
      "|    value_loss             | 264      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -687     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 358      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 22       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.846    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00807  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 99       |\n",
      "|    policy_objective       | 0.0135   |\n",
      "|    std                    | 0.476    |\n",
      "|    value_loss             | 303      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -660     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 356      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 28       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.846    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0078   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 100      |\n",
      "|    policy_objective       | 0.0163   |\n",
      "|    std                    | 0.485    |\n",
      "|    value_loss             | 425      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -673     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 351      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 34       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.853    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00718  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 101      |\n",
      "|    policy_objective       | 0.0154   |\n",
      "|    std                    | 0.475    |\n",
      "|    value_loss             | 449      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -686     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 349      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 41       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.893    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00787  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 102      |\n",
      "|    policy_objective       | 0.0204   |\n",
      "|    std                    | 0.474    |\n",
      "|    value_loss             | 220      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -671     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 349      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 46       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.805    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00813  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 103      |\n",
      "|    policy_objective       | 0.0123   |\n",
      "|    std                    | 0.468    |\n",
      "|    value_loss             | 339      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-598.9239063396584\n",
      "------------------------------\n",
      "round: 13\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.0576486438789046!\n",
      "Avg loss: 0.056496649980593554!\n",
      "Avg loss: 0.059599923554703005!\n",
      "Avg loss: 0.0562729809548182!\n",
      "Avg loss: 0.056190321216636224!\n",
      "Avg loss: 0.05802868409124737!\n",
      "Avg loss: 0.05741444487530316!\n",
      "Avg loss: 0.05694194873064286!\n",
      "Avg loss: 0.05765271585797867!\n",
      "Avg loss: 0.05792334515228201!\n",
      "Avg loss: 0.05708575629039388!\n",
      "Avg loss: 0.057375945720683226!\n",
      "Avg loss: 0.05784478130168206!\n",
      "Avg loss: 0.057414756780587294!\n",
      "Avg loss: 0.057586207908676294!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.050020242789008386!\n",
      "Avg loss: 0.049039016879105474!\n",
      "Avg loss: 0.051106410514342615!\n",
      "Avg loss: 0.04915053181484837!\n",
      "Avg loss: 0.04879624826959723!\n",
      "Avg loss: 0.04946876815645737!\n",
      "Avg loss: 0.04882593849173645!\n",
      "Avg loss: 0.04846972497077938!\n",
      "Avg loss: 0.04901704272076434!\n",
      "Avg loss: 0.04861148911118714!\n",
      "Avg loss: 0.048178348334022306!\n",
      "Avg loss: 0.048464172966845735!\n",
      "Avg loss: 0.04833575685736226!\n",
      "Avg loss: 0.04829041913967975!\n",
      "Avg loss: 0.0482958604546305!\n",
      "Avg loss: 0.04819839510439124!\n",
      "Avg loss: 0.04828261799974749!\n",
      "Avg loss: 0.04816264604290713!\n",
      "Avg loss: 0.048192550716962615!\n",
      "Avg loss: 0.048154237680160465!\n",
      "Avg loss: 0.048074972695195964!\n",
      "Avg loss: 0.04819218716320961!\n",
      "Avg loss: 0.048095430906920075!\n",
      "Avg loss: 0.04811915496146639!\n",
      "Avg loss: 0.0480889136468727!\n",
      "Avg loss: 0.048140983422302955!\n",
      "Avg loss: 0.04811214638572286!\n",
      "Avg loss: 0.0480646117648763!\n",
      "Avg loss: 0.04806951990747469!\n",
      "Avg loss: 0.048067800682977314!\n",
      "Avg loss: 0.04807291598796122!\n",
      "Avg loss: 0.0480677535831785!\n",
      "Avg loss: 0.048078985007058414!\n",
      "Avg loss: 0.048065417080232556!\n",
      "Avg loss: 0.0480722882213135!\n",
      "Avg loss: 0.04805927943472729!\n",
      "Avg loss: 0.0480638489786808!\n",
      "Avg loss: 0.048045113340818756!\n",
      "Avg loss: 0.04805919025219955!\n",
      "Avg loss: 0.048043732592660336!\n",
      "Avg loss: 0.048052005142361194!\n",
      "Avg loss: 0.048035934245480784!\n",
      "Avg loss: 0.04804504902411651!\n",
      "Avg loss: 0.04802722899230569!\n",
      "Avg loss: 0.04803173011625373!\n",
      "Avg loss: 0.04802663683987649!\n",
      "Avg loss: 0.04802460362840426!\n",
      "Avg loss: 0.04801855589708827!\n",
      "Avg loss: 0.04801708414837639!\n",
      "Avg loss: 0.04801145893155995!\n",
      "Avg loss: 0.04801274296127076!\n",
      "Avg loss: 0.04800567584031981!\n",
      "Avg loss: 0.04800589829694265!\n",
      "Avg loss: 0.04799398001614956!\n",
      "Avg loss: 0.048005478410778624!\n",
      "Avg loss: 0.04799063999541981!\n",
      "Avg loss: 0.04799930057814284!\n",
      "Avg loss: 0.04798221655286502!\n",
      "Avg loss: 0.047996455218860014!\n",
      "Avg loss: 0.04797609294399791!\n",
      "Avg loss: 0.04799571253917236!\n",
      "Avg loss: 0.047970241526724446!\n",
      "Avg loss: 0.04799676661175984!\n",
      "Avg loss: 0.04796561994530994!\n",
      "Avg loss: 0.047997078324850694!\n",
      "Avg loss: 0.04796443376320402!\n",
      "Avg loss: 0.047999749223993526!\n",
      "Avg loss: 0.04796048791189643!\n",
      "Avg loss: 0.04800394900288249!\n",
      "Avg loss: 0.0479569265887172!\n",
      "Avg loss: 0.04800407482165914!\n",
      "Avg loss: 0.04795602069824137!\n",
      "Avg loss: 0.048004891544239855!\n",
      "Avg loss: 0.04795507170552611!\n",
      "Avg loss: 0.04800568757935404!\n",
      "Avg loss: 0.04795407581387707!\n",
      "Avg loss: 0.04800322112259399!\n",
      "Avg loss: 0.04795314595376188!\n",
      "Avg loss: 0.04800073921056234!\n",
      "Avg loss: 0.047954586327680127!\n",
      "Avg loss: 0.0479943998602126!\n",
      "Avg loss: 0.047954225980249704!\n",
      "Avg loss: 0.047987794596377475!\n",
      "Avg loss: 0.04795380107457324!\n",
      "Avg loss: 0.04798141894267929!\n",
      "Avg loss: 0.04795923023702737!\n",
      "Avg loss: 0.047969900229858524!\n",
      "Avg loss: 0.04795795549981837!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0008093798878932527!\n",
      "Avg loss: 0.001402178139278476!\n",
      "Avg loss: 0.00310828103422106!\n",
      "Avg loss: 0.002680847731817266!\n",
      "Avg loss: 0.002268820860372216!\n",
      "Avg loss: 0.002457889624233758!\n",
      "Avg loss: 0.002659425996316713!\n",
      "Avg loss: 0.0024622518348193503!\n",
      "Avg loss: 0.0024301526436950856!\n",
      "Avg loss: 0.002499058789726405!\n",
      "Avg loss: 0.0024577423746692754!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -637     |\n",
      "| time/              |          |\n",
      "|    fps             | 358      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -673     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 317      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 12       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.852    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00811  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 105      |\n",
      "|    policy_objective       | 0.0197   |\n",
      "|    std                    | 0.459    |\n",
      "|    value_loss             | 361      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -670     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 331      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 18       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.862    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00746  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 106      |\n",
      "|    policy_objective       | 0.0123   |\n",
      "|    std                    | 0.448    |\n",
      "|    value_loss             | 494      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -701     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 342      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 23       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.91     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00741  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 107      |\n",
      "|    policy_objective       | 0.0147   |\n",
      "|    std                    | 0.436    |\n",
      "|    value_loss             | 359      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -685     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 338      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 30       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.838    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00853  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 108      |\n",
      "|    policy_objective       | 0.013    |\n",
      "|    std                    | 0.448    |\n",
      "|    value_loss             | 601      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -695     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 339      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 36       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.897    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00848  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 109      |\n",
      "|    policy_objective       | 0.0183   |\n",
      "|    std                    | 0.437    |\n",
      "|    value_loss             | 558      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -690     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 339      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 42       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.865    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00705  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 110      |\n",
      "|    policy_objective       | 0.0129   |\n",
      "|    std                    | 0.425    |\n",
      "|    value_loss             | 390      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -672     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 336      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 48       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.905    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00724  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 111      |\n",
      "|    policy_objective       | 0.0143   |\n",
      "|    std                    | 0.42     |\n",
      "|    value_loss             | 390      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-302.84364417297763\n",
      "------------------------------\n",
      "round: 14\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.0012395501258288277!\n",
      "Avg loss: 0.0009243089108349523!\n",
      "Avg loss: 0.0008211528571033948!\n",
      "Avg loss: 0.0004726956392490441!\n",
      "Avg loss: 0.0005926711946297777!\n",
      "Avg loss: 0.0002741493294418736!\n",
      "Avg loss: 0.000442388635072651!\n",
      "Avg loss: 0.00030000717413334617!\n",
      "Avg loss: 0.00023230156615075732!\n",
      "Avg loss: 0.00028514068907194693!\n",
      "Avg loss: 0.0002894905429805779!\n",
      "Avg loss: 0.00022412827410638178!\n",
      "Avg loss: 0.0002525897466633372!\n",
      "Avg loss: 0.00024988979447925885!\n",
      "Avg loss: 0.0002292181386565062!\n",
      "Avg loss: 0.00023392308983905726!\n",
      "Avg loss: 0.000239031942338291!\n",
      "Avg loss: 0.00023234320774766579!\n",
      "Avg loss: 0.00025138435063013273!\n",
      "Avg loss: 0.00023980098861367576!\n",
      "Avg loss: 0.0002585333948021192!\n",
      "Avg loss: 0.0002561617785583318!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.010318444714648649!\n",
      "Avg loss: 0.007755491085942291!\n",
      "Avg loss: 0.007196159024072888!\n",
      "Avg loss: 0.007211428875937903!\n",
      "Avg loss: 0.007039574946344752!\n",
      "Avg loss: 0.0069718054908056125!\n",
      "Avg loss: 0.0066069879070710155!\n",
      "Avg loss: 0.006624770250164147!\n",
      "Avg loss: 0.006220080181701632!\n",
      "Avg loss: 0.006368426396960179!\n",
      "Avg loss: 0.006407079298854417!\n",
      "Avg loss: 0.006274238948086956!\n",
      "Avg loss: 0.006203257550611549!\n",
      "Avg loss: 0.0062113528118106845!\n",
      "Avg loss: 0.0062415795857460425!\n",
      "Avg loss: 0.006244602956051798!\n",
      "Avg loss: 0.006256447023051805!\n",
      "Avg loss: 0.006236230588251601!\n",
      "Avg loss: 0.006250183200929011!\n",
      "Avg loss: 0.006225761347530465!\n",
      "Avg loss: 0.0062187439267017905!\n",
      "Avg loss: 0.0062269265052536105!\n",
      "Avg loss: 0.006208618795879488!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0014127868809130936!\n",
      "Avg loss: 0.0009363343421015694!\n",
      "Avg loss: 0.0010330082063167842!\n",
      "Avg loss: 0.0007502739639555026!\n",
      "Avg loss: 0.0004698760050329535!\n",
      "Avg loss: 0.0003589915141067953!\n",
      "Avg loss: 0.0003516463177644861!\n",
      "Avg loss: 0.0002625929828172957!\n",
      "Avg loss: 0.00032189332665287415!\n",
      "Avg loss: 0.00030304146364566503!\n",
      "Avg loss: 0.0002243837185869779!\n",
      "Avg loss: 0.0001816596253138414!\n",
      "Avg loss: 0.00022441084941798788!\n",
      "Avg loss: 0.0002223878726363182!\n",
      "Avg loss: 0.00017049394454867676!\n",
      "Avg loss: 0.0001810702656742554!\n",
      "Avg loss: 0.00020804031441684856!\n",
      "Avg loss: 0.00019035981836092712!\n",
      "Avg loss: 0.00017479065842356553!\n",
      "Avg loss: 0.00019301124197985094!\n",
      "Avg loss: 0.0001871137409413374!\n",
      "Avg loss: 0.0001833774336228089!\n",
      "Avg loss: 0.00018345744572494975!\n",
      "Avg loss: 0.00019441952310141156!\n",
      "Avg loss: 0.00018504838099791716!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -691     |\n",
      "| time/              |          |\n",
      "|    fps             | 375      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -633     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 378      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 10       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.869    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00796  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 113      |\n",
      "|    policy_objective       | 0.0159   |\n",
      "|    std                    | 0.406    |\n",
      "|    value_loss             | 434      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -638     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 360      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.891    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00734  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 114      |\n",
      "|    policy_objective       | 0.0197   |\n",
      "|    std                    | 0.405    |\n",
      "|    value_loss             | 500      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -632     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 366      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 22       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.905    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0074   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 115      |\n",
      "|    policy_objective       | 0.016    |\n",
      "|    std                    | 0.409    |\n",
      "|    value_loss             | 465      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -628     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 365      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 28       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.869    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00991  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 116      |\n",
      "|    policy_objective       | 0.0115   |\n",
      "|    std                    | 0.396    |\n",
      "|    value_loss             | 826      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -646     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 361      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 33       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.89     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00734  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 117      |\n",
      "|    policy_objective       | 0.0191   |\n",
      "|    std                    | 0.401    |\n",
      "|    value_loss             | 453      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -628     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 363      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 39       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.761    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00745  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 118      |\n",
      "|    policy_objective       | 0.018    |\n",
      "|    std                    | 0.402    |\n",
      "|    value_loss             | 325      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -623     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 359      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 45       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.836    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00628  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 119      |\n",
      "|    policy_objective       | 0.0149   |\n",
      "|    std                    | 0.4      |\n",
      "|    value_loss             | 506      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-242.57555727045983\n",
      "------------------------------\n",
      "round: 15\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.009467763165181775!\n",
      "Avg loss: 0.009295442979606983!\n",
      "Avg loss: 0.01006216572393896!\n",
      "Avg loss: 0.00934494258111954!\n",
      "Avg loss: 0.0093154845251604!\n",
      "Avg loss: 0.009033788145282717!\n",
      "Avg loss: 0.009288634823509103!\n",
      "Avg loss: 0.009151149499592368!\n",
      "Avg loss: 0.00899991035073981!\n",
      "Avg loss: 0.008968307351206023!\n",
      "Avg loss: 0.009080586555690691!\n",
      "Avg loss: 0.009064556816906209!\n",
      "Avg loss: 0.00892912208366018!\n",
      "Avg loss: 0.008972881053581716!\n",
      "Avg loss: 0.009016105660837942!\n",
      "Avg loss: 0.008976195821985585!\n",
      "Avg loss: 0.008941531594815236!\n",
      "Avg loss: 0.00898713898507926!\n",
      "Avg loss: 0.008980106598456813!\n",
      "Avg loss: 0.008976101031893223!\n",
      "Avg loss: 0.00894811925554753!\n",
      "Avg loss: 0.009009853134315715!\n",
      "Avg loss: 0.008958164897592269!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.056381867405483115!\n",
      "Avg loss: 0.05792903906841578!\n",
      "Avg loss: 0.06342639703924458!\n",
      "Avg loss: 0.06037115406089166!\n",
      "Avg loss: 0.059361657987437866!\n",
      "Avg loss: 0.060660831947485956!\n",
      "Avg loss: 0.06147704717521265!\n",
      "Avg loss: 0.06066162380227676!\n",
      "Avg loss: 0.060250714432410556!\n",
      "Avg loss: 0.06054018854844798!\n",
      "Avg loss: 0.060181759111079224!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.03353353987661346!\n",
      "Avg loss: 0.033553296282922626!\n",
      "Avg loss: 0.03496693069838936!\n",
      "Avg loss: 0.03356284760184887!\n",
      "Avg loss: 0.033371636385245436!\n",
      "Avg loss: 0.033308978485495876!\n",
      "Avg loss: 0.03351647755048513!\n",
      "Avg loss: 0.033543327658626367!\n",
      "Avg loss: 0.03322383302331218!\n",
      "Avg loss: 0.033001629652483946!\n",
      "Avg loss: 0.03321610234622388!\n",
      "Avg loss: 0.033175268437854205!\n",
      "Avg loss: 0.03303684071296004!\n",
      "Avg loss: 0.03307879594737301!\n",
      "Avg loss: 0.0331288608990432!\n",
      "Avg loss: 0.03305113204390068!\n",
      "Avg loss: 0.03307879323883147!\n",
      "Avg loss: 0.03310740109931023!\n",
      "Avg loss: 0.03305807124855297!\n",
      "Avg loss: 0.03297393472575038!\n",
      "Avg loss: 0.03299443110648686!\n",
      "Avg loss: 0.032995215487730246!\n",
      "Avg loss: 0.03300868321912314!\n",
      "Avg loss: 0.03302069375280307!\n",
      "Avg loss: 0.033008474551963145!\n",
      "Avg loss: 0.03301554264282231!\n",
      "Avg loss: 0.033012324433456114!\n",
      "Avg loss: 0.03300890660790032!\n",
      "Avg loss: 0.03301947590414196!\n",
      "Avg loss: 0.03302850070019455!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -393     |\n",
      "| time/              |          |\n",
      "|    fps             | 429      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -520     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 405      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 10       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.921    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00925  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 121      |\n",
      "|    policy_objective       | 0.0219   |\n",
      "|    std                    | 0.396    |\n",
      "|    value_loss             | 431      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -563     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 398      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 15       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.875    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00764  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 122      |\n",
      "|    policy_objective       | 0.0145   |\n",
      "|    std                    | 0.397    |\n",
      "|    value_loss             | 407      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -569     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 389      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 21       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.807    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00858  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 123      |\n",
      "|    policy_objective       | 0.0169   |\n",
      "|    std                    | 0.403    |\n",
      "|    value_loss             | 434      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -559     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 384      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 26       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.921    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00859  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 124      |\n",
      "|    policy_objective       | 0.0177   |\n",
      "|    std                    | 0.4      |\n",
      "|    value_loss             | 304      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -568     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 382      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 32       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.927    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00792  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 125      |\n",
      "|    policy_objective       | 0.0136   |\n",
      "|    std                    | 0.404    |\n",
      "|    value_loss             | 380      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -564     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 383      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 37       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.913    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00874  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 126      |\n",
      "|    policy_objective       | 0.0126   |\n",
      "|    std                    | 0.398    |\n",
      "|    value_loss             | 407      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -555     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 375      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 43       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.938    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00813  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 127      |\n",
      "|    policy_objective       | 0.0177   |\n",
      "|    std                    | 0.399    |\n",
      "|    value_loss             | 353      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-255.74213915597647\n",
      "------------------------------\n",
      "round: 16\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.0005342572788746717!\n",
      "Avg loss: 0.0003914373794638474!\n",
      "Avg loss: 0.000623227530886652!\n",
      "Avg loss: 0.00030464916818952285!\n",
      "Avg loss: 0.0001697675089008044!\n",
      "Avg loss: 0.00013658041999102958!\n",
      "Avg loss: 0.0002489059001103063!\n",
      "Avg loss: 0.00013807602580224434!\n",
      "Avg loss: 9.559167803862085e-05!\n",
      "Avg loss: 9.941362287463562e-05!\n",
      "Avg loss: 0.00013180697761223806!\n",
      "Avg loss: 0.00011449662534081047!\n",
      "Avg loss: 8.817783618837893e-05!\n",
      "Avg loss: 8.272505833247124e-05!\n",
      "Avg loss: 0.00011364023923306377!\n",
      "Avg loss: 9.400935488883987e-05!\n",
      "Avg loss: 8.683277674208512e-05!\n",
      "Avg loss: 9.77405029577009e-05!\n",
      "Avg loss: 0.0001154545441265024!\n",
      "Avg loss: 0.00010420959051164877!\n",
      "Avg loss: 0.0001168599964967143!\n",
      "Avg loss: 0.00013315616385322452!\n",
      "Avg loss: 0.0001414430404201994!\n",
      "Avg loss: 0.00014485078513340946!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.0020197946448752193!\n",
      "Avg loss: 0.0006743563003450011!\n",
      "Avg loss: 0.0007148748164763674!\n",
      "Avg loss: 0.0005841914876267159!\n",
      "Avg loss: 0.00045153283987626005!\n",
      "Avg loss: 0.00021971167421725113!\n",
      "Avg loss: 0.0002534882673323106!\n",
      "Avg loss: 0.00014891992895930647!\n",
      "Avg loss: 0.00014880618269671686!\n",
      "Avg loss: 0.00017648947905399837!\n",
      "Avg loss: 0.00013112632078597622!\n",
      "Avg loss: 7.709067204511182e-05!\n",
      "Avg loss: 8.064667172826982e-05!\n",
      "Avg loss: 9.545287058093284e-05!\n",
      "Avg loss: 0.00010871495964541586!\n",
      "Avg loss: 7.423494449236993e-05!\n",
      "Avg loss: 6.0087085947581425e-05!\n",
      "Avg loss: 7.170205611894669e-05!\n",
      "Avg loss: 9.442453846001323e-05!\n",
      "Avg loss: 7.469064380453952e-05!\n",
      "Avg loss: 6.684365501958685e-05!\n",
      "Avg loss: 7.780376213569677e-05!\n",
      "Avg loss: 7.965119919314626e-05!\n",
      "Avg loss: 7.9021609215791e-05!\n",
      "Avg loss: 7.511730939086192e-05!\n",
      "Avg loss: 7.534833243236486e-05!\n",
      "Avg loss: 7.86177691153019e-05!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0030064000674368194!\n",
      "Avg loss: 0.00230578521208372!\n",
      "Avg loss: 0.0028819675565076373!\n",
      "Avg loss: 0.0020886762881855247!\n",
      "Avg loss: 0.0023819175911118386!\n",
      "Avg loss: 0.002022505860495585!\n",
      "Avg loss: 0.0021604171500621307!\n",
      "Avg loss: 0.002020872003995464!\n",
      "Avg loss: 0.002023685268704867!\n",
      "Avg loss: 0.0019822210601675274!\n",
      "Avg loss: 0.0019829489823274572!\n",
      "Avg loss: 0.001964614170792534!\n",
      "Avg loss: 0.001953634311979613!\n",
      "Avg loss: 0.0019534307615427337!\n",
      "Avg loss: 0.0019489789342258253!\n",
      "Avg loss: 0.0019499901620224117!\n",
      "Avg loss: 0.0019467048993183766!\n",
      "Avg loss: 0.00194696667758573!\n",
      "Avg loss: 0.0019475755238017693!\n",
      "Avg loss: 0.0019483019600148074!\n",
      "Avg loss: 0.0019521029207659997!\n",
      "Avg loss: 0.0019473540346598502!\n",
      "Avg loss: 0.0019496365927240808!\n",
      "Avg loss: 0.0019514205107176016!\n",
      "Avg loss: 0.001949357545676283!\n",
      "Avg loss: 0.0019502572902498016!\n",
      "Avg loss: 0.0019516269467713225!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -584     |\n",
      "| time/              |          |\n",
      "|    fps             | 392      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -588     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 378      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 10       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.877    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00855  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 129      |\n",
      "|    policy_objective       | 0.0172   |\n",
      "|    std                    | 0.399    |\n",
      "|    value_loss             | 646      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -585     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 370      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 16       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.881    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00874  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 130      |\n",
      "|    policy_objective       | 0.0207   |\n",
      "|    std                    | 0.401    |\n",
      "|    value_loss             | 492      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -538     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 368      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 22       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.885    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00905  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 131      |\n",
      "|    policy_objective       | 0.0157   |\n",
      "|    std                    | 0.393    |\n",
      "|    value_loss             | 570      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -555     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 364      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 28       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.911    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00713  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 132      |\n",
      "|    policy_objective       | 0.0181   |\n",
      "|    std                    | 0.401    |\n",
      "|    value_loss             | 657      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -571     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 357      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 34       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.849    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00828  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 133      |\n",
      "|    policy_objective       | 0.0143   |\n",
      "|    std                    | 0.399    |\n",
      "|    value_loss             | 569      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -574     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 359      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 39       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.921    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00749  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 134      |\n",
      "|    policy_objective       | 0.0177   |\n",
      "|    std                    | 0.391    |\n",
      "|    value_loss             | 353      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -566     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 357      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 45       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.949    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00887  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 135      |\n",
      "|    policy_objective       | 0.015    |\n",
      "|    std                    | 0.386    |\n",
      "|    value_loss             | 406      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-213.3483472181484\n",
      "------------------------------\n",
      "round: 17\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.0009592816106548223!\n",
      "Avg loss: 0.0005348556831449968!\n",
      "Avg loss: 0.0010814901388948783!\n",
      "Avg loss: 0.0001340483874628262!\n",
      "Avg loss: 0.0006935361847475481!\n",
      "Avg loss: 0.00019352811896908406!\n",
      "Avg loss: 0.0003690288961661281!\n",
      "Avg loss: 0.00013586245240124602!\n",
      "Avg loss: 0.00030422935993253!\n",
      "Avg loss: 0.0001884503965023517!\n",
      "Avg loss: 0.00017906445755215826!\n",
      "Avg loss: 0.0001477353239920376!\n",
      "Avg loss: 0.0001590086801797952!\n",
      "Avg loss: 0.00017523388437742446!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.009085256103426219!\n",
      "Avg loss: 0.0077772840469454724!\n",
      "Avg loss: 0.008119407220510766!\n",
      "Avg loss: 0.00783724503412183!\n",
      "Avg loss: 0.007626916047993291!\n",
      "Avg loss: 0.007613458515479578!\n",
      "Avg loss: 0.007470092679432128!\n",
      "Avg loss: 0.007485278828098672!\n",
      "Avg loss: 0.007359889777023151!\n",
      "Avg loss: 0.007372903004206819!\n",
      "Avg loss: 0.0074344692887590704!\n",
      "Avg loss: 0.007343085453981075!\n",
      "Avg loss: 0.007317917008231234!\n",
      "Avg loss: 0.007363906262269116!\n",
      "Avg loss: 0.007346818744466645!\n",
      "Avg loss: 0.007320462121891941!\n",
      "Avg loss: 0.007334304452956531!\n",
      "Avg loss: 0.007333258491589921!\n",
      "Avg loss: 0.007326987533056884!\n",
      "Avg loss: 0.007323048316612434!\n",
      "Avg loss: 0.0073212614361333785!\n",
      "Avg loss: 0.007332449594593224!\n",
      "Avg loss: 0.00732146807085807!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0012507000482097888!\n",
      "Avg loss: 0.0007856633693154436!\n",
      "Avg loss: 0.0009605624685536895!\n",
      "Avg loss: 0.0002516822843214565!\n",
      "Avg loss: 0.0005651604916541449!\n",
      "Avg loss: 0.0001473397980256171!\n",
      "Avg loss: 0.00028262108233623927!\n",
      "Avg loss: 0.00013776480918750166!\n",
      "Avg loss: 0.00022477589252919945!\n",
      "Avg loss: 5.181538697987283e-05!\n",
      "Avg loss: 9.213817230602217e-05!\n",
      "Avg loss: 0.00010176186947925695!\n",
      "Avg loss: 0.00010907077463343739!\n",
      "Avg loss: 4.017642676937309e-05!\n",
      "Avg loss: 4.4466584239633754e-05!\n",
      "Avg loss: 7.831946587430138e-05!\n",
      "Avg loss: 6.262623393088991e-05!\n",
      "Avg loss: 4.2658363149712386e-05!\n",
      "Avg loss: 5.314935220364229e-05!\n",
      "Avg loss: 5.737070778726168e-05!\n",
      "Avg loss: 5.205199879848503e-05!\n",
      "Avg loss: 5.0672213100521426e-05!\n",
      "Avg loss: 5.233911117822269e-05!\n",
      "Avg loss: 4.5327734770997574e-05!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -468     |\n",
      "| time/              |          |\n",
      "|    fps             | 405      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -590     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 382      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 10       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.885    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0074   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 137      |\n",
      "|    policy_objective       | 0.0139   |\n",
      "|    std                    | 0.384    |\n",
      "|    value_loss             | 452      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -589     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 379      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 16       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.832    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0091   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 138      |\n",
      "|    policy_objective       | 0.021    |\n",
      "|    std                    | 0.38     |\n",
      "|    value_loss             | 434      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -582     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 377      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 21       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.917    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00926  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 139      |\n",
      "|    policy_objective       | 0.0184   |\n",
      "|    std                    | 0.374    |\n",
      "|    value_loss             | 552      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -591     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 374      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 27       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.928    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00888  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 140      |\n",
      "|    policy_objective       | 0.0174   |\n",
      "|    std                    | 0.37     |\n",
      "|    value_loss             | 488      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -574     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 371      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 33       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.929    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00888  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 141      |\n",
      "|    policy_objective       | 0.0226   |\n",
      "|    std                    | 0.372    |\n",
      "|    value_loss             | 525      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -575     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 371      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 38       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.915    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00901  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 142      |\n",
      "|    policy_objective       | 0.0174   |\n",
      "|    std                    | 0.372    |\n",
      "|    value_loss             | 757      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -573     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 371      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 44       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.904    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0075   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 143      |\n",
      "|    policy_objective       | 0.0172   |\n",
      "|    std                    | 0.366    |\n",
      "|    value_loss             | 630      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-283.1163841223344\n",
      "------------------------------\n",
      "round: 18\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.009837619023164735!\n",
      "Avg loss: 0.009390264142023928!\n",
      "Avg loss: 0.00945006859251104!\n",
      "Avg loss: 0.009144264588079144!\n",
      "Avg loss: 0.009228306288811534!\n",
      "Avg loss: 0.00902597959187915!\n",
      "Avg loss: 0.00904504217383116!\n",
      "Avg loss: 0.008897471572563518!\n",
      "Avg loss: 0.009006440931608116!\n",
      "Avg loss: 0.00887800830118825!\n",
      "Avg loss: 0.008923741781782155!\n",
      "Avg loss: 0.008827276975847932!\n",
      "Avg loss: 0.00886693775445167!\n",
      "Avg loss: 0.008870706862570235!\n",
      "Avg loss: 0.008837712606552183!\n",
      "Avg loss: 0.008846405725466865!\n",
      "Avg loss: 0.00886735729535379!\n",
      "Avg loss: 0.008863759233591964!\n",
      "Avg loss: 0.00885532449344737!\n",
      "Avg loss: 0.008876971514003636!\n",
      "Avg loss: 0.008878690206154167!\n",
      "Avg loss: 0.008887065071547795!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.0008579315689469998!\n",
      "Avg loss: 0.0006765030923027856!\n",
      "Avg loss: 0.0005308647405278559!\n",
      "Avg loss: 0.00017006532993946166!\n",
      "Avg loss: 0.00037709455490888405!\n",
      "Avg loss: 9.390089641631979e-05!\n",
      "Avg loss: 0.00023305644800226824!\n",
      "Avg loss: 0.00011024592356079666!\n",
      "Avg loss: 0.00012942852518487295!\n",
      "Avg loss: 5.7981043080985725e-05!\n",
      "Avg loss: 7.530289102154105e-05!\n",
      "Avg loss: 7.598275473469585e-05!\n",
      "Avg loss: 7.50253212034598e-05!\n",
      "Avg loss: 4.584816980847488e-05!\n",
      "Avg loss: 5.172305888021533e-05!\n",
      "Avg loss: 5.282198948483104e-05!\n",
      "Avg loss: 4.692143230992466e-05!\n",
      "Avg loss: 4.82997386761023e-05!\n",
      "Avg loss: 5.811715270321353e-05!\n",
      "Avg loss: 4.402604412405253e-05!\n",
      "Avg loss: 4.450710119063691e-05!\n",
      "Avg loss: 5.454883224804992e-05!\n",
      "Avg loss: 5.297045326282538e-05!\n",
      "Avg loss: 4.3857067147617575e-05!\n",
      "Avg loss: 4.9117648946150896e-05!\n",
      "Avg loss: 5.153155897431816e-05!\n",
      "Avg loss: 4.714607320522646e-05!\n",
      "Avg loss: 5.159052695555981e-05!\n",
      "Avg loss: 4.859565548007557e-05!\n",
      "Avg loss: 4.942841617605609e-05!\n",
      "Avg loss: 5.065162281094142e-05!\n",
      "Avg loss: 4.841618300337321e-05!\n",
      "Avg loss: 5.1172211332376116e-05!\n",
      "Avg loss: 5.094148525955689e-05!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0006039665688270664!\n",
      "Avg loss: 0.000361595912448441!\n",
      "Avg loss: 0.0005286526635003005!\n",
      "Avg loss: 0.0001778050085461776!\n",
      "Avg loss: 0.00023894936129484752!\n",
      "Avg loss: 0.000246220132982368!\n",
      "Avg loss: 0.0002828077617611295!\n",
      "Avg loss: 9.12323073165074e-05!\n",
      "Avg loss: 0.00011704655885599398!\n",
      "Avg loss: 0.00016318839217622857!\n",
      "Avg loss: 0.00018635035840096256!\n",
      "Avg loss: 0.00014423217878478076!\n",
      "Avg loss: 0.00011284021049201935!\n",
      "Avg loss: 0.0001379304755588843!\n",
      "Avg loss: 0.00012969266044971542!\n",
      "Avg loss: 0.00012703289658209845!\n",
      "Avg loss: 0.00014354946779121747!\n",
      "Avg loss: 0.00013004543826620343!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -589     |\n",
      "| time/              |          |\n",
      "|    fps             | 389      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -627     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 366      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 11       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.939    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00656  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 145      |\n",
      "|    policy_objective       | 0.0166   |\n",
      "|    std                    | 0.366    |\n",
      "|    value_loss             | 541      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -577     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 348      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.946    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00898  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 146      |\n",
      "|    policy_objective       | 0.0158   |\n",
      "|    std                    | 0.373    |\n",
      "|    value_loss             | 348      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -546     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 343      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 23       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.902    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00734  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 147      |\n",
      "|    policy_objective       | 0.0143   |\n",
      "|    std                    | 0.38     |\n",
      "|    value_loss             | 710      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -511     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 343      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 29       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.944    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00782  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 148      |\n",
      "|    policy_objective       | 0.0143   |\n",
      "|    std                    | 0.38     |\n",
      "|    value_loss             | 577      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -529     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 344      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 35       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.941    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00817  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 149      |\n",
      "|    policy_objective       | 0.0184   |\n",
      "|    std                    | 0.372    |\n",
      "|    value_loss             | 576      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -550     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 343      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 41       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.899    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00778  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 150      |\n",
      "|    policy_objective       | 0.0187   |\n",
      "|    std                    | 0.372    |\n",
      "|    value_loss             | 479      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -552     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 337      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 48       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.915    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00721  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 151      |\n",
      "|    policy_objective       | 0.0169   |\n",
      "|    std                    | 0.371    |\n",
      "|    value_loss             | 305      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-186.7118948964402\n",
      "------------------------------\n",
      "round: 19\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.0006827760453961674!\n",
      "Avg loss: 0.0005127654657796181!\n",
      "Avg loss: 0.0005525034861057066!\n",
      "Avg loss: 0.0003309338194655235!\n",
      "Avg loss: 0.00024901291786591176!\n",
      "Avg loss: 0.00018339166044218776!\n",
      "Avg loss: 0.00020939700946958812!\n",
      "Avg loss: 0.00013466414398749293!\n",
      "Avg loss: 0.00012645685383783228!\n",
      "Avg loss: 8.293033585497748e-05!\n",
      "Avg loss: 0.00011506281497531745!\n",
      "Avg loss: 8.267936333785049e-05!\n",
      "Avg loss: 7.632523168164578e-05!\n",
      "Avg loss: 7.540206504017987e-05!\n",
      "Avg loss: 6.598923677434717e-05!\n",
      "Avg loss: 6.972853323380453e-05!\n",
      "Avg loss: 7.257131753969286e-05!\n",
      "Avg loss: 6.496420665134413e-05!\n",
      "Avg loss: 6.059329261044392e-05!\n",
      "Avg loss: 6.700146546412119e-05!\n",
      "Avg loss: 6.747115483809314e-05!\n",
      "Avg loss: 6.411635845608999e-05!\n",
      "Avg loss: 6.522266504229416e-05!\n",
      "Avg loss: 6.95935707393384e-05!\n",
      "Avg loss: 6.42324798199212e-05!\n",
      "Avg loss: 6.376605067468214e-05!\n",
      "Avg loss: 6.411031205459494e-05!\n",
      "Avg loss: 6.46656044691459e-05!\n",
      "Avg loss: 6.28925593333681e-05!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.011483750708066509!\n",
      "Avg loss: 0.010837505220527722!\n",
      "Avg loss: 0.011284368693935298!\n",
      "Avg loss: 0.010914374265116749!\n",
      "Avg loss: 0.010809218315286367!\n",
      "Avg loss: 0.010794529424545847!\n",
      "Avg loss: 0.01071251817014551!\n",
      "Avg loss: 0.010725286492433952!\n",
      "Avg loss: 0.010658133462872001!\n",
      "Avg loss: 0.010690293542741832!\n",
      "Avg loss: 0.01060709691908869!\n",
      "Avg loss: 0.010625208076551948!\n",
      "Avg loss: 0.01066108235495714!\n",
      "Avg loss: 0.010622074706928402!\n",
      "Avg loss: 0.010607792807113204!\n",
      "Avg loss: 0.010634448034189177!\n",
      "Avg loss: 0.010653713283978163!\n",
      "Avg loss: 0.010613641791537702!\n",
      "Avg loss: 0.010626694928968542!\n",
      "Avg loss: 0.01063332719241771!\n",
      "Avg loss: 0.010636764923397853!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0009679203579192593!\n",
      "Avg loss: 0.0006637075750283353!\n",
      "Avg loss: 0.00040550757582726265!\n",
      "Avg loss: 0.0004195832896948559!\n",
      "Avg loss: 0.00015307587678762503!\n",
      "Avg loss: 0.0002873213947107918!\n",
      "Avg loss: 0.00013175179036807095!\n",
      "Avg loss: 0.00020406007403835246!\n",
      "Avg loss: 8.806776327219268e-05!\n",
      "Avg loss: 0.00011280982067394992!\n",
      "Avg loss: 9.173731544782034e-05!\n",
      "Avg loss: 9.453249761326296e-05!\n",
      "Avg loss: 6.488346425157942e-05!\n",
      "Avg loss: 9.69961163809785e-05!\n",
      "Avg loss: 7.018402094464212e-05!\n",
      "Avg loss: 8.005486617056098e-05!\n",
      "Avg loss: 6.725334517057035e-05!\n",
      "Avg loss: 7.945091107491939e-05!\n",
      "Avg loss: 7.690325427006428e-05!\n",
      "Avg loss: 7.358931333423394e-05!\n",
      "Avg loss: 6.861888050669525e-05!\n",
      "Avg loss: 6.65114392719109e-05!\n",
      "Avg loss: 6.854113840105924e-05!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -403     |\n",
      "| time/              |          |\n",
      "|    fps             | 350      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -489     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 338      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 12       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.916    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00889  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 153      |\n",
      "|    policy_objective       | 0.0125   |\n",
      "|    std                    | 0.376    |\n",
      "|    value_loss             | 579      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -526     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 339      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 18       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.921    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00793  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 154      |\n",
      "|    policy_objective       | 0.0206   |\n",
      "|    std                    | 0.378    |\n",
      "|    value_loss             | 645      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -533     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 342      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 23       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.88     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00755  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 155      |\n",
      "|    policy_objective       | 0.0244   |\n",
      "|    std                    | 0.381    |\n",
      "|    value_loss             | 569      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -562     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 347      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 29       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.874    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00845  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 156      |\n",
      "|    policy_objective       | 0.0217   |\n",
      "|    std                    | 0.381    |\n",
      "|    value_loss             | 631      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -564     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 348      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 35       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.875    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00792  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 157      |\n",
      "|    policy_objective       | 0.0208   |\n",
      "|    std                    | 0.379    |\n",
      "|    value_loss             | 463      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -563     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 348      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 41       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.781    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00809  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 158      |\n",
      "|    policy_objective       | 0.0158   |\n",
      "|    std                    | 0.38     |\n",
      "|    value_loss             | 486      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -561     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 351      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 46       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.886    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00863  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 159      |\n",
      "|    policy_objective       | 0.0238   |\n",
      "|    std                    | 0.379    |\n",
      "|    value_loss             | 613      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-239.12449115570635\n",
      "------------------------------\n",
      "round: 20\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.0012593470286810771!\n",
      "Avg loss: 0.001284285746999861!\n",
      "Avg loss: 0.0019233152052440042!\n",
      "Avg loss: 0.001831849644271036!\n",
      "Avg loss: 0.0020667007787786434!\n",
      "Avg loss: 0.0023099389531853376!\n",
      "Avg loss: 0.0021216586681415115!\n",
      "Avg loss: 0.002141524536430855!\n",
      "Avg loss: 0.002177024127437524!\n",
      "Avg loss: 0.002355209077783608!\n",
      "Avg loss: 0.002423244958445139!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.011370689129228898!\n",
      "Avg loss: 0.011024068804981652!\n",
      "Avg loss: 0.011629930553463055!\n",
      "Avg loss: 0.0110530469519108!\n",
      "Avg loss: 0.010993630656375899!\n",
      "Avg loss: 0.010863633202928517!\n",
      "Avg loss: 0.011148461288794351!\n",
      "Avg loss: 0.011000597860487082!\n",
      "Avg loss: 0.010887224484674031!\n",
      "Avg loss: 0.010833187454813924!\n",
      "Avg loss: 0.010978165596326714!\n",
      "Avg loss: 0.010945251265582859!\n",
      "Avg loss: 0.010869910649741238!\n",
      "Avg loss: 0.010869218464558609!\n",
      "Avg loss: 0.010922988945249774!\n",
      "Avg loss: 0.010891263647570402!\n",
      "Avg loss: 0.010862423487862998!\n",
      "Avg loss: 0.010886718403217206!\n",
      "Avg loss: 0.010888728232397681!\n",
      "Avg loss: 0.010885477154422271!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0017989540032188717!\n",
      "Avg loss: 0.0009681532308362269!\n",
      "Avg loss: 0.0016276841528997466!\n",
      "Avg loss: 0.0003914870566101551!\n",
      "Avg loss: 0.0011544836864535075!\n",
      "Avg loss: 0.00030778794800426115!\n",
      "Avg loss: 0.0006253394728567704!\n",
      "Avg loss: 0.00022281441289123905!\n",
      "Avg loss: 0.0005124581686080395!\n",
      "Avg loss: 0.0002231510550185097!\n",
      "Avg loss: 0.0003064160159124185!\n",
      "Avg loss: 0.00022795603218886146!\n",
      "Avg loss: 0.00027367024952278975!\n",
      "Avg loss: 0.0002377619238677653!\n",
      "Avg loss: 0.00022131974680936157!\n",
      "Avg loss: 0.00025197432915698907!\n",
      "Avg loss: 0.00021727737205386196!\n",
      "Avg loss: 0.0002263102630384613!\n",
      "Avg loss: 0.00023065770186804003!\n",
      "Avg loss: 0.00021973593029467036!\n",
      "Avg loss: 0.00021464782324490746!\n",
      "Avg loss: 0.00021810444239539112!\n",
      "Avg loss: 0.0002244079337989054!\n",
      "Avg loss: 0.0002181942501844484!\n",
      "Avg loss: 0.00021757008604784763!\n",
      "Avg loss: 0.00021775039032756165!\n",
      "Avg loss: 0.0002133715547014011!\n",
      "Avg loss: 0.00021593283935771978!\n",
      "Avg loss: 0.00021981672209903992!\n",
      "Avg loss: 0.00022059948279983625!\n",
      "Avg loss: 0.00021730708511465005!\n",
      "Avg loss: 0.00021514010432459449!\n",
      "Avg loss: 0.00021492696941701676!\n",
      "Avg loss: 0.00021554254095292435!\n",
      "Avg loss: 0.0002162518508460683!\n",
      "Avg loss: 0.00022053247857608464!\n",
      "Avg loss: 0.00022403386790775432!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -692     |\n",
      "| time/              |          |\n",
      "|    fps             | 426      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -557     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 403      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 10       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.88     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00815  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 161      |\n",
      "|    policy_objective       | 0.0167   |\n",
      "|    std                    | 0.383    |\n",
      "|    value_loss             | 482      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -593     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 397      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 15       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.919    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00829  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 162      |\n",
      "|    policy_objective       | 0.0207   |\n",
      "|    std                    | 0.379    |\n",
      "|    value_loss             | 456      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -546     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 395      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 20       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.875    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00798  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 163      |\n",
      "|    policy_objective       | 0.0137   |\n",
      "|    std                    | 0.382    |\n",
      "|    value_loss             | 639      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -543     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 391      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 26       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.888    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00842  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 164      |\n",
      "|    policy_objective       | 0.013    |\n",
      "|    std                    | 0.371    |\n",
      "|    value_loss             | 514      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -522     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 390      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 31       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.91     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00831  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 165      |\n",
      "|    policy_objective       | 0.016    |\n",
      "|    std                    | 0.36     |\n",
      "|    value_loss             | 775      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -507     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 389      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 36       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.866    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00891  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 166      |\n",
      "|    policy_objective       | 0.0158   |\n",
      "|    std                    | 0.356    |\n",
      "|    value_loss             | 593      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -509     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 388      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 42       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.913    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00894  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 167      |\n",
      "|    policy_objective       | 0.0281   |\n",
      "|    std                    | 0.356    |\n",
      "|    value_loss             | 576      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-367.1023692952469\n",
      "------------------------------\n",
      "round: 21\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.013616718595537047!\n",
      "Avg loss: 0.012849573697464317!\n",
      "Avg loss: 0.012974325368995778!\n",
      "Avg loss: 0.012552570795479218!\n",
      "Avg loss: 0.01243400377928386!\n",
      "Avg loss: 0.012646986913847892!\n",
      "Avg loss: 0.012480408243087973!\n",
      "Avg loss: 0.012312043280059394!\n",
      "Avg loss: 0.012400528900089587!\n",
      "Avg loss: 0.012428872903025573!\n",
      "Avg loss: 0.012233647825041013!\n",
      "Avg loss: 0.012251676954679169!\n",
      "Avg loss: 0.012344408623306057!\n",
      "Avg loss: 0.012261133748370708!\n",
      "Avg loss: 0.01224930631964071!\n",
      "Avg loss: 0.012293844724736876!\n",
      "Avg loss: 0.01229408998276881!\n",
      "Avg loss: 0.0122486181135226!\n",
      "Avg loss: 0.012276097905973605!\n",
      "Avg loss: 0.012285716623280223!\n",
      "Avg loss: 0.012255893931069673!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.00042808294771627214!\n",
      "Avg loss: 0.00029260829051054317!\n",
      "Avg loss: 0.0002887552871106891!\n",
      "Avg loss: 0.00015006471969779037!\n",
      "Avg loss: 0.00013226945297598527!\n",
      "Avg loss: 8.486749703176126e-05!\n",
      "Avg loss: 8.923789200404523e-05!\n",
      "Avg loss: 5.358493934522812e-05!\n",
      "Avg loss: 4.8244789068121465e-05!\n",
      "Avg loss: 3.4051055569458794e-05!\n",
      "Avg loss: 3.305548636262756e-05!\n",
      "Avg loss: 2.840778491721115e-05!\n",
      "Avg loss: 2.7072005444400323e-05!\n",
      "Avg loss: 1.9587153971372118e-05!\n",
      "Avg loss: 2.4454422470701804e-05!\n",
      "Avg loss: 1.7982409479202487e-05!\n",
      "Avg loss: 1.8986117092746707e-05!\n",
      "Avg loss: 1.6826305719064293e-05!\n",
      "Avg loss: 1.6350451001632867e-05!\n",
      "Avg loss: 1.656278003082434e-05!\n",
      "Avg loss: 1.7784096340183926e-05!\n",
      "Avg loss: 1.6425292298739198e-05!\n",
      "Avg loss: 1.510268657511915e-05!\n",
      "Avg loss: 1.632065579049898e-05!\n",
      "Avg loss: 1.6451478866201797e-05!\n",
      "Avg loss: 1.6259772458440126e-05!\n",
      "Avg loss: 1.5519773331173307e-05!\n",
      "Avg loss: 1.5836387745290874e-05!\n",
      "Avg loss: 1.5879276252519502e-05!\n",
      "Avg loss: 1.5475356832060546e-05!\n",
      "Avg loss: 1.6040649053650214e-05!\n",
      "Avg loss: 1.6474626933700163e-05!\n",
      "Avg loss: 1.590254495577407e-05!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0002789081623571595!\n",
      "Avg loss: 0.0005381913694145623!\n",
      "Avg loss: 0.00018765818681458767!\n",
      "Avg loss: 0.00015495080231630709!\n",
      "Avg loss: 0.0001973619960335782!\n",
      "Avg loss: 0.00021171346505677018!\n",
      "Avg loss: 9.19308860829915e-05!\n",
      "Avg loss: 7.362424255916267e-05!\n",
      "Avg loss: 9.5720881587719e-05!\n",
      "Avg loss: 6.780167270335368e-05!\n",
      "Avg loss: 6.57883643725654e-05!\n",
      "Avg loss: 5.053762067404932e-05!\n",
      "Avg loss: 9.739641176125247e-05!\n",
      "Avg loss: 5.648504674506209e-05!\n",
      "Avg loss: 4.9770817367402744e-05!\n",
      "Avg loss: 6.213430720019157e-05!\n",
      "Avg loss: 7.080132219130065e-05!\n",
      "Avg loss: 5.73344342569726e-05!\n",
      "Avg loss: 5.969967322774513e-05!\n",
      "Avg loss: 7.141385248132792e-05!\n",
      "Avg loss: 5.980003338644716e-05!\n",
      "Avg loss: 6.10246335145348e-05!\n",
      "Avg loss: 7.054384047781544e-05!\n",
      "Avg loss: 6.929239028825881e-05!\n",
      "Avg loss: 6.76612160532386e-05!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -601     |\n",
      "| time/              |          |\n",
      "|    fps             | 347      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -558     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 365      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 11       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.862    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00924  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 169      |\n",
      "|    policy_objective       | 0.0144   |\n",
      "|    std                    | 0.356    |\n",
      "|    value_loss             | 734      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -553     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 361      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.771    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00713  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 170      |\n",
      "|    policy_objective       | 0.016    |\n",
      "|    std                    | 0.353    |\n",
      "|    value_loss             | 558      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -579     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 356      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 23       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.88     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00911  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 171      |\n",
      "|    policy_objective       | 0.0226   |\n",
      "|    std                    | 0.349    |\n",
      "|    value_loss             | 522      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -541     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 359      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 28       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.728    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00627  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 172      |\n",
      "|    policy_objective       | 0.0134   |\n",
      "|    std                    | 0.348    |\n",
      "|    value_loss             | 574      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -516     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 349      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 35       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.848    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00772  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 173      |\n",
      "|    policy_objective       | 0.0326   |\n",
      "|    std                    | 0.347    |\n",
      "|    value_loss             | 443      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -502     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 350      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 40       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.815    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0091   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 174      |\n",
      "|    policy_objective       | 0.0176   |\n",
      "|    std                    | 0.347    |\n",
      "|    value_loss             | 684      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -493     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 350      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 46       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.857    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00995  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 175      |\n",
      "|    policy_objective       | 0.0154   |\n",
      "|    std                    | 0.35     |\n",
      "|    value_loss             | 482      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-156.5617831733078\n",
      "------------------------------\n",
      "round: 22\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.0005700017351773567!\n",
      "Avg loss: 0.00027473044150004474!\n",
      "Avg loss: 0.0003716496814740822!\n",
      "Avg loss: 9.722042843653374e-05!\n",
      "Avg loss: 0.00024394063591898885!\n",
      "Avg loss: 0.00010865774277287225!\n",
      "Avg loss: 7.396960076221149e-05!\n",
      "Avg loss: 9.043582350689879e-05!\n",
      "Avg loss: 6.388803883358681e-05!\n",
      "Avg loss: 7.904545188163563e-05!\n",
      "Avg loss: 4.806483079543492e-05!\n",
      "Avg loss: 5.617593991360081e-05!\n",
      "Avg loss: 6.120945078691876e-05!\n",
      "Avg loss: 4.47615665580751e-05!\n",
      "Avg loss: 5.023613031956605e-05!\n",
      "Avg loss: 4.431422870671516e-05!\n",
      "Avg loss: 5.435989225740438e-05!\n",
      "Avg loss: 4.5843707919933274e-05!\n",
      "Avg loss: 4.659274479990927e-05!\n",
      "Avg loss: 4.9963289855744125e-05!\n",
      "Avg loss: 4.913883177058172e-05!\n",
      "Avg loss: 4.830137938218589e-05!\n",
      "Avg loss: 4.5690519778910733e-05!\n",
      "Avg loss: 5.1968120939515456e-05!\n",
      "Avg loss: 4.739112780934344e-05!\n",
      "Avg loss: 4.939026969244272e-05!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.0005794991753646173!\n",
      "Avg loss: 0.0006582714409402494!\n",
      "Avg loss: 0.00047089110667002386!\n",
      "Avg loss: 0.0003557481998238169!\n",
      "Avg loss: 0.0002918522651937868!\n",
      "Avg loss: 0.00015871630776473467!\n",
      "Avg loss: 0.00020592382231067555!\n",
      "Avg loss: 0.00018529863788595928!\n",
      "Avg loss: 0.00016979840123288644!\n",
      "Avg loss: 9.968979225656463e-05!\n",
      "Avg loss: 0.00012225507675490613!\n",
      "Avg loss: 9.896582724801798e-05!\n",
      "Avg loss: 0.00011657660369517468!\n",
      "Avg loss: 8.834342425226775e-05!\n",
      "Avg loss: 0.00010909425614689402!\n",
      "Avg loss: 9.596778465493117e-05!\n",
      "Avg loss: 0.0001038790465342269!\n",
      "Avg loss: 0.00010252711645724351!\n",
      "Avg loss: 9.802635684764028e-05!\n",
      "Avg loss: 9.422219235678616e-05!\n",
      "Avg loss: 0.00010289029578927967!\n",
      "Avg loss: 0.0001060676766716521!\n",
      "Avg loss: 9.658747751871033e-05!\n",
      "Avg loss: 0.00010149575066937662!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.000970557555265259!\n",
      "Avg loss: 0.0005996417736150761!\n",
      "Avg loss: 0.0005488028014118148!\n",
      "Avg loss: 0.0005135784530322478!\n",
      "Avg loss: 0.00022548582513991276!\n",
      "Avg loss: 0.00017404979591447044!\n",
      "Avg loss: 0.00028380681638850546!\n",
      "Avg loss: 0.00019541227853854556!\n",
      "Avg loss: 0.00018942403070771737!\n",
      "Avg loss: 0.00012730298856723722!\n",
      "Avg loss: 0.00011845091041664091!\n",
      "Avg loss: 0.00010952044885319387!\n",
      "Avg loss: 0.00013900080685478618!\n",
      "Avg loss: 0.00011007646400078859!\n",
      "Avg loss: 9.867475139420398e-05!\n",
      "Avg loss: 0.00011302399434882205!\n",
      "Avg loss: 0.00010159750100683595!\n",
      "Avg loss: 0.00011268362120821015!\n",
      "Avg loss: 9.94527970064496e-05!\n",
      "Avg loss: 9.276471188494876e-05!\n",
      "Avg loss: 9.955349189264477e-05!\n",
      "Avg loss: 0.00010118091562778394!\n",
      "Avg loss: 9.760400969317592e-05!\n",
      "Avg loss: 9.783435743088376e-05!\n",
      "Avg loss: 9.864163742330826e-05!\n",
      "Avg loss: 9.93759665020851e-05!\n",
      "Avg loss: 9.45103200406076e-05!\n",
      "Avg loss: 9.599956273708206e-05!\n",
      "Avg loss: 9.803169403198809e-05!\n",
      "Avg loss: 9.617166859821206e-05!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -456     |\n",
      "| time/              |          |\n",
      "|    fps             | 333      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -487     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 317      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 12       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.846    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00825  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 177      |\n",
      "|    policy_objective       | 0.0212   |\n",
      "|    std                    | 0.347    |\n",
      "|    value_loss             | 423      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -529     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 316      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 19       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.862    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00947  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 178      |\n",
      "|    policy_objective       | 0.0201   |\n",
      "|    std                    | 0.345    |\n",
      "|    value_loss             | 413      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -528     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 311      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 26       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.871    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00857  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 179      |\n",
      "|    policy_objective       | 0.0196   |\n",
      "|    std                    | 0.35     |\n",
      "|    value_loss             | 402      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -505     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 309      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 33       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.88     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00896  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 180      |\n",
      "|    policy_objective       | 0.0133   |\n",
      "|    std                    | 0.339    |\n",
      "|    value_loss             | 596      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -477     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 310      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 39       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.896    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00814  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 181      |\n",
      "|    policy_objective       | 0.02     |\n",
      "|    std                    | 0.338    |\n",
      "|    value_loss             | 469      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -467     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 315      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 45       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.908    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00903  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 182      |\n",
      "|    policy_objective       | 0.0186   |\n",
      "|    std                    | 0.336    |\n",
      "|    value_loss             | 486      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -462     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 322      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 50       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.896    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00871  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 183      |\n",
      "|    policy_objective       | 0.0187   |\n",
      "|    std                    | 0.332    |\n",
      "|    value_loss             | 573      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-167.36910062208773\n",
      "------------------------------\n",
      "round: 23\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.0010162702998301636!\n",
      "Avg loss: 0.0006377777152132088!\n",
      "Avg loss: 0.0004967193757450635!\n",
      "Avg loss: 0.0003056873350093762!\n",
      "Avg loss: 0.0003320280300158629!\n",
      "Avg loss: 0.0004278472886168553!\n",
      "Avg loss: 0.00022110874140404728!\n",
      "Avg loss: 0.0001828742255687151!\n",
      "Avg loss: 0.0002905333302836273!\n",
      "Avg loss: 0.00023266911176657838!\n",
      "Avg loss: 0.00017022010876795927!\n",
      "Avg loss: 0.00019709974634679383!\n",
      "Avg loss: 0.00019986270188004104!\n",
      "Avg loss: 0.0001780910848841207!\n",
      "Avg loss: 0.00015713419671328665!\n",
      "Avg loss: 0.00016129426734740567!\n",
      "Avg loss: 0.0001851680784720126!\n",
      "Avg loss: 0.00017451039392123372!\n",
      "Avg loss: 0.00015632885060843667!\n",
      "Avg loss: 0.00016630837397618354!\n",
      "Avg loss: 0.0001843087036130934!\n",
      "Avg loss: 0.00017188532408795253!\n",
      "Avg loss: 0.00017079189575573158!\n",
      "Avg loss: 0.00017773430896302975!\n",
      "Avg loss: 0.00017193377380882188!\n",
      "Avg loss: 0.00017034732061328364!\n",
      "Avg loss: 0.00017339155497438696!\n",
      "Avg loss: 0.0001780271139659817!\n",
      "Avg loss: 0.00017844696853671848!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.005355614112243832!\n",
      "Avg loss: 0.005031944172672714!\n",
      "Avg loss: 0.005363496952498584!\n",
      "Avg loss: 0.004864468682474883!\n",
      "Avg loss: 0.004979190390004078!\n",
      "Avg loss: 0.004799916965416742!\n",
      "Avg loss: 0.004818811254514609!\n",
      "Avg loss: 0.004737041367149383!\n",
      "Avg loss: 0.004759556628308701!\n",
      "Avg loss: 0.0047286130408732184!\n",
      "Avg loss: 0.004706096257017786!\n",
      "Avg loss: 0.0046974235103008745!\n",
      "Avg loss: 0.0046782415145546945!\n",
      "Avg loss: 0.004686205978564431!\n",
      "Avg loss: 0.004700416214391225!\n",
      "Avg loss: 0.004663623747210105!\n",
      "Avg loss: 0.004656445287183336!\n",
      "Avg loss: 0.0046674410760302485!\n",
      "Avg loss: 0.004677602845563721!\n",
      "Avg loss: 0.004657516967778482!\n",
      "Avg loss: 0.004653382374640623!\n",
      "Avg loss: 0.004666010798754693!\n",
      "Avg loss: 0.004657883399919266!\n",
      "Avg loss: 0.004654721293151928!\n",
      "Avg loss: 0.004657517548111088!\n",
      "Avg loss: 0.0046567656128068315!\n",
      "Avg loss: 0.004653115354947464!\n",
      "Avg loss: 0.004657216860479896!\n",
      "Avg loss: 0.004654115870454802!\n",
      "Avg loss: 0.0046543018789522725!\n",
      "Avg loss: 0.0046530784037762864!\n",
      "Avg loss: 0.004655346048173972!\n",
      "Avg loss: 0.00465094825144926!\n",
      "Avg loss: 0.004653089663293031!\n",
      "Avg loss: 0.0046530488075457776!\n",
      "Avg loss: 0.004651830635560164!\n",
      "Avg loss: 0.004652318588010947!\n",
      "Avg loss: 0.004653511832597654!\n",
      "Avg loss: 0.004652265294277716!\n",
      "Avg loss: 0.004652506567373583!\n",
      "Avg loss: 0.0046524784256575915!\n",
      "Avg loss: 0.004651858488794763!\n",
      "Avg loss: 0.004649959382681601!\n",
      "Avg loss: 0.004650158306877093!\n",
      "Avg loss: 0.004651113261604228!\n",
      "Avg loss: 0.00465275014536284!\n",
      "Avg loss: 0.004651909788741951!\n",
      "Avg loss: 0.004651490678548847!\n",
      "Avg loss: 0.004649110753418313!\n",
      "Avg loss: 0.004650614385856357!\n",
      "Avg loss: 0.00464992178717291!\n",
      "Avg loss: 0.004649963419486909!\n",
      "Avg loss: 0.0046493348825224715!\n",
      "Avg loss: 0.004648624079745123!\n",
      "Avg loss: 0.004651876934821928!\n",
      "Avg loss: 0.004649019597265204!\n",
      "Avg loss: 0.0046529054101248826!\n",
      "Avg loss: 0.004650237543672991!\n",
      "Avg loss: 0.0046476864534927146!\n",
      "Avg loss: 0.004647931559255956!\n",
      "Avg loss: 0.004647781276431336!\n",
      "Avg loss: 0.004648209697249209!\n",
      "Avg loss: 0.004651083605918061!\n",
      "Avg loss: 0.004647663583241315!\n",
      "Avg loss: 0.00464836715116632!\n",
      "Avg loss: 0.004647374604924982!\n",
      "Avg loss: 0.004648033472617688!\n",
      "Avg loss: 0.004649514827777447!\n",
      "Avg loss: 0.004648816338954115!\n",
      "Avg loss: 0.0046465921499343685!\n",
      "Avg loss: 0.004645058866426458!\n",
      "Avg loss: 0.004643884803213562!\n",
      "Avg loss: 0.004645609368250897!\n",
      "Avg loss: 0.004646938569493671!\n",
      "Avg loss: 0.004648437156302568!\n",
      "Avg loss: 0.004644695759221046!\n",
      "Avg loss: 0.004646447461702354!\n",
      "Avg loss: 0.004646010513036103!\n",
      "Avg loss: 0.004647147521673366!\n",
      "Avg loss: 0.004643907451548823!\n",
      "Avg loss: 0.004647508415244157!\n",
      "Avg loss: 0.0046441959420412595!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.015375712876799905!\n",
      "Avg loss: 0.015339187657821943!\n",
      "Avg loss: 0.015642020207439298!\n",
      "Avg loss: 0.015655600127514237!\n",
      "Avg loss: 0.015282615849318972!\n",
      "Avg loss: 0.01528053395953369!\n",
      "Avg loss: 0.015281631433329798!\n",
      "Avg loss: 0.015275561687243453!\n",
      "Avg loss: 0.01538579045421405!\n",
      "Avg loss: 0.015319368802578311!\n",
      "Avg loss: 0.015205563531505201!\n",
      "Avg loss: 0.015171478790072494!\n",
      "Avg loss: 0.015331514818047556!\n",
      "Avg loss: 0.015313310762643462!\n",
      "Avg loss: 0.015172762983163739!\n",
      "Avg loss: 0.015197637175365533!\n",
      "Avg loss: 0.015270560134809395!\n",
      "Avg loss: 0.015240445126942935!\n",
      "Avg loss: 0.015183875679549411!\n",
      "Avg loss: 0.015237235909353946!\n",
      "Avg loss: 0.015202839545068514!\n",
      "Avg loss: 0.015239991350415873!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -439     |\n",
      "| time/              |          |\n",
      "|    fps             | 362      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -421     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 365      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 11       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.755    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00962  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 185      |\n",
      "|    policy_objective       | 0.018    |\n",
      "|    std                    | 0.339    |\n",
      "|    value_loss             | 487      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -474     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 360      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.91     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00739  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 186      |\n",
      "|    policy_objective       | 0.0184   |\n",
      "|    std                    | 0.338    |\n",
      "|    value_loss             | 471      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -486     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 359      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 22       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.92     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00892  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 187      |\n",
      "|    policy_objective       | 0.0173   |\n",
      "|    std                    | 0.333    |\n",
      "|    value_loss             | 442      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -465     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 361      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 28       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.873    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00854  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 188      |\n",
      "|    policy_objective       | 0.0179   |\n",
      "|    std                    | 0.325    |\n",
      "|    value_loss             | 497      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -490     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 355      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 34       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.93     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0081   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 189      |\n",
      "|    policy_objective       | 0.0194   |\n",
      "|    std                    | 0.315    |\n",
      "|    value_loss             | 414      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -506     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 351      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 40       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.801    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00904  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 190      |\n",
      "|    policy_objective       | 0.0168   |\n",
      "|    std                    | 0.306    |\n",
      "|    value_loss             | 391      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -524     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 346      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 47       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.918    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00931  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 191      |\n",
      "|    policy_objective       | 0.0191   |\n",
      "|    std                    | 0.308    |\n",
      "|    value_loss             | 521      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-208.07899495717137\n",
      "------------------------------\n",
      "round: 24\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.00047301665089131956!\n",
      "Avg loss: 0.0003889250762373801!\n",
      "Avg loss: 0.0002326191657690894!\n",
      "Avg loss: 0.0003451362390903038!\n",
      "Avg loss: 0.00014674799586524993!\n",
      "Avg loss: 0.00020041597055808324!\n",
      "Avg loss: 0.00013431266346439468!\n",
      "Avg loss: 0.00011280497554423619!\n",
      "Avg loss: 8.675302737894223e-05!\n",
      "Avg loss: 0.00011979030562846068!\n",
      "Avg loss: 9.70159229118887e-05!\n",
      "Avg loss: 9.653846936525194e-05!\n",
      "Avg loss: 9.954734466039857e-05!\n",
      "Avg loss: 0.00010690682023512939!\n",
      "Avg loss: 9.590354813402276e-05!\n",
      "Avg loss: 9.019833717028784e-05!\n",
      "Avg loss: 8.641273052338268e-05!\n",
      "Avg loss: 9.307418642417057e-05!\n",
      "Avg loss: 8.611196338665176e-05!\n",
      "Avg loss: 8.25924228979602e-05!\n",
      "Avg loss: 8.34857828508954e-05!\n",
      "Avg loss: 8.50084383741508e-05!\n",
      "Avg loss: 8.372569205221225e-05!\n",
      "Avg loss: 8.379903501122499e-05!\n",
      "Avg loss: 8.398196351805609e-05!\n",
      "Avg loss: 8.270962432372168e-05!\n",
      "Avg loss: 8.231082364972053e-05!\n",
      "Avg loss: 8.405408828934924e-05!\n",
      "Avg loss: 8.342693192901151e-05!\n",
      "Avg loss: 8.315339855452445e-05!\n",
      "Avg loss: 8.323960529007005e-05!\n",
      "Avg loss: 8.322804733097655e-05!\n",
      "Avg loss: 8.35885189061969e-05!\n",
      "Avg loss: 8.298803160708227e-05!\n",
      "Avg loss: 8.320032367464591e-05!\n",
      "Avg loss: 8.329066820503309e-05!\n",
      "Avg loss: 8.129373702189468e-05!\n",
      "Avg loss: 8.132144557843427e-05!\n",
      "Avg loss: 7.951762494845601e-05!\n",
      "Avg loss: 7.964274643391889e-05!\n",
      "Avg loss: 7.991568409693173e-05!\n",
      "Avg loss: 7.965990743353283e-05!\n",
      "Avg loss: 8.23534539404136e-05!\n",
      "Avg loss: 8.100190777895477e-05!\n",
      "Avg loss: 8.194309860537411e-05!\n",
      "Avg loss: 8.215808812650494e-05!\n",
      "Avg loss: 8.140819153785135e-05!\n",
      "Avg loss: 8.124477440427806e-05!\n",
      "Avg loss: 8.182269252192971e-05!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.000314706130787575!\n",
      "Avg loss: 0.00041083853428062865!\n",
      "Avg loss: 0.0002667556772454797!\n",
      "Avg loss: 0.00021774041044106223!\n",
      "Avg loss: 0.00022951580952697745!\n",
      "Avg loss: 0.00018749192711917808!\n",
      "Avg loss: 0.00013715701812619347!\n",
      "Avg loss: 0.0001302553360293738!\n",
      "Avg loss: 0.00018001432834050018!\n",
      "Avg loss: 0.00013522439358212068!\n",
      "Avg loss: 9.135896622789612e-05!\n",
      "Avg loss: 0.00010478875177492833!\n",
      "Avg loss: 0.00012794044545595776!\n",
      "Avg loss: 0.00010687022910739566!\n",
      "Avg loss: 0.00010128900724320526!\n",
      "Avg loss: 0.00011336070095846178!\n",
      "Avg loss: 0.00011407784679704492!\n",
      "Avg loss: 0.00011223044098206476!\n",
      "Avg loss: 0.00011494720103407019!\n",
      "Avg loss: 0.00010884897721704571!\n",
      "Avg loss: 0.00010692291350248221!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0008481867955803561!\n",
      "Avg loss: 0.000681063675947371!\n",
      "Avg loss: 0.00045053222464048304!\n",
      "Avg loss: 0.0005090409481757281!\n",
      "Avg loss: 0.0002644366079402971!\n",
      "Avg loss: 0.00021116432346389048!\n",
      "Avg loss: 0.00019181935327045114!\n",
      "Avg loss: 0.0003308270102449266!\n",
      "Avg loss: 0.00020515246106697304!\n",
      "Avg loss: 0.00013568717795502987!\n",
      "Avg loss: 0.00016157593211725422!\n",
      "Avg loss: 0.00020571517779444549!\n",
      "Avg loss: 0.00018809184737544153!\n",
      "Avg loss: 0.00013983402265182576!\n",
      "Avg loss: 0.0001481020558541483!\n",
      "Avg loss: 0.00016264509574511976!\n",
      "Avg loss: 0.00016779514789353318!\n",
      "Avg loss: 0.00014865355558602762!\n",
      "Avg loss: 0.00014788478068718784!\n",
      "Avg loss: 0.0001559906600918263!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -662     |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -621     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 290      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 14       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.886    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00949  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 193      |\n",
      "|    policy_objective       | 0.0219   |\n",
      "|    std                    | 0.295    |\n",
      "|    value_loss             | 483      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -536     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 298      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 20       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.922    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00969  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 194      |\n",
      "|    policy_objective       | 0.0177   |\n",
      "|    std                    | 0.29     |\n",
      "|    value_loss             | 493      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -522     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 303      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 26       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.887    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00834  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 195      |\n",
      "|    policy_objective       | 0.0203   |\n",
      "|    std                    | 0.292    |\n",
      "|    value_loss             | 465      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -496     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 309      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 33       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.812    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00887  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 196      |\n",
      "|    policy_objective       | 0.0114   |\n",
      "|    std                    | 0.288    |\n",
      "|    value_loss             | 735      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -499     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 312      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 39       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.869    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00892  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 197      |\n",
      "|    policy_objective       | 0.0162   |\n",
      "|    std                    | 0.286    |\n",
      "|    value_loss             | 603      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -506     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 319      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 44       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.89     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00977  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 198      |\n",
      "|    policy_objective       | 0.0162   |\n",
      "|    std                    | 0.286    |\n",
      "|    value_loss             | 570      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -525     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 320      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 51       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.826    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00636  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 199      |\n",
      "|    policy_objective       | 0.014    |\n",
      "|    std                    | 0.281    |\n",
      "|    value_loss             | 427      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-143.8481327002868\n",
      "------------------------------\n",
      "round: 25\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.005908909195907957!\n",
      "Avg loss: 0.005430002030423869!\n",
      "Avg loss: 0.005719002043939933!\n",
      "Avg loss: 0.005556549241749357!\n",
      "Avg loss: 0.005368652816371953!\n",
      "Avg loss: 0.005319093389516638!\n",
      "Avg loss: 0.005398368289907012!\n",
      "Avg loss: 0.00539402518541768!\n",
      "Avg loss: 0.005282351113179781!\n",
      "Avg loss: 0.005294852340261969!\n",
      "Avg loss: 0.005298494402503214!\n",
      "Avg loss: 0.0053278290950947845!\n",
      "Avg loss: 0.005261098418272923!\n",
      "Avg loss: 0.005273917081525876!\n",
      "Avg loss: 0.005286963045848931!\n",
      "Avg loss: 0.005292854243843029!\n",
      "Avg loss: 0.005264514653252566!\n",
      "Avg loss: 0.005276624655067839!\n",
      "Avg loss: 0.005287719797369922!\n",
      "Avg loss: 0.005282870534093338!\n",
      "Avg loss: 0.0052693444410906905!\n",
      "Avg loss: 0.005284515929914069!\n",
      "Avg loss: 0.0052844855990764475!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.0006451421937284371!\n",
      "Avg loss: 0.0003567326751362998!\n",
      "Avg loss: 0.0003586791705189777!\n",
      "Avg loss: 0.00020049653197171815!\n",
      "Avg loss: 0.00010038790278637559!\n",
      "Avg loss: 0.00014185913518910336!\n",
      "Avg loss: 0.00015193674507827382!\n",
      "Avg loss: 6.947992970708583e-05!\n",
      "Avg loss: 6.159897132420156e-05!\n",
      "Avg loss: 7.005172813326984e-05!\n",
      "Avg loss: 7.135610582887846e-05!\n",
      "Avg loss: 5.230951393931112e-05!\n",
      "Avg loss: 4.110221954154743e-05!\n",
      "Avg loss: 4.017284310066316e-05!\n",
      "Avg loss: 4.0725188546275605e-05!\n",
      "Avg loss: 4.418210017547608e-05!\n",
      "Avg loss: 3.977678005715764e-05!\n",
      "Avg loss: 3.1422927391417944e-05!\n",
      "Avg loss: 3.722840314897743e-05!\n",
      "Avg loss: 4.069000811720495e-05!\n",
      "Avg loss: 3.541106713782938e-05!\n",
      "Avg loss: 3.3077919211640014e-05!\n",
      "Avg loss: 3.80224075085304e-05!\n",
      "Avg loss: 3.381017595453765e-05!\n",
      "Avg loss: 3.616802282825423e-05!\n",
      "Avg loss: 3.326637619390264e-05!\n",
      "Avg loss: 3.565642521872784e-05!\n",
      "Avg loss: 3.605515539978417e-05!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.000616272093951314!\n",
      "Avg loss: 0.0005989922911976464!\n",
      "Avg loss: 0.0001482386997683231!\n",
      "Avg loss: 0.00017727507078234338!\n",
      "Avg loss: 0.00024374721956216188!\n",
      "Avg loss: 0.0002595835015290504!\n",
      "Avg loss: 0.00012846108288310158!\n",
      "Avg loss: 0.00010553620459783512!\n",
      "Avg loss: 0.00012584596056058216!\n",
      "Avg loss: 0.00019045876654672612!\n",
      "Avg loss: 0.00010847437829468732!\n",
      "Avg loss: 9.189554657647629e-05!\n",
      "Avg loss: 0.0001100150017462435!\n",
      "Avg loss: 0.00014029603697205553!\n",
      "Avg loss: 0.00010750278829258757!\n",
      "Avg loss: 9.900655825276772e-05!\n",
      "Avg loss: 0.00011311552520851365!\n",
      "Avg loss: 0.00012602076878048745!\n",
      "Avg loss: 0.00010870585178357336!\n",
      "Avg loss: 0.00010352591931725405!\n",
      "Avg loss: 0.00011412045090802772!\n",
      "Avg loss: 0.00011537431643262153!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -455     |\n",
      "| time/              |          |\n",
      "|    fps             | 299      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -433     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 307      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 13       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.848    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00977  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 201      |\n",
      "|    policy_objective       | 0.0254   |\n",
      "|    std                    | 0.281    |\n",
      "|    value_loss             | 409      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -423     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 296      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 20       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.839    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0095   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 202      |\n",
      "|    policy_objective       | 0.0174   |\n",
      "|    std                    | 0.274    |\n",
      "|    value_loss             | 628      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -417     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 288      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 28       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.822    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00793  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 203      |\n",
      "|    policy_objective       | 0.0121   |\n",
      "|    std                    | 0.27     |\n",
      "|    value_loss             | 427      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -457     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 303      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 33       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.891    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00937  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 204      |\n",
      "|    policy_objective       | 0.0147   |\n",
      "|    std                    | 0.268    |\n",
      "|    value_loss             | 480      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -447     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 304      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 40       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.845    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00892  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 205      |\n",
      "|    policy_objective       | 0.0124   |\n",
      "|    std                    | 0.255    |\n",
      "|    value_loss             | 416      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -457     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 312      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 45       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.824    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00907  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 206      |\n",
      "|    policy_objective       | 0.0167   |\n",
      "|    std                    | 0.246    |\n",
      "|    value_loss             | 362      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -463     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 313      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 52       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.865    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00896  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 207      |\n",
      "|    policy_objective       | 0.0183   |\n",
      "|    std                    | 0.251    |\n",
      "|    value_loss             | 412      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-150.1074405770749\n",
      "------------------------------\n",
      "round: 26\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.004430670024400267!\n",
      "Avg loss: 0.004231968593327717!\n",
      "Avg loss: 0.004093725683687808!\n",
      "Avg loss: 0.003976156569588056!\n",
      "Avg loss: 0.004112066220962636!\n",
      "Avg loss: 0.004008704366236391!\n",
      "Avg loss: 0.003906768337546964!\n",
      "Avg loss: 0.003933574032459243!\n",
      "Avg loss: 0.003950298575167229!\n",
      "Avg loss: 0.003901899562234803!\n",
      "Avg loss: 0.0039099125743086915!\n",
      "Avg loss: 0.003944531478612514!\n",
      "Avg loss: 0.003899835031023334!\n",
      "Avg loss: 0.003895958346350407!\n",
      "Avg loss: 0.003924339416296476!\n",
      "Avg loss: 0.003915925677033556!\n",
      "Avg loss: 0.0039010701471419414!\n",
      "Avg loss: 0.0039010170268329604!\n",
      "Avg loss: 0.003912727897406967!\n",
      "Avg loss: 0.003895068207013234!\n",
      "Avg loss: 0.0038935045657855958!\n",
      "Avg loss: 0.0039037543494278757!\n",
      "Avg loss: 0.0038935085618322773!\n",
      "Avg loss: 0.0038963116050164596!\n",
      "Avg loss: 0.0039061352913650656!\n",
      "Avg loss: 0.0038971270979726567!\n",
      "Avg loss: 0.00390123829320828!\n",
      "Avg loss: 0.0039026136408403054!\n",
      "Avg loss: 0.003899981439595308!\n",
      "Avg loss: 0.003900553146513725!\n",
      "Avg loss: 0.003900896853370976!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.0006790775449189823!\n",
      "Avg loss: 0.0005659604754934359!\n",
      "Avg loss: 0.0003205959303401566!\n",
      "Avg loss: 0.000279513913167951!\n",
      "Avg loss: 0.00014392584646657269!\n",
      "Avg loss: 0.00012551662455886496!\n",
      "Avg loss: 0.00015202071579248393!\n",
      "Avg loss: 0.00011789698100074019!\n",
      "Avg loss: 4.6135837293377336e-05!\n",
      "Avg loss: 7.543697733960168e-05!\n",
      "Avg loss: 4.184028147543965e-05!\n",
      "Avg loss: 7.638035708017318e-05!\n",
      "Avg loss: 5.395512699360931e-05!\n",
      "Avg loss: 4.265125719863742e-05!\n",
      "Avg loss: 3.8758011306375314e-05!\n",
      "Avg loss: 4.581773143172541e-05!\n",
      "Avg loss: 4.8337964005137714e-05!\n",
      "Avg loss: 3.7547848807738165e-05!\n",
      "Avg loss: 3.921631547408803e-05!\n",
      "Avg loss: 4.112815493726885e-05!\n",
      "Avg loss: 4.368227362344138e-05!\n",
      "Avg loss: 4.112604860703565e-05!\n",
      "Avg loss: 3.6743956919546386e-05!\n",
      "Avg loss: 3.980104558934272e-05!\n",
      "Avg loss: 3.8541561464361016e-05!\n",
      "Avg loss: 4.168779591125826e-05!\n",
      "Avg loss: 3.75385716843842e-05!\n",
      "Avg loss: 4.248811939675079e-05!\n",
      "Avg loss: 4.065846402719823e-05!\n",
      "Avg loss: 3.887917098632935e-05!\n",
      "Avg loss: 3.799117357923857e-05!\n",
      "Avg loss: 4.214854418961522e-05!\n",
      "Avg loss: 4.141401497688453e-05!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0012565612578570532!\n",
      "Avg loss: 0.000725193792071271!\n",
      "Avg loss: 0.00040465857391003133!\n",
      "Avg loss: 0.000310869972963701!\n",
      "Avg loss: 0.0002984859122928659!\n",
      "Avg loss: 0.0001828987985815426!\n",
      "Avg loss: 0.00012960195342505662!\n",
      "Avg loss: 0.0002355148647908815!\n",
      "Avg loss: 0.00011308740222375491!\n",
      "Avg loss: 9.104933627895661e-05!\n",
      "Avg loss: 7.184422326834768e-05!\n",
      "Avg loss: 0.00010159917483785345!\n",
      "Avg loss: 9.65191429026883e-05!\n",
      "Avg loss: 8.419921567565325e-05!\n",
      "Avg loss: 8.406269371448616e-05!\n",
      "Avg loss: 6.759862477186591e-05!\n",
      "Avg loss: 7.092799431916319e-05!\n",
      "Avg loss: 8.662860270571097e-05!\n",
      "Avg loss: 8.108233063846152e-05!\n",
      "Avg loss: 6.990893592141372e-05!\n",
      "Avg loss: 7.009049031050078e-05!\n",
      "Avg loss: 7.717067567000413e-05!\n",
      "Avg loss: 7.30998339256909e-05!\n",
      "Avg loss: 7.323852435736928e-05!\n",
      "Avg loss: 7.744776648526871e-05!\n",
      "Avg loss: 6.883074943933328e-05!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -591     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -448     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 378      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 10       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.831    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00903  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 209      |\n",
      "|    policy_objective       | 0.017    |\n",
      "|    std                    | 0.258    |\n",
      "|    value_loss             | 509      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -428     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 359      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.905    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0096   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 210      |\n",
      "|    policy_objective       | 0.0189   |\n",
      "|    std                    | 0.257    |\n",
      "|    value_loss             | 376      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -439     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 362      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 22       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.897    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00864  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 211      |\n",
      "|    policy_objective       | 0.0176   |\n",
      "|    std                    | 0.249    |\n",
      "|    value_loss             | 517      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -431     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 361      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 28       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.911    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0086   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 212      |\n",
      "|    policy_objective       | 0.0167   |\n",
      "|    std                    | 0.243    |\n",
      "|    value_loss             | 580      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -431     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 357      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 34       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.879    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0095   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 213      |\n",
      "|    policy_objective       | 0.0265   |\n",
      "|    std                    | 0.239    |\n",
      "|    value_loss             | 412      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -414     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 360      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 39       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.823    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00948  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 214      |\n",
      "|    policy_objective       | 0.0195   |\n",
      "|    std                    | 0.237    |\n",
      "|    value_loss             | 473      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -411     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 355      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 46       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.905    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0089   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 215      |\n",
      "|    policy_objective       | 0.0204   |\n",
      "|    std                    | 0.229    |\n",
      "|    value_loss             | 377      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-200.99566091261804\n",
      "------------------------------\n",
      "round: 27\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.0034791638871926505!\n",
      "Avg loss: 0.0030569279869208307!\n",
      "Avg loss: 0.0030235938920426027!\n",
      "Avg loss: 0.00279048275050324!\n",
      "Avg loss: 0.0030557790742022917!\n",
      "Avg loss: 0.0028210134887558524!\n",
      "Avg loss: 0.002768905947353536!\n",
      "Avg loss: 0.002728878123657523!\n",
      "Avg loss: 0.002877984941909138!\n",
      "Avg loss: 0.0027636868993219346!\n",
      "Avg loss: 0.0027235257469268013!\n",
      "Avg loss: 0.0027436307714613878!\n",
      "Avg loss: 0.0027785756624136107!\n",
      "Avg loss: 0.0027260111169039192!\n",
      "Avg loss: 0.002732045839350879!\n",
      "Avg loss: 0.0027410066884021944!\n",
      "Avg loss: 0.0027491969307709497!\n",
      "Avg loss: 0.0027314694022298153!\n",
      "Avg loss: 0.0027250153811833873!\n",
      "Avg loss: 0.0027461022293778113!\n",
      "Avg loss: 0.0027377404011613747!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.000505386282748077!\n",
      "Avg loss: 0.0004303324038119172!\n",
      "Avg loss: 0.0003398156560918627!\n",
      "Avg loss: 0.0001591254129925801!\n",
      "Avg loss: 0.0002831227889691945!\n",
      "Avg loss: 6.62958043388547e-05!\n",
      "Avg loss: 0.0001410114373053754!\n",
      "Avg loss: 4.7411978359453616e-05!\n",
      "Avg loss: 6.219266974615796e-05!\n",
      "Avg loss: 5.456066228892572e-05!\n",
      "Avg loss: 9.759037156650645e-06!\n",
      "Avg loss: 3.990466353116062e-05!\n",
      "Avg loss: 1.2941629114825066e-05!\n",
      "Avg loss: 1.636058154171375e-05!\n",
      "Avg loss: 2.0293119028641134e-05!\n",
      "Avg loss: 9.986473079332351e-06!\n",
      "Avg loss: 8.433983117157595e-06!\n",
      "Avg loss: 8.685456388851284e-06!\n",
      "Avg loss: 8.480098228934215e-06!\n",
      "Avg loss: 6.572889330177153e-06!\n",
      "Avg loss: 7.513323089464545e-06!\n",
      "Avg loss: 6.453659818153786e-06!\n",
      "Avg loss: 4.498255466671708e-06!\n",
      "Avg loss: 6.83133268393495e-06!\n",
      "Avg loss: 6.2183913709172125e-06!\n",
      "Avg loss: 4.2934407584264515e-06!\n",
      "Avg loss: 5.6156960114606135e-06!\n",
      "Avg loss: 5.316964248862632e-06!\n",
      "Avg loss: 5.295052035284205e-06!\n",
      "Avg loss: 5.567968503508899e-06!\n",
      "Avg loss: 4.986361311386152e-06!\n",
      "Avg loss: 5.172765612222463e-06!\n",
      "Avg loss: 5.374716648821239e-06!\n",
      "Avg loss: 5.073964798090931e-06!\n",
      "Avg loss: 5.32896384286848e-06!\n",
      "Avg loss: 5.011727340142139e-06!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0006063955290483136!\n",
      "Avg loss: 0.00014684730844843823!\n",
      "Avg loss: 0.0005609017232685194!\n",
      "Avg loss: 8.124312966477495e-05!\n",
      "Avg loss: 0.00019708361373583708!\n",
      "Avg loss: 8.000428138378387e-05!\n",
      "Avg loss: 0.00015000023636578893!\n",
      "Avg loss: 4.521780875014277e-05!\n",
      "Avg loss: 3.9164328624489525e-05!\n",
      "Avg loss: 5.285064819493831e-05!\n",
      "Avg loss: 4.2342340863494123e-05!\n",
      "Avg loss: 2.3820152581682426e-05!\n",
      "Avg loss: 2.334775113164748e-05!\n",
      "Avg loss: 3.4074770331547675e-05!\n",
      "Avg loss: 1.7157084725643776e-05!\n",
      "Avg loss: 1.4768345877958685e-05!\n",
      "Avg loss: 2.705008352487918e-05!\n",
      "Avg loss: 1.654418479015855e-05!\n",
      "Avg loss: 1.4690773791912193e-05!\n",
      "Avg loss: 1.909467123861456e-05!\n",
      "Avg loss: 1.743805911303298e-05!\n",
      "Avg loss: 1.524209751626889e-05!\n",
      "Avg loss: 1.8568652128389354e-05!\n",
      "Avg loss: 1.5037246197569706e-05!\n",
      "Avg loss: 1.5873148570525093e-05!\n",
      "Avg loss: 1.7185731309486603e-05!\n",
      "Avg loss: 1.6967913613067746e-05!\n",
      "Avg loss: 1.4301998185525614e-05!\n",
      "Avg loss: 1.8101116991431355e-05!\n",
      "Avg loss: 1.4385042091191735e-05!\n",
      "Avg loss: 1.6589951091342906e-05!\n",
      "Avg loss: 1.53925951772275e-05!\n",
      "Avg loss: 1.6543710738782617e-05!\n",
      "Avg loss: 1.5205017590555295e-05!\n",
      "Avg loss: 1.5966593516421786e-05!\n",
      "Avg loss: 1.4723410217053849e-05!\n",
      "Avg loss: 1.5876119985781163e-05!\n",
      "Avg loss: 1.4993710490595428e-05!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -465     |\n",
      "| time/              |          |\n",
      "|    fps             | 411      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -488     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 377      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 10       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.818    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00669  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 217      |\n",
      "|    policy_objective       | 0.0156   |\n",
      "|    std                    | 0.218    |\n",
      "|    value_loss             | 484      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -517     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 345      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.884    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00884  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 218      |\n",
      "|    policy_objective       | 0.0153   |\n",
      "|    std                    | 0.219    |\n",
      "|    value_loss             | 584      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -525     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 333      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 24       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.872    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0097   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 219      |\n",
      "|    policy_objective       | 0.0182   |\n",
      "|    std                    | 0.223    |\n",
      "|    value_loss             | 666      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -503     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 334      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 30       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.906    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00895  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 220      |\n",
      "|    policy_objective       | 0.0164   |\n",
      "|    std                    | 0.227    |\n",
      "|    value_loss             | 437      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -489     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 337      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 36       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.914    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00953  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 221      |\n",
      "|    policy_objective       | 0.0167   |\n",
      "|    std                    | 0.226    |\n",
      "|    value_loss             | 432      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -496     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 338      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 42       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.858    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0093   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 222      |\n",
      "|    policy_objective       | 0.0222   |\n",
      "|    std                    | 0.226    |\n",
      "|    value_loss             | 655      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -502     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 338      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 48       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.904    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00953  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 223      |\n",
      "|    policy_objective       | 0.0223   |\n",
      "|    std                    | 0.228    |\n",
      "|    value_loss             | 490      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-209.2300049532205\n",
      "------------------------------\n",
      "round: 28\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.0005128015870286617!\n",
      "Avg loss: 0.0002809878995321924!\n",
      "Avg loss: 0.00036378466742462476!\n",
      "Avg loss: 0.00019660279715026264!\n",
      "Avg loss: 0.0001077881428955152!\n",
      "Avg loss: 0.0001705930738777776!\n",
      "Avg loss: 8.59240582296176e-05!\n",
      "Avg loss: 6.829729115755374e-05!\n",
      "Avg loss: 7.144387413063669e-05!\n",
      "Avg loss: 8.739094490541295e-05!\n",
      "Avg loss: 6.589114760951513e-05!\n",
      "Avg loss: 4.6391348970473704e-05!\n",
      "Avg loss: 6.640445810338255e-05!\n",
      "Avg loss: 5.1463538273613573e-05!\n",
      "Avg loss: 5.336189447386156e-05!\n",
      "Avg loss: 6.10930129758458e-05!\n",
      "Avg loss: 4.4978623962682224e-05!\n",
      "Avg loss: 5.027264706010707e-05!\n",
      "Avg loss: 5.473923272016161e-05!\n",
      "Avg loss: 4.9472837616425144e-05!\n",
      "Avg loss: 4.550044163579514e-05!\n",
      "Avg loss: 5.113265678839222e-05!\n",
      "Avg loss: 5.1188462051262226e-05!\n",
      "Avg loss: 4.843920023669549e-05!\n",
      "Avg loss: 4.9804226130921354e-05!\n",
      "Avg loss: 4.940082065104434e-05!\n",
      "Avg loss: 4.954588045999723e-05!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.0008704150056776901!\n",
      "Avg loss: 0.0008278204252807578!\n",
      "Avg loss: 0.0003282525147854661!\n",
      "Avg loss: 0.00028603807075645214!\n",
      "Avg loss: 0.00030988866036447385!\n",
      "Avg loss: 0.0001867168249570265!\n",
      "Avg loss: 0.0001569570016082859!\n",
      "Avg loss: 0.00018378206414733237!\n",
      "Avg loss: 0.00016081461904226066!\n",
      "Avg loss: 7.14463782871159e-05!\n",
      "Avg loss: 0.00012336644707526526!\n",
      "Avg loss: 0.00012724272812192794!\n",
      "Avg loss: 0.00010433132648927312!\n",
      "Avg loss: 9.985321722221367e-05!\n",
      "Avg loss: 8.31658281019069e-05!\n",
      "Avg loss: 0.00011057685448880268!\n",
      "Avg loss: 9.838395905376274e-05!\n",
      "Avg loss: 7.79226211668534e-05!\n",
      "Avg loss: 9.856697054298518e-05!\n",
      "Avg loss: 0.00010159086806538653!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.009495331595923442!\n",
      "Avg loss: 0.008930523026562392!\n",
      "Avg loss: 0.009417152267851635!\n",
      "Avg loss: 0.009021460519032682!\n",
      "Avg loss: 0.009017796945251273!\n",
      "Avg loss: 0.008913813801443666!\n",
      "Avg loss: 0.008951441814967135!\n",
      "Avg loss: 0.008970137834111635!\n",
      "Avg loss: 0.008884862017162808!\n",
      "Avg loss: 0.008871838674732164!\n",
      "Avg loss: 0.008916833868588582!\n",
      "Avg loss: 0.008911869843918794!\n",
      "Avg loss: 0.008871841718899702!\n",
      "Avg loss: 0.008864360012929258!\n",
      "Avg loss: 0.0088791787631961!\n",
      "Avg loss: 0.008887095093612818!\n",
      "Avg loss: 0.008865874092942363!\n",
      "Avg loss: 0.008868279928224561!\n",
      "Avg loss: 0.008881249496853722!\n",
      "Avg loss: 0.008870722014384854!\n",
      "Avg loss: 0.008866915992870948!\n",
      "Avg loss: 0.00887040291525627!\n",
      "Avg loss: 0.008872058281732886!\n",
      "Avg loss: 0.008865722907463578!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -608     |\n",
      "| time/              |          |\n",
      "|    fps             | 396      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -544     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 362      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 11       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.885    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00905  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 225      |\n",
      "|    policy_objective       | 0.0166   |\n",
      "|    std                    | 0.222    |\n",
      "|    value_loss             | 604      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -512     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 362      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 16       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.883    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00989  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 226      |\n",
      "|    policy_objective       | 0.019    |\n",
      "|    std                    | 0.216    |\n",
      "|    value_loss             | 574      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -517     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 362      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 22       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.916    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0068   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 227      |\n",
      "|    policy_objective       | 0.0152   |\n",
      "|    std                    | 0.213    |\n",
      "|    value_loss             | 487      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -486     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 363      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 28       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.855    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00904  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 228      |\n",
      "|    policy_objective       | 0.0173   |\n",
      "|    std                    | 0.205    |\n",
      "|    value_loss             | 586      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -480     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 362      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 33       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.916    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00911  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 229      |\n",
      "|    policy_objective       | 0.019    |\n",
      "|    std                    | 0.196    |\n",
      "|    value_loss             | 441      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -489     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 360      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 39       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.925    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00952  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 230      |\n",
      "|    policy_objective       | 0.0152   |\n",
      "|    std                    | 0.197    |\n",
      "|    value_loss             | 490      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -483     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 358      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 45       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.86     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00871  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 231      |\n",
      "|    policy_objective       | 0.0147   |\n",
      "|    std                    | 0.197    |\n",
      "|    value_loss             | 481      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-172.16850874321534\n",
      "------------------------------\n",
      "round: 29\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.0007050160969568727!\n",
      "Avg loss: 0.0005505656792471806!\n",
      "Avg loss: 0.0002794464791986684!\n",
      "Avg loss: 0.00014617742841162832!\n",
      "Avg loss: 0.0003789550148940179!\n",
      "Avg loss: 0.00010512208301709809!\n",
      "Avg loss: 0.00013487358716398983!\n",
      "Avg loss: 0.0001874356892327948!\n",
      "Avg loss: 0.00022140460221028963!\n",
      "Avg loss: 7.245931806513302e-05!\n",
      "Avg loss: 6.849372019132716e-05!\n",
      "Avg loss: 0.00015369844194234854!\n",
      "Avg loss: 0.00015381337055562957!\n",
      "Avg loss: 9.153713861148087e-05!\n",
      "Avg loss: 9.404157238047143e-05!\n",
      "Avg loss: 0.00012658181150773846!\n",
      "Avg loss: 0.00010373000273527092!\n",
      "Avg loss: 0.00010332194935775381!\n",
      "Avg loss: 0.00012240393310283555!\n",
      "Avg loss: 0.00010644035447209414!\n",
      "Avg loss: 9.609135183685187e-05!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.0005789828415921268!\n",
      "Avg loss: 0.0004655961410996194!\n",
      "Avg loss: 0.0003016796289011836!\n",
      "Avg loss: 0.00015408162837199295!\n",
      "Avg loss: 0.00027371118350856706!\n",
      "Avg loss: 0.00011494086557756114!\n",
      "Avg loss: 0.00011144566900838981!\n",
      "Avg loss: 5.272281940506218e-05!\n",
      "Avg loss: 0.00011188503143178726!\n",
      "Avg loss: 6.019880841298194e-05!\n",
      "Avg loss: 5.69164398007634e-05!\n",
      "Avg loss: 2.49919140522555e-05!\n",
      "Avg loss: 5.377625342665245e-05!\n",
      "Avg loss: 3.6663426205147216e-05!\n",
      "Avg loss: 2.87408342804459e-05!\n",
      "Avg loss: 2.4815264719393326e-05!\n",
      "Avg loss: 3.618043172120148e-05!\n",
      "Avg loss: 2.46365500538559e-05!\n",
      "Avg loss: 2.5697926027229793e-05!\n",
      "Avg loss: 2.8320187990781657e-05!\n",
      "Avg loss: 2.7681049987885824e-05!\n",
      "Avg loss: 1.996491888841471e-05!\n",
      "Avg loss: 2.477650408896655e-05!\n",
      "Avg loss: 2.7383964846497594e-05!\n",
      "Avg loss: 2.4352913053746762e-05!\n",
      "Avg loss: 2.1701886068209813e-05!\n",
      "Avg loss: 2.6693692848785607e-05!\n",
      "Avg loss: 2.4161905621156166e-05!\n",
      "Avg loss: 2.2240914971310608e-05!\n",
      "Avg loss: 2.3293618552315822e-05!\n",
      "Avg loss: 2.5975072992613e-05!\n",
      "Avg loss: 2.6500123750755242e-05!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0013414193239683907!\n",
      "Avg loss: 0.0004265917055939402!\n",
      "Avg loss: 0.0005421670359100971!\n",
      "Avg loss: 0.00024287647679254102!\n",
      "Avg loss: 0.00030326192976644963!\n",
      "Avg loss: 9.332714419391172e-05!\n",
      "Avg loss: 0.00011235791852262385!\n",
      "Avg loss: 0.00016511144841691323!\n",
      "Avg loss: 5.752920124450611e-05!\n",
      "Avg loss: 5.568275745342059e-05!\n",
      "Avg loss: 4.180665437881241e-05!\n",
      "Avg loss: 8.186315540569921e-05!\n",
      "Avg loss: 5.6569934052580114e-05!\n",
      "Avg loss: 3.5977737374726834e-05!\n",
      "Avg loss: 4.765058059092553e-05!\n",
      "Avg loss: 4.1616794513477845e-05!\n",
      "Avg loss: 4.504515630439225e-05!\n",
      "Avg loss: 4.124236009279987e-05!\n",
      "Avg loss: 3.6318867850582136e-05!\n",
      "Avg loss: 3.528396533946913e-05!\n",
      "Avg loss: 4.211146737740516e-05!\n",
      "Avg loss: 4.035458565757229e-05!\n",
      "Avg loss: 3.6226474338718615e-05!\n",
      "Avg loss: 3.4434235270074015e-05!\n",
      "Avg loss: 3.871606299251577e-05!\n",
      "Avg loss: 3.76015858385396e-05!\n",
      "Avg loss: 4.108423103360792e-05!\n",
      "Avg loss: 3.798526842350232e-05!\n",
      "Avg loss: 3.9221728879160386e-05!\n",
      "Avg loss: 3.767523231218206e-05!\n",
      "Avg loss: 3.95784116577147e-05!\n",
      "Avg loss: 3.7548786543363616e-05!\n",
      "Avg loss: 3.939740397849316e-05!\n",
      "Avg loss: 3.827964134795062e-05!\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -587     |\n",
      "| time/              |          |\n",
      "|    fps             | 395      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -526     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 377      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 10       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.858    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00975  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 233      |\n",
      "|    policy_objective       | 0.0171   |\n",
      "|    std                    | 0.194    |\n",
      "|    value_loss             | 594      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -494     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 375      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 16       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.9      |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00863  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 234      |\n",
      "|    policy_objective       | 0.0147   |\n",
      "|    std                    | 0.188    |\n",
      "|    value_loss             | 389      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -507     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 367      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 22       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.911    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00985  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 235      |\n",
      "|    policy_objective       | 0.0186   |\n",
      "|    std                    | 0.187    |\n",
      "|    value_loss             | 382      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -497     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 365      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 27       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.873    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00933  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 236      |\n",
      "|    policy_objective       | 0.0172   |\n",
      "|    std                    | 0.186    |\n",
      "|    value_loss             | 545      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -491     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 364      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 33       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.898    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00663  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 237      |\n",
      "|    policy_objective       | 0.0148   |\n",
      "|    std                    | 0.186    |\n",
      "|    value_loss             | 505      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -503     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 364      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 39       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.948    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00962  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 238      |\n",
      "|    policy_objective       | 0.0203   |\n",
      "|    std                    | 0.182    |\n",
      "|    value_loss             | 396      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -494     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 361      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 45       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.903    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0092   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 239      |\n",
      "|    policy_objective       | 0.0233   |\n",
      "|    std                    | 0.181    |\n",
      "|    value_loss             | 531      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-158.5632299207151\n"
     ]
    }
   ],
   "source": [
    "# initialize the client and server\n",
    "timesteps_real_per_round = 500\n",
    "timesteps_fc_per_round = timesteps_real_per_round * 30\n",
    "epoch_per_round = 100\n",
    "CLIENTS_NUM = 3\n",
    "rounds_num = 30\n",
    "batch_size_env_model = 128\n",
    "\n",
    "test_dir = \"Diff_test2\"\n",
    "model_tmp_path = test_dir + \"/models/tmp\"\n",
    "\n",
    "env_models = []\n",
    "MB_env = TimeLimit(MB_PendulumEnv(env_models,device), max_episode_steps = 200)\n",
    "\n",
    "# Global_RL = PPO(\"MlpPolicy\", MB_env, verbose=1)\n",
    "Global_RL = TRPO(\"MlpPolicy\", MB_env, verbose=1)\n",
    "\n",
    "env_theta = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "real_envs = []\n",
    "Clients = []\n",
    "for i in range(CLIENTS_NUM):\n",
    "    real_envs.append( TimeLimit(PendulumEnv(), max_episode_steps=200) )\n",
    "    policy_net = Global_RL\n",
    "    agent = SB3Agent(policy_net)\n",
    "    client = FRLClient(real_envs[i], agent, lr = 3e-4, hidden_size = 256, device = device)\n",
    "    Clients.append(client)\n",
    "    env_model = copy.deepcopy(client.model)\n",
    "    env_models.append(env_model)\n",
    "    \n",
    "\n",
    "    \n",
    "Global_RL.env.models = env_models\n",
    "\n",
    "Global_RL.save(model_tmp_path)\n",
    "\n",
    "rewards_log = []\n",
    "\n",
    "env_models = []\n",
    "for round_idx in range(rounds_num):\n",
    "    print('------------------------------')\n",
    "    print(\"round: \" + str(round_idx))\n",
    "    for client_idx in range(len(Clients)):\n",
    "        print('------------------------------')\n",
    "        print(\"client: \" + str(client_idx))\n",
    "        # update policy\n",
    "        Clients[client_idx].agent.policy_net = Global_RL\n",
    "        # train prediction models\n",
    "        Clients[client_idx].learn(timesteps_real_per_round, epoch_per_round, batch_size_env_model)\n",
    "        #\n",
    "        env_model = Clients[client_idx].get_prediction_model()\n",
    "        env_models.append(env_model)\n",
    "    \n",
    "#     Server.update_env_models(env_models)\n",
    "\n",
    "    MB_env = TimeLimit(MB_PendulumEnv(env_models,device), max_episode_steps = 200)\n",
    "    \n",
    "    Global_RL = TRPO.load(model_tmp_path, env = MB_env)\n",
    "#     Global_RL.env.models = env_models\n",
    "    #\n",
    "    Global_RL.learn(total_timesteps=timesteps_fc_per_round)\n",
    "    \n",
    "    Global_RL.save(model_tmp_path)\n",
    "#     Server.learn(timesteps_real_per_round = 10000)\n",
    "    # test performance\n",
    "    mean_reward, std_reward = evaluate_policy(Global_RL, real_envs[1], n_eval_episodes=10)\n",
    "    rewards_log.append(mean_reward)\n",
    "    print(\"mean_reward in real env:\" + str(mean_reward))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "264f9e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-970.8002081733197, -1123.6436900161207, -1136.0690905712545, -1126.5493662536144, -1142.3008359141647, -1095.7273782581092, -1022.6560384841636, -1020.4520503315958, -1029.3009487275035, -871.6724438581557, -558.7193391416222, -425.7675370226032, -598.9239063396584, -302.84364417297763, -242.57555727045983, -255.74213915597647, -213.3483472181484, -283.1163841223344, -186.7118948964402, -239.12449115570635, -367.1023692952469, -156.5617831733078, -167.36910062208773, -208.07899495717137, -143.8481327002868, -150.1074405770749, -200.99566091261804, -209.2300049532205, -172.16850874321534, -158.5632299207151]\n"
     ]
    }
   ],
   "source": [
    "print(rewards_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eff6d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save( test_dir + \"/reward_logs.npy\", rewards_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f784c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_rewards(rewards, steps_per_round):\n",
    "    \"\"\"\n",
    "    绘制奖励曲线图\n",
    "\n",
    "    参数:\n",
    "    rewards (list or array): 每轮的奖励\n",
    "    steps_per_round (int): 每轮的固定步数\n",
    "    \"\"\"\n",
    "    # 计算每轮的平均奖励\n",
    "    avg_rewards = [reward / steps_per_round for reward in rewards]\n",
    "\n",
    "    plt.figure(figsize=(10, 6), dpi=300)\n",
    "    plt.plot(range(1, len(rewards) + 1), rewards, label='Average Reward per Step')\n",
    "    plt.xlabel('Round')\n",
    "    plt.ylabel('Average Reward')\n",
    "    plt.title('Average Reward per Step Over Rounds')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17903867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3000x1800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_rewards(rewards_log, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd142432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c36921a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " )]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Global_RL.env.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f54dcf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " GaussianModel(\n",
       "   (fc_net): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       " )]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Global_RL.env.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faf66af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b315ebde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.25910562, -0.965849  ,  0.49215463], dtype=float32), {})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MB_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6092195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25910562, -0.965849  ,  0.49215463], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MB_env.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75f8fde6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mMB_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMB_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mF:\\AI\\RL\\FedMBRL\\MBEnvs\\mb_pendulum2_gaussian.py:147\u001b[0m, in \u001b[0;36mMB_PendulumEnv.step\u001b[1;34m(self, u)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, u):\n\u001b[0;32m    145\u001b[0m     last_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs  \u001b[38;5;66;03m# th := theta\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_reward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m     next_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_obs_by_model(last_obs, action\u001b[38;5;241m=\u001b[39mu)\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs \u001b[38;5;241m=\u001b[39m next_obs\n",
      "File \u001b[1;32mF:\\AI\\RL\\FedMBRL\\MBEnvs\\mb_pendulum2_gaussian.py:210\u001b[0m, in \u001b[0;36mMB_PendulumEnv._get_reward\u001b[1;34m(self, obs, action)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_reward\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs, action):\n\u001b[1;32m--> 210\u001b[0m     obs1, obs2, thdot \u001b[38;5;241m=\u001b[39m obs\n\u001b[0;32m    211\u001b[0m     th \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recover_theta(obs1, obs2)\n\u001b[0;32m    212\u001b[0m     costs \u001b[38;5;241m=\u001b[39m angle_normalize(th) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m thdot\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.001\u001b[39m \u001b[38;5;241m*\u001b[39m (action\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "MB_env.step(MB_env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99a7f293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2085361, -0.7650793, -1.1017272]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MB_env.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292dc859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366cff92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0481a6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f748ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs,_ = Clients[0].env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "200357a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.43307275,  0.90135896, -0.16240236], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c447055d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02079844",
   "metadata": {},
   "outputs": [],
   "source": [
    "action =  Clients[0].agent.act(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9e3bd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33290574], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53bab146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianModel(\n",
       "  (fc_net): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (mean_logvar): Linear(in_features=256, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clients[0].model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "464dbe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_tensor = torch.tensor(obs, dtype=torch.float32)\n",
    "action_tensor = torch.tensor(action, dtype=torch.float32)\n",
    "input_d = torch.cat((obs_tensor, action_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d1d9c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4331,  0.9014, -0.1624, -0.3329])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e39458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_d = input_d.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edbb8cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, logvar = Clients[0].model.forward(input_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "caf4e380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0052, -0.0026,  0.6155], device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([-3.5161, -2.7553, -2.9714], device='cuda:0', grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, logvar[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b50dfc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1724, 0.2522, 0.2263], device='cuda:0', grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = torch.exp(0.5 * logvar[0])\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea0ea8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = torch.randn_like(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a634daaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7962, 0.2781, 1.4486], device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ed95b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_state_change = mean + eps * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34ec3c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1320, 0.0675, 0.9434], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_state_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "579f73a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_np = pred_state_change.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19eda842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13200563, 0.06751756, 0.94340324], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e5570d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.43307275,  0.90135896, -0.16240236], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec85e71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_new = obs + output_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e2e9c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5650784 , 0.96887654, 0.78100085], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b05573f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edc20798",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_clipped = np.clip(obs, Clients[0].env.observation_space.low, Clients[0].env.observation_space.high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7a1ced1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.43307275,  0.90135896, -0.16240236], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337cf7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2beb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0053a243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22093d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.30735433], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clients[0].agent.policy_net.predict(obs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bbe53a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1699efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: -93.15121025741101 +/- 109.2765889131137\n"
     ]
    }
   ],
   "source": [
    "# mean_reward, std_reward = evaluate_policy(Global_RL, real_envs[1], n_eval_episodes=10)\n",
    "mean_reward, std_reward = evaluate_policy(Global_RL, MB_env, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9285a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib import TRPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1ac5563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "TRPO_model = TRPO(\"MlpPolicy\", env=real_envs[0], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23e35f65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -829     |\n",
      "| time/              |          |\n",
      "|    fps             | 520      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -847     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 478      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 8        |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.715    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00696  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 50       |\n",
      "|    policy_objective       | 0.0147   |\n",
      "|    std                    | 0.809    |\n",
      "|    value_loss             | 433      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -893     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 481      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 12       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.749    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00777  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 51       |\n",
      "|    policy_objective       | 0.0188   |\n",
      "|    std                    | 0.789    |\n",
      "|    value_loss             | 629      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -890     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 470      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.759    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00865  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 52       |\n",
      "|    policy_objective       | 0.0126   |\n",
      "|    std                    | 0.762    |\n",
      "|    value_loss             | 857      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -875     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 470      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 21       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.8      |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00702  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 53       |\n",
      "|    policy_objective       | 0.0123   |\n",
      "|    std                    | 0.769    |\n",
      "|    value_loss             | 679      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -860     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 465      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 26       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.825    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00762  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 54       |\n",
      "|    policy_objective       | 0.0143   |\n",
      "|    std                    | 0.757    |\n",
      "|    value_loss             | 660      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -832     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 467      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 30       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.851    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00773  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 55       |\n",
      "|    policy_objective       | 0.0167   |\n",
      "|    std                    | 0.743    |\n",
      "|    value_loss             | 428      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -808     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 470      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 34       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.881    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00726  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 56       |\n",
      "|    policy_objective       | 0.0213   |\n",
      "|    std                    | 0.72     |\n",
      "|    value_loss             | 291      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -794     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 472      |\n",
      "|    iterations             | 9        |\n",
      "|    time_elapsed           | 39       |\n",
      "|    total_timesteps        | 18432    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.876    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00698  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 57       |\n",
      "|    policy_objective       | 0.0147   |\n",
      "|    std                    | 0.728    |\n",
      "|    value_loss             | 506      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -758     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 471      |\n",
      "|    iterations             | 10       |\n",
      "|    time_elapsed           | 43       |\n",
      "|    total_timesteps        | 20480    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.914    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00761  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 58       |\n",
      "|    policy_objective       | 0.0205   |\n",
      "|    std                    | 0.72     |\n",
      "|    value_loss             | 376      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -734     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 472      |\n",
      "|    iterations             | 11       |\n",
      "|    time_elapsed           | 47       |\n",
      "|    total_timesteps        | 22528    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.883    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00787  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 59       |\n",
      "|    policy_objective       | 0.0231   |\n",
      "|    std                    | 0.698    |\n",
      "|    value_loss             | 250      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -690     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 473      |\n",
      "|    iterations             | 12       |\n",
      "|    time_elapsed           | 51       |\n",
      "|    total_timesteps        | 24576    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.927    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00787  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 60       |\n",
      "|    policy_objective       | 0.0255   |\n",
      "|    std                    | 0.692    |\n",
      "|    value_loss             | 283      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -644     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 473      |\n",
      "|    iterations             | 13       |\n",
      "|    time_elapsed           | 56       |\n",
      "|    total_timesteps        | 26624    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.928    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00833  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 61       |\n",
      "|    policy_objective       | 0.0195   |\n",
      "|    std                    | 0.681    |\n",
      "|    value_loss             | 334      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -604     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 473      |\n",
      "|    iterations             | 14       |\n",
      "|    time_elapsed           | 60       |\n",
      "|    total_timesteps        | 28672    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.884    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00801  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 62       |\n",
      "|    policy_objective       | 0.0296   |\n",
      "|    std                    | 0.677    |\n",
      "|    value_loss             | 282      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -550     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 474      |\n",
      "|    iterations             | 15       |\n",
      "|    time_elapsed           | 64       |\n",
      "|    total_timesteps        | 30720    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.927    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00836  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 63       |\n",
      "|    policy_objective       | 0.0263   |\n",
      "|    std                    | 0.654    |\n",
      "|    value_loss             | 260      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -499     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 474      |\n",
      "|    iterations             | 16       |\n",
      "|    time_elapsed           | 69       |\n",
      "|    total_timesteps        | 32768    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.926    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00848  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 64       |\n",
      "|    policy_objective       | 0.0303   |\n",
      "|    std                    | 0.638    |\n",
      "|    value_loss             | 274      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -445     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 473      |\n",
      "|    iterations             | 17       |\n",
      "|    time_elapsed           | 73       |\n",
      "|    total_timesteps        | 34816    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.954    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00868  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 65       |\n",
      "|    policy_objective       | 0.0229   |\n",
      "|    std                    | 0.639    |\n",
      "|    value_loss             | 202      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mTRPO_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\sb3_contrib\\trpo\\trpo.py:412\u001b[0m, in \u001b[0;36mTRPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTRPO,\n\u001b[0;32m    405\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    410\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    411\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTRPO:\n\u001b[1;32m--> 412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:259\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 259\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:169\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Convert to pytorch tensor or to TensorDict\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     obs_tensor \u001b[38;5;241m=\u001b[39m obs_as_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 169\u001b[0m     actions, values, log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\policies.py:619\u001b[0m, in \u001b[0;36mActorCriticPolicy.forward\u001b[1;34m(self, obs, deterministic)\u001b[0m\n\u001b[0;32m    617\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_features(obs)\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor:\n\u001b[1;32m--> 619\u001b[0m     latent_pi, latent_vf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m     pi_features, vf_features \u001b[38;5;241m=\u001b[39m features\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\torch_layers.py:222\u001b[0m, in \u001b[0;36mMlpExtractor.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[th\u001b[38;5;241m.\u001b[39mTensor, th\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m    :return: latent_policy, latent_value of the specified network.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m        If all layers are shared, then ``latent_policy == latent_value``\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_actor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_critic(features)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\torch_layers.py:225\u001b[0m, in \u001b[0;36mMlpExtractor.forward_actor\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_actor\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\activation.py:356\u001b[0m, in \u001b[0;36mTanh.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRPO_model.learn(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc7bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e8fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4fdc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178374d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "897fb7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Input Mean: tensor([ 0.3523, -0.0157, -0.2429,  0.1068], grad_fn=<SqueezeBackward1>)\n",
      "Single Input Logvar: tensor([-0.5165, -0.4999, -0.4875, -0.4478], grad_fn=<SqueezeBackward1>)\n",
      "Batch Input Mean: tensor([[ 0.1343,  0.0868, -0.1983,  0.0582],\n",
      "        [ 0.1066, -0.1898, -0.6315,  0.0736],\n",
      "        [ 0.3875,  0.1861, -0.3479,  0.0122],\n",
      "        [ 0.1715,  0.0231, -0.1943,  0.1135],\n",
      "        [ 0.2438, -0.0612, -0.4051,  0.0425]], grad_fn=<SliceBackward0>)\n",
      "Batch Input Logvar: tensor([[-0.4949, -0.4842, -0.5894, -0.4223],\n",
      "        [-0.4841, -0.3873, -0.6761, -0.3461],\n",
      "        [-0.5958, -0.4917, -0.8158, -0.3497],\n",
      "        [-0.4940, -0.4847, -0.5807, -0.4696],\n",
      "        [-0.4818, -0.4734, -0.7298, -0.3792]], grad_fn=<AddBackward0>)\n",
      "Single Input Loss: 3.6077818870544434\n",
      "Batch Input Loss: 3.898193597793579\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定义GaussianModel\n",
    "class GaussianModel(nn.Module):\n",
    "    def __init__(self, obs_size, action_size, hidden_size=256, learn_logvar_bounds=False):\n",
    "        super(GaussianModel, self).__init__()\n",
    "        self.out_size = obs_size\n",
    "        \n",
    "        self.fc_net = nn.Sequential(\n",
    "            nn.Linear(obs_size + action_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.mean_logvar = nn.Linear(hidden_size, obs_size * 2)\n",
    "        \n",
    "        self.min_logvar = nn.Parameter(\n",
    "            -10 * torch.ones(1, obs_size), requires_grad=learn_logvar_bounds\n",
    "        )\n",
    "        self.max_logvar = nn.Parameter(\n",
    "            0.5 * torch.ones(1, obs_size), requires_grad=learn_logvar_bounds\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc_net(x)\n",
    "        mean_and_logvar = self.mean_logvar(x)\n",
    "        mean = mean_and_logvar[..., :self.out_size]\n",
    "        logvar = mean_and_logvar[..., self.out_size:]\n",
    "        \n",
    "        logvar = self.max_logvar - F.softplus(self.max_logvar - logvar)\n",
    "        logvar = self.min_logvar + F.softplus(logvar - self.min_logvar)\n",
    "        \n",
    "        # If the original input was one-dimensional, squeeze the output\n",
    "        if logvar.shape[0] == 1:\n",
    "            mean = mean.squeeze(0)\n",
    "            logvar = logvar.squeeze(0)\n",
    "        \n",
    "        return mean, logvar\n",
    "\n",
    "# 定义测试用例\n",
    "def test_gaussian_model():\n",
    "    obs_size = 4\n",
    "    action_size = 2\n",
    "    hidden_size = 256\n",
    "\n",
    "    model = GaussianModel(obs_size, action_size, hidden_size)\n",
    "\n",
    "    # 单个输入数据\n",
    "    single_input = torch.randn(obs_size + action_size)\n",
    "    \n",
    "    # 批量输入数据\n",
    "    batch_input = torch.randn(5, obs_size + action_size)\n",
    "    \n",
    "    # 前向传播\n",
    "    single_mean, single_logvar = model(single_input)\n",
    "    batch_mean, batch_logvar = model(batch_input)\n",
    "    \n",
    "    print(\"Single Input Mean:\", single_mean)\n",
    "    print(\"Single Input Logvar:\", single_logvar)\n",
    "    print(\"Batch Input Mean:\", batch_mean)\n",
    "    print(\"Batch Input Logvar:\", batch_logvar)\n",
    "    \n",
    "    # 构建损失函数\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    # 构造目标数据\n",
    "    target_mean = torch.randn(obs_size)\n",
    "    target_logvar = torch.randn(obs_size)\n",
    "    \n",
    "    # 计算损失\n",
    "    single_loss = loss_fn(single_mean, target_mean) + loss_fn(single_logvar, target_logvar)\n",
    "    batch_loss = loss_fn(batch_mean, target_mean.unsqueeze(0).expand_as(batch_mean)) + \\\n",
    "                 loss_fn(batch_logvar, target_logvar.unsqueeze(0).expand_as(batch_logvar))\n",
    "    \n",
    "    print(\"Single Input Loss:\", single_loss.item())\n",
    "    print(\"Batch Input Loss:\", batch_loss.item())\n",
    "\n",
    "# 运行测试用例\n",
    "test_gaussian_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a990d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db1039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2303b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Envs.pendulum import PendulumEnv\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import TimeLimit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494268cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PendulumEnv()\n",
    "env = TimeLimit(env, max_episode_steps=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fba20c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.76838493, -0.63998795,  0.81405437], dtype=float32), {})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eec815b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2024f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MBEnvs.mb_pendulum2 import MB_PendulumEnv\n",
    "env_models = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MB_env = MB_PendulumEnv(env_models, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07c32890",
   "metadata": {},
   "outputs": [],
   "source": [
    "Global_RL = PPO(\"MlpPolicy\", MB_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52b71d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_sb3 = SB3Agent(policy_net=Global_RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc323e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_client = FRLClient(env=env,agent=agent_sb3, lr=0.0001, hidden_size= 256, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc228a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_client.sample_data(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efdc721e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.322894</td>\n",
       "      <td>0.946435</td>\n",
       "      <td>-0.989896</td>\n",
       "      <td>[-1.0409824]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.302177</td>\n",
       "      <td>0.953252</td>\n",
       "      <td>-0.436217</td>\n",
       "      <td>[-0.6262884]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.310971</td>\n",
       "      <td>0.950420</td>\n",
       "      <td>0.184779</td>\n",
       "      <td>[0.17797917]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.354546</td>\n",
       "      <td>0.935039</td>\n",
       "      <td>0.924290</td>\n",
       "      <td>[0.090897225]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.429906</td>\n",
       "      <td>0.902874</td>\n",
       "      <td>1.639204</td>\n",
       "      <td>[-0.5123889]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-0.598818</td>\n",
       "      <td>-0.800885</td>\n",
       "      <td>-1.669427</td>\n",
       "      <td>[0.70794886]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.681799</td>\n",
       "      <td>-0.731539</td>\n",
       "      <td>-2.163898</td>\n",
       "      <td>[0.0085118115]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.774411</td>\n",
       "      <td>-0.632683</td>\n",
       "      <td>-2.711276</td>\n",
       "      <td>[-0.112191804]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.865383</td>\n",
       "      <td>-0.501111</td>\n",
       "      <td>-3.202617</td>\n",
       "      <td>[0.9892371]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.938209</td>\n",
       "      <td>-0.346070</td>\n",
       "      <td>-3.430064</td>\n",
       "      <td>[-0.71530473]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         actions\n",
       "0  -0.322894  0.946435 -0.989896    [-1.0409824]\n",
       "1  -0.302177  0.953252 -0.436217    [-0.6262884]\n",
       "2  -0.310971  0.950420  0.184779    [0.17797917]\n",
       "3  -0.354546  0.935039  0.924290   [0.090897225]\n",
       "4  -0.429906  0.902874  1.639204    [-0.5123889]\n",
       "..       ...       ...       ...             ...\n",
       "94 -0.598818 -0.800885 -1.669427    [0.70794886]\n",
       "95 -0.681799 -0.731539 -2.163898  [0.0085118115]\n",
       "96 -0.774411 -0.632683 -2.711276  [-0.112191804]\n",
       "97 -0.865383 -0.501111 -3.202617     [0.9892371]\n",
       "98 -0.938209 -0.346070 -3.430064   [-0.71530473]\n",
       "\n",
       "[99 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_client.dataset_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7007ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020718</td>\n",
       "      <td>0.006817</td>\n",
       "      <td>0.553679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.008794</td>\n",
       "      <td>-0.002832</td>\n",
       "      <td>0.620996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.043576</td>\n",
       "      <td>-0.015381</td>\n",
       "      <td>0.739511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.075360</td>\n",
       "      <td>-0.032165</td>\n",
       "      <td>0.714913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.098196</td>\n",
       "      <td>-0.053693</td>\n",
       "      <td>0.600297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-0.082981</td>\n",
       "      <td>0.069346</td>\n",
       "      <td>-0.494471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.092611</td>\n",
       "      <td>0.098856</td>\n",
       "      <td>-0.547378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.090972</td>\n",
       "      <td>0.131572</td>\n",
       "      <td>-0.491341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.072826</td>\n",
       "      <td>0.155041</td>\n",
       "      <td>-0.227448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.048450</td>\n",
       "      <td>0.183265</td>\n",
       "      <td>-0.366848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.020718  0.006817  0.553679\n",
       "1  -0.008794 -0.002832  0.620996\n",
       "2  -0.043576 -0.015381  0.739511\n",
       "3  -0.075360 -0.032165  0.714913\n",
       "4  -0.098196 -0.053693  0.600297\n",
       "..       ...       ...       ...\n",
       "94 -0.082981  0.069346 -0.494471\n",
       "95 -0.092611  0.098856 -0.547378\n",
       "96 -0.090972  0.131572 -0.491341\n",
       "97 -0.072826  0.155041 -0.227448\n",
       "98 -0.048450  0.183265 -0.366848\n",
       "\n",
       "[99 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_client.dataset_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3870d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aed97cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c69c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib import TRPO\n",
    "from Client_diff import FRLClient\n",
    "from Agent import SB3Agent\n",
    "import copy\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acb84f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8046c1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbc0bbb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------\n",
      "round: 0\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.09677656704870363!\n",
      "Avg loss: 0.07015586787485517!\n",
      "Avg loss: 0.04730734085353712!\n",
      "Avg loss: 0.030482896285053962!\n",
      "Avg loss: 0.018819304870751997!\n",
      "Avg loss: 0.009563239624064105!\n",
      "Avg loss: 0.005105818427400663!\n",
      "Avg loss: 0.004595879271510057!\n",
      "Avg loss: 0.0047878739884617974!\n",
      "Avg loss: 0.003952470326961096!\n",
      "Avg loss: 0.0037547514090450324!\n",
      "Avg loss: 0.0037353936982981394!\n",
      "Avg loss: 0.003291534914606018!\n",
      "Avg loss: 0.002192283471425374!\n",
      "Avg loss: 0.001625417570345841!\n",
      "Avg loss: 0.0016835247261284773!\n",
      "Avg loss: 0.001959851173908949!\n",
      "Avg loss: 0.0019289238159399247!\n",
      "Avg loss: 0.0018305774985613729!\n",
      "Avg loss: 0.0019161201479785935!\n",
      "Avg loss: 0.0020821858830822747!\n",
      "Avg loss: 0.002057912137194459!\n",
      "Avg loss: 0.001954764022533103!\n",
      "Avg loss: 0.0019344172135667274!\n",
      "Avg loss: 0.0019631054442046055!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.11701234047029478!\n",
      "Avg loss: 0.09269894062036958!\n",
      "Avg loss: 0.07138766135826397!\n",
      "Avg loss: 0.05608097755194952!\n",
      "Avg loss: 0.04469980534651161!\n",
      "Avg loss: 0.03490649288096999!\n",
      "Avg loss: 0.0278825778401612!\n",
      "Avg loss: 0.0244262618011453!\n",
      "Avg loss: 0.023703428823749467!\n",
      "Avg loss: 0.02330767451351373!\n",
      "Avg loss: 0.0229367079109943!\n",
      "Avg loss: 0.022900630093172367!\n",
      "Avg loss: 0.022975436763893718!\n",
      "Avg loss: 0.022809103828816055!\n",
      "Avg loss: 0.022694818455250544!\n",
      "Avg loss: 0.022971056420986617!\n",
      "Avg loss: 0.023191300836527564!\n",
      "Avg loss: 0.023251154287863757!\n",
      "Avg loss: 0.023349879924723305!\n",
      "Avg loss: 0.02332724172017758!\n",
      "Avg loss: 0.02324326294579805!\n",
      "Avg loss: 0.023183690063609295!\n",
      "Avg loss: 0.023087663264820247!\n",
      "Avg loss: 0.022997293763361692!\n",
      "Avg loss: 0.022949433606092196!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.08202619177444527!\n",
      "Avg loss: 0.06344543300491447!\n",
      "Avg loss: 0.0482226536651918!\n",
      "Avg loss: 0.036131866302263616!\n",
      "Avg loss: 0.02354330818585974!\n",
      "Avg loss: 0.014568085118371528!\n",
      "Avg loss: 0.008416834379883463!\n",
      "Avg loss: 0.00565669626686334!\n",
      "Avg loss: 0.004265842896566028!\n",
      "Avg loss: 0.002972080554548787!\n",
      "Avg loss: 0.0029763956877710976!\n",
      "Avg loss: 0.003002618433565658!\n",
      "Avg loss: 0.0027120084283402926!\n",
      "Avg loss: 0.002511225518634698!\n",
      "Avg loss: 0.0023995700288166216!\n",
      "Avg loss: 0.002365955874774954!\n",
      "Avg loss: 0.0022466882554484377!\n",
      "Avg loss: 0.002201587805514767!\n",
      "Avg loss: 0.0022125241595288493!\n",
      "Avg loss: 0.002149144736219265!\n",
      "Avg loss: 0.002158721074980955!\n",
      "Avg loss: 0.002174949219430952!\n",
      "Avg loss: 0.0021296515890571756!\n",
      "Avg loss: 0.0021200009317302224!\n",
      "Avg loss: 0.0021462242898511855!\n",
      "Avg loss: 0.0020926423084286702!\n",
      "Avg loss: 0.0020497945196196574!\n",
      "Avg loss: 0.0020336176461084204!\n",
      "Avg loss: 0.0020116274645465637!\n",
      "Avg loss: 0.002023544772093828!\n",
      "Avg loss: 0.0020657977005294013!\n",
      "Avg loss: 0.0020752643353929064!\n",
      "Avg loss: 0.002062184976833426!\n",
      "Avg loss: 0.0020730069569253828!\n",
      "Avg loss: 0.0020904387138944!\n",
      "Avg loss: 0.0021153945516653038!\n",
      "Avg loss: 0.002114004421861561!\n",
      "Avg loss: 0.002110798702685012!\n",
      "Avg loss: 0.0021047337224831607!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -884     |\n",
      "| time/              |          |\n",
      "|    fps             | 298      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -955     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 306      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 13       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.000849 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0086   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 1        |\n",
      "|    policy_objective       | 0.0079   |\n",
      "|    std                    | 1        |\n",
      "|    value_loss             | 6.18e+03 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.02e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 311       |\n",
      "|    iterations             | 3         |\n",
      "|    time_elapsed           | 19        |\n",
      "|    total_timesteps        | 6144      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -0.038    |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00582   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 2         |\n",
      "|    policy_objective       | 0.00542   |\n",
      "|    std                    | 0.99      |\n",
      "|    value_loss             | 6.26e+03  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -948     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 315      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 25       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.011    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00832  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 3        |\n",
      "|    policy_objective       | 0.0111   |\n",
      "|    std                    | 1.01     |\n",
      "|    value_loss             | 8.56e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -935     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 328      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 31       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.00661  |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00665  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 4        |\n",
      "|    policy_objective       | 0.00526  |\n",
      "|    std                    | 1.03     |\n",
      "|    value_loss             | 4.65e+03 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1269.0388372687623\n",
      "------------------------------\n",
      "round: 1\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.004725577053322922!\n",
      "Avg loss: 0.00390276768037135!\n",
      "Avg loss: 0.005330365389988098!\n",
      "Avg loss: 0.003245797453658573!\n",
      "Avg loss: 0.003745883344866646!\n",
      "Avg loss: 0.003608668855279878!\n",
      "Avg loss: 0.003715497708496211!\n",
      "Avg loss: 0.0031481926394917536!\n",
      "Avg loss: 0.0029722894560351657!\n",
      "Avg loss: 0.0035163732889729243!\n",
      "Avg loss: 0.0029279939812840894!\n",
      "Avg loss: 0.00274510562424742!\n",
      "Avg loss: 0.0030160449048950494!\n",
      "Avg loss: 0.002756519045166594!\n",
      "Avg loss: 0.002554343257070286!\n",
      "Avg loss: 0.0027002088238320234!\n",
      "Avg loss: 0.002662639587336647!\n",
      "Avg loss: 0.002576252302897046!\n",
      "Avg loss: 0.002665853633128184!\n",
      "Avg loss: 0.0026402792921362563!\n",
      "Avg loss: 0.0025449013676431304!\n",
      "Avg loss: 0.002675414690187002!\n",
      "Avg loss: 0.0026401259693860386!\n",
      "Avg loss: 0.0026150792295932964!\n",
      "Avg loss: 0.00258068790958229!\n",
      "Avg loss: 0.0025774249494982843!\n",
      "Avg loss: 0.0025631515744680656!\n",
      "Avg loss: 0.0026290890578638936!\n",
      "Avg loss: 0.0025732435476129465!\n",
      "Avg loss: 0.002563675037545181!\n",
      "Avg loss: 0.0025871762869064696!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.007057138069455201!\n",
      "Avg loss: 0.006493528743546146!\n",
      "Avg loss: 0.005385051123739686!\n",
      "Avg loss: 0.0044204702257290285!\n",
      "Avg loss: 0.004883254615536619!\n",
      "Avg loss: 0.004506536426439804!\n",
      "Avg loss: 0.004374459204118466!\n",
      "Avg loss: 0.004007300232260604!\n",
      "Avg loss: 0.004190988500219343!\n",
      "Avg loss: 0.0038577432168070422!\n",
      "Avg loss: 0.0038463935309482624!\n",
      "Avg loss: 0.003710112139233388!\n",
      "Avg loss: 0.003716429503874679!\n",
      "Avg loss: 0.0036457128928547413!\n",
      "Avg loss: 0.003652940945700417!\n",
      "Avg loss: 0.0036230613639175622!\n",
      "Avg loss: 0.0036120904159846153!\n",
      "Avg loss: 0.003604626806527449!\n",
      "Avg loss: 0.0036129772301198198!\n",
      "Avg loss: 0.0036586137489575776!\n",
      "Avg loss: 0.003690929862344395!\n",
      "Avg loss: 0.0036616744519960775!\n",
      "Avg loss: 0.0036246543364298607!\n",
      "Avg loss: 0.00360512691463858!\n",
      "Avg loss: 0.0036152280741331803!\n",
      "Avg loss: 0.0036227992111525966!\n",
      "Avg loss: 0.0036326777530014927!\n",
      "Avg loss: 0.0036474643979636312!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.008392256879645477!\n",
      "Avg loss: 0.005526859945506051!\n",
      "Avg loss: 0.006358900041207865!\n",
      "Avg loss: 0.004639380736759146!\n",
      "Avg loss: 0.005481995593484801!\n",
      "Avg loss: 0.004610928687531365!\n",
      "Avg loss: 0.00483932928576299!\n",
      "Avg loss: 0.004471357513443764!\n",
      "Avg loss: 0.004673390761745395!\n",
      "Avg loss: 0.004550715702980597!\n",
      "Avg loss: 0.004617303843307733!\n",
      "Avg loss: 0.00460684336598509!\n",
      "Avg loss: 0.00458560146860691!\n",
      "Avg loss: 0.0045264220272171465!\n",
      "Avg loss: 0.004489086678086096!\n",
      "Avg loss: 0.0045870522905655286!\n",
      "Avg loss: 0.0045636711214441066!\n",
      "Avg loss: 0.0045456896860938895!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1.1e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 363      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.06e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 321       |\n",
      "|    iterations             | 2         |\n",
      "|    time_elapsed           | 12        |\n",
      "|    total_timesteps        | 4096      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.0115    |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00743   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 6         |\n",
      "|    policy_objective       | 0.00604   |\n",
      "|    std                    | 1.01      |\n",
      "|    value_loss             | 7.31e+03  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -997     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 331      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 18       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.00125  |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00925  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 7        |\n",
      "|    policy_objective       | 0.00572  |\n",
      "|    std                    | 1.07     |\n",
      "|    value_loss             | 6.05e+03 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.02e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 341       |\n",
      "|    iterations             | 4         |\n",
      "|    time_elapsed           | 23        |\n",
      "|    total_timesteps        | 8192      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.00106   |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00843   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 8         |\n",
      "|    policy_objective       | 0.00588   |\n",
      "|    std                    | 1.15      |\n",
      "|    value_loss             | 6.01e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.06e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 346       |\n",
      "|    iterations             | 5         |\n",
      "|    time_elapsed           | 29        |\n",
      "|    total_timesteps        | 10240     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.00139   |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00859   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 9         |\n",
      "|    policy_objective       | 0.00776   |\n",
      "|    std                    | 1.06      |\n",
      "|    value_loss             | 6.6e+03   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1167.533584973216\n",
      "------------------------------\n",
      "round: 2\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.045638864110029924!\n",
      "Avg loss: 0.04058444035341381!\n",
      "Avg loss: 0.04200477829290321!\n",
      "Avg loss: 0.03865174622204601!\n",
      "Avg loss: 0.04239344896321806!\n",
      "Avg loss: 0.037668802958287416!\n",
      "Avg loss: 0.03777992352554672!\n",
      "Avg loss: 0.03791844716891622!\n",
      "Avg loss: 0.03790207412018693!\n",
      "Avg loss: 0.03664851506412863!\n",
      "Avg loss: 0.036394394914779395!\n",
      "Avg loss: 0.037243007976550564!\n",
      "Avg loss: 0.03637302260454211!\n",
      "Avg loss: 0.03609345805890068!\n",
      "Avg loss: 0.03647167681926173!\n",
      "Avg loss: 0.03637959940380824!\n",
      "Avg loss: 0.03592641264424552!\n",
      "Avg loss: 0.035899569028936186!\n",
      "Avg loss: 0.036101883476482424!\n",
      "Avg loss: 0.035864711240465114!\n",
      "Avg loss: 0.035996666796078595!\n",
      "Avg loss: 0.0361150896196826!\n",
      "Avg loss: 0.035883537325088734!\n",
      "Avg loss: 0.03581396050254019!\n",
      "Avg loss: 0.035823383354951756!\n",
      "Avg loss: 0.03567140844721204!\n",
      "Avg loss: 0.0356966543370072!\n",
      "Avg loss: 0.03565496567860161!\n",
      "Avg loss: 0.03556920381752813!\n",
      "Avg loss: 0.03551321445052281!\n",
      "Avg loss: 0.0354790760322112!\n",
      "Avg loss: 0.035474161513081415!\n",
      "Avg loss: 0.035511237695282034!\n",
      "Avg loss: 0.03544572709897087!\n",
      "Avg loss: 0.035423220687497786!\n",
      "Avg loss: 0.03536332873688176!\n",
      "Avg loss: 0.03525830865464134!\n",
      "Avg loss: 0.035240446108722005!\n",
      "Avg loss: 0.03526446167996861!\n",
      "Avg loss: 0.03524395878407025!\n",
      "Avg loss: 0.03522856492431856!\n",
      "Avg loss: 0.035186275128523146!\n",
      "Avg loss: 0.035055842436452926!\n",
      "Avg loss: 0.035077302668601075!\n",
      "Avg loss: 0.035027831611890485!\n",
      "Avg loss: 0.03497599090243663!\n",
      "Avg loss: 0.03500860143174274!\n",
      "Avg loss: 0.03489525913866601!\n",
      "Avg loss: 0.0349317320271454!\n",
      "Avg loss: 0.034855991803019605!\n",
      "Avg loss: 0.034864149521426954!\n",
      "Avg loss: 0.03487144247403497!\n",
      "Avg loss: 0.034796411441860374!\n",
      "Avg loss: 0.034897534216912995!\n",
      "Avg loss: 0.03475611761525064!\n",
      "Avg loss: 0.03473288798774774!\n",
      "Avg loss: 0.03466517910958677!\n",
      "Avg loss: 0.03461702817203597!\n",
      "Avg loss: 0.0346158393969957!\n",
      "Avg loss: 0.03462479326048538!\n",
      "Avg loss: 0.03458162782001485!\n",
      "Avg loss: 0.03462273038822029!\n",
      "Avg loss: 0.03444977046711908!\n",
      "Avg loss: 0.03451637578090261!\n",
      "Avg loss: 0.034479642187975515!\n",
      "Avg loss: 0.034433774839875086!\n",
      "Avg loss: 0.03435246756221507!\n",
      "Avg loss: 0.034374395965789215!\n",
      "Avg loss: 0.03437349002060425!\n",
      "Avg loss: 0.034354621236265835!\n",
      "Avg loss: 0.034294048654004046!\n",
      "Avg loss: 0.03425411769101553!\n",
      "Avg loss: 0.03426778456186791!\n",
      "Avg loss: 0.03427231278036061!\n",
      "Avg loss: 0.0341943747444581!\n",
      "Avg loss: 0.03416203310303521!\n",
      "Avg loss: 0.034108135008227694!\n",
      "Avg loss: 0.03407008744719406!\n",
      "Avg loss: 0.034121978831851724!\n",
      "Avg loss: 0.03411529603892935!\n",
      "Avg loss: 0.034116752469860026!\n",
      "Avg loss: 0.03398926756212556!\n",
      "Avg loss: 0.03403320319378205!\n",
      "Avg loss: 0.03395076167120275!\n",
      "Avg loss: 0.033915456463734964!\n",
      "Avg loss: 0.03391961261121196!\n",
      "Avg loss: 0.03390692347934419!\n",
      "Avg loss: 0.03394191543830478!\n",
      "Avg loss: 0.0339215588801494!\n",
      "Avg loss: 0.03392647375262717!\n",
      "Avg loss: 0.03372848822610952!\n",
      "Avg loss: 0.03390289428238096!\n",
      "Avg loss: 0.03381218951730564!\n",
      "Avg loss: 0.03393896976415514!\n",
      "Avg loss: 0.033675282804041064!\n",
      "Avg loss: 0.03377669525253888!\n",
      "Avg loss: 0.03359645838123773!\n",
      "Avg loss: 0.03399295413715246!\n",
      "Avg loss: 0.03369639217921001!\n",
      "Avg loss: 0.033892339822540786!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.017749776598551155!\n",
      "Avg loss: 0.01793226902387687!\n",
      "Avg loss: 0.016598430031129586!\n",
      "Avg loss: 0.01606791799605465!\n",
      "Avg loss: 0.016429055269309174!\n",
      "Avg loss: 0.01698170056272223!\n",
      "Avg loss: 0.01647262089319459!\n",
      "Avg loss: 0.016040066505448747!\n",
      "Avg loss: 0.015976490495607624!\n",
      "Avg loss: 0.016259463202707897!\n",
      "Avg loss: 0.016413007623441445!\n",
      "Avg loss: 0.01614033806505025!\n",
      "Avg loss: 0.015996030086297044!\n",
      "Avg loss: 0.016102627824226754!\n",
      "Avg loss: 0.016323351525021887!\n",
      "Avg loss: 0.01633130401638482!\n",
      "Avg loss: 0.016218593779764586!\n",
      "Avg loss: 0.016195487309617722!\n",
      "Avg loss: 0.01623394281566713!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0675245324143422!\n",
      "Avg loss: 0.06508966653959457!\n",
      "Avg loss: 0.0640016560296984!\n",
      "Avg loss: 0.062274101127428975!\n",
      "Avg loss: 0.06335811448356253!\n",
      "Avg loss: 0.06142739459042787!\n",
      "Avg loss: 0.06119229709698023!\n",
      "Avg loss: 0.06170587410617979!\n",
      "Avg loss: 0.06133091496589865!\n",
      "Avg loss: 0.06071809640042678!\n",
      "Avg loss: 0.06065959702852221!\n",
      "Avg loss: 0.060823403958881195!\n",
      "Avg loss: 0.06020183978214997!\n",
      "Avg loss: 0.060031410660909994!\n",
      "Avg loss: 0.06006651735026026!\n",
      "Avg loss: 0.05980556640384748!\n",
      "Avg loss: 0.059543822371312366!\n",
      "Avg loss: 0.059522663350580846!\n",
      "Avg loss: 0.059430124702569934!\n",
      "Avg loss: 0.05923011503693791!\n",
      "Avg loss: 0.05914079211015026!\n",
      "Avg loss: 0.05901759361270706!\n",
      "Avg loss: 0.05885255899501696!\n",
      "Avg loss: 0.058773915530761466!\n",
      "Avg loss: 0.058647999279410216!\n",
      "Avg loss: 0.05846763992996178!\n",
      "Avg loss: 0.05831999968451782!\n",
      "Avg loss: 0.05818751316704341!\n",
      "Avg loss: 0.05803645081433691!\n",
      "Avg loss: 0.05792703497483065!\n",
      "Avg loss: 0.05774323870686203!\n",
      "Avg loss: 0.05762319361348394!\n",
      "Avg loss: 0.05753892480782573!\n",
      "Avg loss: 0.05747499403588942!\n",
      "Avg loss: 0.05738038870242841!\n",
      "Avg loss: 0.05723354366659502!\n",
      "Avg loss: 0.0570123565280907!\n",
      "Avg loss: 0.05688586355227623!\n",
      "Avg loss: 0.056754180897878544!\n",
      "Avg loss: 0.05670225187222968!\n",
      "Avg loss: 0.0565914362011002!\n",
      "Avg loss: 0.056491377217438035!\n",
      "Avg loss: 0.05633640070527084!\n",
      "Avg loss: 0.056186353736447925!\n",
      "Avg loss: 0.056132730528370305!\n",
      "Avg loss: 0.056020238244618666!\n",
      "Avg loss: 0.05586791525489995!\n",
      "Avg loss: 0.05574607460142336!\n",
      "Avg loss: 0.05569986599891612!\n",
      "Avg loss: 0.05563477872464318!\n",
      "Avg loss: 0.055431016026474635!\n",
      "Avg loss: 0.05537307753267062!\n",
      "Avg loss: 0.05523999098274241!\n",
      "Avg loss: 0.055231138918519114!\n",
      "Avg loss: 0.055025403786852015!\n",
      "Avg loss: 0.05495505509900492!\n",
      "Avg loss: 0.05479484793289885!\n",
      "Avg loss: 0.0547698624921001!\n",
      "Avg loss: 0.054675232774364604!\n",
      "Avg loss: 0.05459708090462603!\n",
      "Avg loss: 0.054415930228921446!\n",
      "Avg loss: 0.05427081479528776!\n",
      "Avg loss: 0.0541900688487173!\n",
      "Avg loss: 0.05414410831319401!\n",
      "Avg loss: 0.05401690993081502!\n",
      "Avg loss: 0.05390883592613136!\n",
      "Avg loss: 0.053781761097582904!\n",
      "Avg loss: 0.05377518718593213!\n",
      "Avg loss: 0.053592492058581534!\n",
      "Avg loss: 0.05361494609028341!\n",
      "Avg loss: 0.05341660508178696!\n",
      "Avg loss: 0.05349040056069498!\n",
      "Avg loss: 0.053214220056391544!\n",
      "Avg loss: 0.05325355769314229!\n",
      "Avg loss: 0.053040793160155315!\n",
      "Avg loss: 0.05318077386239869!\n",
      "Avg loss: 0.05294837796749107!\n",
      "Avg loss: 0.053041377800764164!\n",
      "Avg loss: 0.05276896319328443!\n",
      "Avg loss: 0.05290033499114846!\n",
      "Avg loss: 0.05262386702530421!\n",
      "Avg loss: 0.05276948791245559!\n",
      "Avg loss: 0.05251414569034144!\n",
      "Avg loss: 0.05267581917032506!\n",
      "Avg loss: 0.05238803039905179!\n",
      "Avg loss: 0.05251309204786594!\n",
      "Avg loss: 0.05225819166350751!\n",
      "Avg loss: 0.052471762806890185!\n",
      "Avg loss: 0.05220643529416217!\n",
      "Avg loss: 0.05236340040926734!\n",
      "Avg loss: 0.05203423549241658!\n",
      "Avg loss: 0.05232256722769913!\n",
      "Avg loss: 0.052078445794631986!\n",
      "Avg loss: 0.052296411295756115!\n",
      "Avg loss: 0.0519302028314208!\n",
      "Avg loss: 0.052236491317938394!\n",
      "Avg loss: 0.05172061892530716!\n",
      "Avg loss: 0.051872932944485604!\n",
      "Avg loss: 0.051247236310910015!\n",
      "Avg loss: 0.05166845351089175!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.06e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 354       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 5         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -933     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 333      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 12       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.000915 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00813  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 11       |\n",
      "|    policy_objective       | 0.00713  |\n",
      "|    std                    | 1.13     |\n",
      "|    value_loss             | 5.82e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -958     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 338      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 18       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.000461 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00868  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 12       |\n",
      "|    policy_objective       | 0.00271  |\n",
      "|    std                    | 1.08     |\n",
      "|    value_loss             | 3.86e+03 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -944     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 335      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 24       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.0019   |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.009    |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 13       |\n",
      "|    policy_objective       | 0.011    |\n",
      "|    std                    | 1.15     |\n",
      "|    value_loss             | 5.16e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -974     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 332      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 30       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.00113  |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00938  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 14       |\n",
      "|    policy_objective       | 0.0117   |\n",
      "|    std                    | 1.18     |\n",
      "|    value_loss             | 4.58e+03 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1158.7312382165342\n",
      "------------------------------\n",
      "round: 3\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.003409306312884534!\n",
      "Avg loss: 0.002528925080575088!\n",
      "Avg loss: 0.011573645865816313!\n",
      "Avg loss: 0.0030754885171942682!\n",
      "Avg loss: 0.0030909851124548975!\n",
      "Avg loss: 0.002864939764931478!\n",
      "Avg loss: 0.005322177289732887!\n",
      "Avg loss: 0.001768086271968059!\n",
      "Avg loss: 0.0017608903756869646!\n",
      "Avg loss: 0.0031666519501474494!\n",
      "Avg loss: 0.0025362699476803147!\n",
      "Avg loss: 0.001754332396267273!\n",
      "Avg loss: 0.002289690732880748!\n",
      "Avg loss: 0.0026914928245241753!\n",
      "Avg loss: 0.0019301567174867765!\n",
      "Avg loss: 0.00209199778278465!\n",
      "Avg loss: 0.0025076556355876772!\n",
      "Avg loss: 0.001995045357101238!\n",
      "Avg loss: 0.00204481373963669!\n",
      "Avg loss: 0.002322211585797049!\n",
      "Avg loss: 0.0021121149401430255!\n",
      "Avg loss: 0.0021082342059647393!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.018074076006402418!\n",
      "Avg loss: 0.018109499973036992!\n",
      "Avg loss: 0.01708331717506856!\n",
      "Avg loss: 0.016495030619795823!\n",
      "Avg loss: 0.016939911712018633!\n",
      "Avg loss: 0.016255658835308773!\n",
      "Avg loss: 0.01626618952544201!\n",
      "Avg loss: 0.015954800100316788!\n",
      "Avg loss: 0.016218706668835996!\n",
      "Avg loss: 0.01599370005005767!\n",
      "Avg loss: 0.016073164886282333!\n",
      "Avg loss: 0.015955079916985446!\n",
      "Avg loss: 0.016093157935282154!\n",
      "Avg loss: 0.01598598334561454!\n",
      "Avg loss: 0.015952047512643428!\n",
      "Avg loss: 0.015929482592212024!\n",
      "Avg loss: 0.015953949216541332!\n",
      "Avg loss: 0.01585949458668286!\n",
      "Avg loss: 0.015845019480337518!\n",
      "Avg loss: 0.015881781578730547!\n",
      "Avg loss: 0.015862622963850298!\n",
      "Avg loss: 0.015832316588766843!\n",
      "Avg loss: 0.015814659575657686!\n",
      "Avg loss: 0.015825990487448205!\n",
      "Avg loss: 0.015805573998466875!\n",
      "Avg loss: 0.01580162620774312!\n",
      "Avg loss: 0.01581463205384883!\n",
      "Avg loss: 0.015801331429740155!\n",
      "Avg loss: 0.01579525723691442!\n",
      "Avg loss: 0.015797411696766517!\n",
      "Avg loss: 0.015797137054542342!\n",
      "Avg loss: 0.015794900476376293!\n",
      "Avg loss: 0.01579549211507962!\n",
      "Avg loss: 0.015791615623514114!\n",
      "Avg loss: 0.015786072456499673!\n",
      "Avg loss: 0.015786527170366754!\n",
      "Avg loss: 0.015781790905123216!\n",
      "Avg loss: 0.015787716206640046!\n",
      "Avg loss: 0.01577967390672711!\n",
      "Avg loss: 0.015774077926010554!\n",
      "Avg loss: 0.01576401729178902!\n",
      "Avg loss: 0.015776987110854557!\n",
      "Avg loss: 0.015780128361286453!\n",
      "Avg loss: 0.015775914920584454!\n",
      "Avg loss: 0.01577822662963854!\n",
      "Avg loss: 0.015787017240380313!\n",
      "Avg loss: 0.015781495382065316!\n",
      "Avg loss: 0.01577921736038358!\n",
      "Avg loss: 0.015781218423591856!\n",
      "Avg loss: 0.015791750731801432!\n",
      "Avg loss: 0.0157748472597738!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.14169879199757512!\n",
      "Avg loss: 0.1453422299364441!\n",
      "Avg loss: 0.152399819951!\n",
      "Avg loss: 0.14545797797039994!\n",
      "Avg loss: 0.14397218856262042!\n",
      "Avg loss: 0.14426864431963624!\n",
      "Avg loss: 0.14747889093327105!\n",
      "Avg loss: 0.14377901981305816!\n",
      "Avg loss: 0.1427198998212892!\n",
      "Avg loss: 0.14464554040878283!\n",
      "Avg loss: 0.1451927563348454!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -999     |\n",
      "| time/              |          |\n",
      "|    fps             | 336      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.13e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 353       |\n",
      "|    iterations             | 2         |\n",
      "|    time_elapsed           | 11        |\n",
      "|    total_timesteps        | 4096      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.00131   |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00863   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 16        |\n",
      "|    policy_objective       | 0.0124    |\n",
      "|    std                    | 1.13      |\n",
      "|    value_loss             | 4.11e+03  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -1.1e+03 |\n",
      "| time/                     |          |\n",
      "|    fps                    | 360      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.0463   |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00447  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 17       |\n",
      "|    policy_objective       | 0.00365  |\n",
      "|    std                    | 1.11     |\n",
      "|    value_loss             | 5.24e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -983     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 367      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 22       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.153    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00872  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 18       |\n",
      "|    policy_objective       | 0.00916  |\n",
      "|    std                    | 1.13     |\n",
      "|    value_loss             | 3.86e+03 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 200       |\n",
      "|    ep_rew_mean            | -1.01e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 366       |\n",
      "|    iterations             | 5         |\n",
      "|    time_elapsed           | 27        |\n",
      "|    total_timesteps        | 10240     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 0.484     |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00928   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 19        |\n",
      "|    policy_objective       | 0.00582   |\n",
      "|    std                    | 1.19      |\n",
      "|    value_loss             | 2.3e+03   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1228.8602546133102\n",
      "------------------------------\n",
      "round: 4\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.1643475453557524!\n",
      "Avg loss: 0.15794534383848563!\n",
      "Avg loss: 0.15469655744503447!\n",
      "Avg loss: 0.1555987290294191!\n",
      "Avg loss: 0.158597077924472!\n",
      "Avg loss: 0.15400842806317996!\n",
      "Avg loss: 0.1537402785443798!\n",
      "Avg loss: 0.1563517858541066!\n",
      "Avg loss: 0.15559829000232034!\n",
      "Avg loss: 0.15444059458745263!\n",
      "Avg loss: 0.15493907651295102!\n",
      "Avg loss: 0.15487573009279004!\n",
      "Avg loss: 0.15494545248589323!\n",
      "Avg loss: 0.15429878203591216!\n",
      "Avg loss: 0.15440125435157218!\n",
      "Avg loss: 0.15476275004134246!\n",
      "Avg loss: 0.1548610659218078!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.00885215488053897!\n",
      "Avg loss: 0.007585348767412749!\n",
      "Avg loss: 0.006480358012631768!\n",
      "Avg loss: 0.00682442158125923!\n",
      "Avg loss: 0.004519472423368522!\n",
      "Avg loss: 0.00470334163842684!\n",
      "Avg loss: 0.0040242712119652425!\n",
      "Avg loss: 0.004731065232457089!\n",
      "Avg loss: 0.003868184757405591!\n",
      "Avg loss: 0.0037149410268527087!\n",
      "Avg loss: 0.00364309368464698!\n",
      "Avg loss: 0.0037635176291890577!\n",
      "Avg loss: 0.0036421755707245515!\n",
      "Avg loss: 0.003490707463473276!\n",
      "Avg loss: 0.003434938432352889!\n",
      "Avg loss: 0.0035313938692828136!\n",
      "Avg loss: 0.003422105184630103!\n",
      "Avg loss: 0.0033205450736447043!\n",
      "Avg loss: 0.0033031594513886374!\n",
      "Avg loss: 0.0033014442897426003!\n",
      "Avg loss: 0.0032131244728831614!\n",
      "Avg loss: 0.0031579188991357416!\n",
      "Avg loss: 0.00320169596490814!\n",
      "Avg loss: 0.0032125348330191627!\n",
      "Avg loss: 0.003168480424125543!\n",
      "Avg loss: 0.00315638905743981!\n",
      "Avg loss: 0.0031573525532636875!\n",
      "Avg loss: 0.003159680662029132!\n",
      "Avg loss: 0.003132296579503115!\n",
      "Avg loss: 0.003125845656459205!\n",
      "Avg loss: 0.0031672502944972316!\n",
      "Avg loss: 0.003120118607043878!\n",
      "Avg loss: 0.0030678493137020267!\n",
      "Avg loss: 0.00308629185987229!\n",
      "Avg loss: 0.0031040241796290503!\n",
      "Avg loss: 0.0030941602701659576!\n",
      "Avg loss: 0.003097909826092291!\n",
      "Avg loss: 0.0031534979049683896!\n",
      "Avg loss: 0.0031240407830470454!\n",
      "Avg loss: 0.003101498297319267!\n",
      "Avg loss: 0.0030859574377518585!\n",
      "Avg loss: 0.003094661925024411!\n",
      "Avg loss: 0.003119450702286789!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.05814941540151873!\n",
      "Avg loss: 0.05889911071479825!\n",
      "Avg loss: 0.058614358843963904!\n",
      "Avg loss: 0.056271903072071534!\n",
      "Avg loss: 0.05779118561860135!\n",
      "Avg loss: 0.05701140662919594!\n",
      "Avg loss: 0.056832436422519096!\n",
      "Avg loss: 0.05651576382690109!\n",
      "Avg loss: 0.05735294631459207!\n",
      "Avg loss: 0.05685328455864995!\n",
      "Avg loss: 0.05707421494211303!\n",
      "Avg loss: 0.05718211978498099!\n",
      "Avg loss: 0.05708441141456205!\n",
      "Avg loss: 0.057180813942159146!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.01e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 383       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 5         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -916     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 378      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 10       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.614    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00722  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 21       |\n",
      "|    policy_objective       | 0.00658  |\n",
      "|    std                    | 1.15     |\n",
      "|    value_loss             | 3.74e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -826     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 374      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 16       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.715    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00605  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 22       |\n",
      "|    policy_objective       | 0.00984  |\n",
      "|    std                    | 1.14     |\n",
      "|    value_loss             | 2.71e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -813     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 373      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 21       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.753    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00833  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 23       |\n",
      "|    policy_objective       | 0.00553  |\n",
      "|    std                    | 1.13     |\n",
      "|    value_loss             | 2.09e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -837     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 365      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 27       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.785    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00829  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 24       |\n",
      "|    policy_objective       | 0.00691  |\n",
      "|    std                    | 1.05     |\n",
      "|    value_loss             | 2.53e+03 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1367.5842231348156\n",
      "------------------------------\n",
      "round: 5\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.10023965090125178!\n",
      "Avg loss: 0.08023461091374581!\n",
      "Avg loss: 0.08687886675033951!\n",
      "Avg loss: 0.08150165693448798!\n",
      "Avg loss: 0.08665898822890691!\n",
      "Avg loss: 0.07946988842852686!\n",
      "Avg loss: 0.07986952317697918!\n",
      "Avg loss: 0.08233519859523464!\n",
      "Avg loss: 0.0813041020395273!\n",
      "Avg loss: 0.07956898282701634!\n",
      "Avg loss: 0.07936479059765891!\n",
      "Avg loss: 0.08129151882533431!\n",
      "Avg loss: 0.07942385632021796!\n",
      "Avg loss: 0.07930223400753068!\n",
      "Avg loss: 0.0805092158925072!\n",
      "Avg loss: 0.07999561766509335!\n",
      "Avg loss: 0.07931799208848436!\n",
      "Avg loss: 0.07973925264380645!\n",
      "Avg loss: 0.07977315062909081!\n",
      "Avg loss: 0.07923912030302745!\n",
      "Avg loss: 0.07966202736244062!\n",
      "Avg loss: 0.07974444111334984!\n",
      "Avg loss: 0.07943062376161833!\n",
      "Avg loss: 0.07962122254505327!\n",
      "Avg loss: 0.07950980549093704!\n",
      "Avg loss: 0.07932751366268954!\n",
      "Avg loss: 0.07956332922960428!\n",
      "Avg loss: 0.07938925306060507!\n",
      "Avg loss: 0.07940012105059092!\n",
      "Avg loss: 0.07950879215699085!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.09236394254844829!\n",
      "Avg loss: 0.08285509808517721!\n",
      "Avg loss: 0.08267550261797926!\n",
      "Avg loss: 0.08367019477962458!\n",
      "Avg loss: 0.08358949281044867!\n",
      "Avg loss: 0.07966912135239303!\n",
      "Avg loss: 0.07905449343301976!\n",
      "Avg loss: 0.08152793611174275!\n",
      "Avg loss: 0.07793588105105907!\n",
      "Avg loss: 0.07745770142316663!\n",
      "Avg loss: 0.07875073082824505!\n",
      "Avg loss: 0.07810549478707496!\n",
      "Avg loss: 0.07726820269502241!\n",
      "Avg loss: 0.07792367611698259!\n",
      "Avg loss: 0.07770806471583759!\n",
      "Avg loss: 0.07703073291547602!\n",
      "Avg loss: 0.07747220788702786!\n",
      "Avg loss: 0.07722285606259902!\n",
      "Avg loss: 0.07691663519050053!\n",
      "Avg loss: 0.0771186250827183!\n",
      "Avg loss: 0.0768903124105691!\n",
      "Avg loss: 0.07685321524097162!\n",
      "Avg loss: 0.07683645595244494!\n",
      "Avg loss: 0.07664577984917136!\n",
      "Avg loss: 0.0766581298522336!\n",
      "Avg loss: 0.07671446241189793!\n",
      "Avg loss: 0.07670758860005056!\n",
      "Avg loss: 0.0766304759381698!\n",
      "Avg loss: 0.07661835758488147!\n",
      "Avg loss: 0.07654317578853806!\n",
      "Avg loss: 0.07659092145754282!\n",
      "Avg loss: 0.07656400699411885!\n",
      "Avg loss: 0.07648934587584032!\n",
      "Avg loss: 0.07655535684305505!\n",
      "Avg loss: 0.07647778053980801!\n",
      "Avg loss: 0.07650173857584378!\n",
      "Avg loss: 0.07644131891477628!\n",
      "Avg loss: 0.07649408403716734!\n",
      "Avg loss: 0.07646605108053336!\n",
      "Avg loss: 0.07642230824068974!\n",
      "Avg loss: 0.07638495600450067!\n",
      "Avg loss: 0.0764645971824469!\n",
      "Avg loss: 0.07643656000777203!\n",
      "Avg loss: 0.07644779731617443!\n",
      "Avg loss: 0.07642636797025867!\n",
      "Avg loss: 0.07641736104674844!\n",
      "Avg loss: 0.0763879580415475!\n",
      "Avg loss: 0.07646300220903868!\n",
      "Avg loss: 0.07642321438487822!\n",
      "Avg loss: 0.07652027995639098!\n",
      "Avg loss: 0.0764490756219675!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.005468898019559371!\n",
      "Avg loss: 0.00852997452088554!\n",
      "Avg loss: 0.009229895743634794!\n",
      "Avg loss: 0.010452620902190877!\n",
      "Avg loss: 0.007528225823128499!\n",
      "Avg loss: 0.007273504266983461!\n",
      "Avg loss: 0.008921165281838814!\n",
      "Avg loss: 0.007783417110446559!\n",
      "Avg loss: 0.006890422609091426!\n",
      "Avg loss: 0.006742597011846859!\n",
      "Avg loss: 0.007497902334992735!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -950     |\n",
      "| time/              |          |\n",
      "|    fps             | 322      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -856     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 333      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 12       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.801    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00807  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 26       |\n",
      "|    policy_objective       | 0.0105   |\n",
      "|    std                    | 1.02     |\n",
      "|    value_loss             | 2.73e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -802     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 349      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.857    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00888  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 27       |\n",
      "|    policy_objective       | 0.00876  |\n",
      "|    std                    | 1.01     |\n",
      "|    value_loss             | 1.89e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -716     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 355      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 23       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.882    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00892  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 28       |\n",
      "|    policy_objective       | 0.0085   |\n",
      "|    std                    | 1.05     |\n",
      "|    value_loss             | 2.17e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -782     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 354      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 28       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.903    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00521  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 29       |\n",
      "|    policy_objective       | 0.0056   |\n",
      "|    std                    | 1.1      |\n",
      "|    value_loss             | 1.23e+03 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1175.1042507975246\n",
      "------------------------------\n",
      "round: 6\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.012565953197384563!\n",
      "Avg loss: 0.004143941460182153!\n",
      "Avg loss: 0.009571078109438531!\n",
      "Avg loss: 0.005189227179677497!\n",
      "Avg loss: 0.007325558829810082!\n",
      "Avg loss: 0.004945146506142919!\n",
      "Avg loss: 0.005425397022724307!\n",
      "Avg loss: 0.0048182164719340415!\n",
      "Avg loss: 0.004866496820131943!\n",
      "Avg loss: 0.0047062925741192885!\n",
      "Avg loss: 0.004585233537103098!\n",
      "Avg loss: 0.004936015501419509!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.13794082816762965!\n",
      "Avg loss: 0.136621521094033!\n",
      "Avg loss: 0.1524026427999767!\n",
      "Avg loss: 0.13937880492706123!\n",
      "Avg loss: 0.13631233582080313!\n",
      "Avg loss: 0.14083076499710842!\n",
      "Avg loss: 0.14443026696061984!\n",
      "Avg loss: 0.13762888826808195!\n",
      "Avg loss: 0.13683285032709439!\n",
      "Avg loss: 0.14101210918629173!\n",
      "Avg loss: 0.14014361250893367!\n",
      "Avg loss: 0.1368715279616663!\n",
      "Avg loss: 0.13827482001630415!\n",
      "Avg loss: 0.14015849575526468!\n",
      "Avg loss: 0.13784468566896976!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.03568076075061981!\n",
      "Avg loss: 0.030321944521880747!\n",
      "Avg loss: 0.034876796703319994!\n",
      "Avg loss: 0.029934234211371705!\n",
      "Avg loss: 0.030215185486886186!\n",
      "Avg loss: 0.031334066505514784!\n",
      "Avg loss: 0.02962061725269753!\n",
      "Avg loss: 0.030062861915600175!\n",
      "Avg loss: 0.02966542530415912!\n",
      "Avg loss: 0.029754047288818888!\n",
      "Avg loss: 0.029355999654095893!\n",
      "Avg loss: 0.029112731578376648!\n",
      "Avg loss: 0.02915923924319941!\n",
      "Avg loss: 0.028869285067673143!\n",
      "Avg loss: 0.028894606231673!\n",
      "Avg loss: 0.029056647102891776!\n",
      "Avg loss: 0.02898809935262155!\n",
      "Avg loss: 0.029028565241639322!\n",
      "Avg loss: 0.0290358144216043!\n",
      "Avg loss: 0.02905402415787724!\n",
      "Avg loss: 0.02916844145468834!\n",
      "Avg loss: 0.029175278605925618!\n",
      "Avg loss: 0.02921324821651524!\n",
      "Avg loss: 0.029267933543202767!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -940     |\n",
      "| time/              |          |\n",
      "|    fps             | 376      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -877     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 358      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 11       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.91     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00906  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 31       |\n",
      "|    policy_objective       | 0.00561  |\n",
      "|    std                    | 1.02     |\n",
      "|    value_loss             | 1.72e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -834     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 341      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.903    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00797  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 32       |\n",
      "|    policy_objective       | 0.0044   |\n",
      "|    std                    | 0.976    |\n",
      "|    value_loss             | 1.59e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -844     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 337      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 24       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.913    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00717  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 33       |\n",
      "|    policy_objective       | 0.00658  |\n",
      "|    std                    | 0.914    |\n",
      "|    value_loss             | 1.66e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -813     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 338      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 30       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.874    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00525  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 34       |\n",
      "|    policy_objective       | 0.00822  |\n",
      "|    std                    | 0.911    |\n",
      "|    value_loss             | 1.74e+03 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1158.7137848503887\n",
      "------------------------------\n",
      "round: 7\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.012233895704654666!\n",
      "Avg loss: 0.006985509525208424!\n",
      "Avg loss: 0.010086658815853298!\n",
      "Avg loss: 0.0034903589707422117!\n",
      "Avg loss: 0.00826586333780142!\n",
      "Avg loss: 0.003270671615343114!\n",
      "Avg loss: 0.004422586361858218!\n",
      "Avg loss: 0.004420451963984912!\n",
      "Avg loss: 0.0045963689882167575!\n",
      "Avg loss: 0.0037334923098023866!\n",
      "Avg loss: 0.0034311304682584404!\n",
      "Avg loss: 0.00415271955896363!\n",
      "Avg loss: 0.0033594904770537443!\n",
      "Avg loss: 0.003408101385042149!\n",
      "Avg loss: 0.0037468964575828067!\n",
      "Avg loss: 0.0035529175503264316!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.012418257006987309!\n",
      "Avg loss: 0.005735598816681886!\n",
      "Avg loss: 0.005414237214863533!\n",
      "Avg loss: 0.005263586261304833!\n",
      "Avg loss: 0.003836544488064343!\n",
      "Avg loss: 0.004779216960863171!\n",
      "Avg loss: 0.003309505354579111!\n",
      "Avg loss: 0.0036466441119167334!\n",
      "Avg loss: 0.004143624036878464!\n",
      "Avg loss: 0.0035830801713018444!\n",
      "Avg loss: 0.003589843320999838!\n",
      "Avg loss: 0.0035487087149613217!\n",
      "Avg loss: 0.003742641210938018!\n",
      "Avg loss: 0.0034974571136020434!\n",
      "Avg loss: 0.003456266019687367!\n",
      "Avg loss: 0.003626468866605137!\n",
      "Avg loss: 0.0035603371625741904!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.0071505509389135115!\n",
      "Avg loss: 0.00512865021834538!\n",
      "Avg loss: 0.011083371824546096!\n",
      "Avg loss: 0.003881246920876341!\n",
      "Avg loss: 0.00432725150315188!\n",
      "Avg loss: 0.007034728084145172!\n",
      "Avg loss: 0.006287412220881378!\n",
      "Avg loss: 0.005016025432450988!\n",
      "Avg loss: 0.005502560271694771!\n",
      "Avg loss: 0.007042995169916443!\n",
      "Avg loss: 0.005262700142363125!\n",
      "Avg loss: 0.005061080621744623!\n",
      "Avg loss: 0.006110815016054403!\n",
      "Avg loss: 0.00577379185948909!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -826     |\n",
      "| time/              |          |\n",
      "|    fps             | 303      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -897     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 302      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 13       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.883    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00947  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 36       |\n",
      "|    policy_objective       | 0.0075   |\n",
      "|    std                    | 0.87     |\n",
      "|    value_loss             | 1.5e+03  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -796     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 296      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 20       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.924    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00788  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 37       |\n",
      "|    policy_objective       | 0.00906  |\n",
      "|    std                    | 0.849    |\n",
      "|    value_loss             | 1.81e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -836     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 295      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 27       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.922    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00833  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 38       |\n",
      "|    policy_objective       | 0.0118   |\n",
      "|    std                    | 0.848    |\n",
      "|    value_loss             | 1.21e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -821     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 293      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 34       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.946    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0066   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 39       |\n",
      "|    policy_objective       | 0.00574  |\n",
      "|    std                    | 0.827    |\n",
      "|    value_loss             | 1.52e+03 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1175.5295694340953\n",
      "------------------------------\n",
      "round: 8\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.016530650079463763!\n",
      "Avg loss: 0.012139073769794777!\n",
      "Avg loss: 0.00786695308944521!\n",
      "Avg loss: 0.004254940289514101!\n",
      "Avg loss: 0.010402192203813077!\n",
      "Avg loss: 0.007816584832495815!\n",
      "Avg loss: 0.005340477406134596!\n",
      "Avg loss: 0.004702963253948838!\n",
      "Avg loss: 0.0068170562655480655!\n",
      "Avg loss: 0.0064141869006319515!\n",
      "Avg loss: 0.005013921862761587!\n",
      "Avg loss: 0.004830193004981993!\n",
      "Avg loss: 0.006035376152091582!\n",
      "Avg loss: 0.005737127022370411!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.009727804911623632!\n",
      "Avg loss: 0.0055621269835683055!\n",
      "Avg loss: 0.008337212240245815!\n",
      "Avg loss: 0.005869888211018406!\n",
      "Avg loss: 0.006461059400535305!\n",
      "Avg loss: 0.005836749406298623!\n",
      "Avg loss: 0.0052688467863481496!\n",
      "Avg loss: 0.005982109007006026!\n",
      "Avg loss: 0.0057701181012089365!\n",
      "Avg loss: 0.00588229005537869!\n",
      "Avg loss: 0.0054891447747407555!\n",
      "Avg loss: 0.00537921736795397!\n",
      "Avg loss: 0.0056546402436773256!\n",
      "Avg loss: 0.005547321217078812!\n",
      "Avg loss: 0.005498963013512063!\n",
      "Avg loss: 0.005519422352930027!\n",
      "Avg loss: 0.005501439589030876!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.019659030467058376!\n",
      "Avg loss: 0.01414407434417323!\n",
      "Avg loss: 0.013154462528182193!\n",
      "Avg loss: 0.01280207774942634!\n",
      "Avg loss: 0.01478193493287108!\n",
      "Avg loss: 0.011207121043304747!\n",
      "Avg loss: 0.011382073548702465!\n",
      "Avg loss: 0.011755778652614027!\n",
      "Avg loss: 0.011736354712484172!\n",
      "Avg loss: 0.010646662305371138!\n",
      "Avg loss: 0.010681738440198388!\n",
      "Avg loss: 0.011045531301851952!\n",
      "Avg loss: 0.01057039949039743!\n",
      "Avg loss: 0.010326691479032585!\n",
      "Avg loss: 0.010453807626217894!\n",
      "Avg loss: 0.010450817035641649!\n",
      "Avg loss: 0.010243516425715976!\n",
      "Avg loss: 0.010267154537350507!\n",
      "Avg loss: 0.010225252719787931!\n",
      "Avg loss: 0.010167252419673976!\n",
      "Avg loss: 0.01018201032416755!\n",
      "Avg loss: 0.010115018448634222!\n",
      "Avg loss: 0.010061059080322442!\n",
      "Avg loss: 0.01006657897650257!\n",
      "Avg loss: 0.010013836516697931!\n",
      "Avg loss: 0.010008227622074628!\n",
      "Avg loss: 0.010015136761852167!\n",
      "Avg loss: 0.009979755754640489!\n",
      "Avg loss: 0.009948413322605727!\n",
      "Avg loss: 0.009919051727771754!\n",
      "Avg loss: 0.009932677173599889!\n",
      "Avg loss: 0.009924854674666979!\n",
      "Avg loss: 0.009910863585989015!\n",
      "Avg loss: 0.009895327100196786!\n",
      "Avg loss: 0.009898236272304833!\n",
      "Avg loss: 0.009884989881741907!\n",
      "Avg loss: 0.009875263186102833!\n",
      "Avg loss: 0.009839581331687365!\n",
      "Avg loss: 0.009849996397038012!\n",
      "Avg loss: 0.009809280278497378!\n",
      "Avg loss: 0.00983603684316222!\n",
      "Avg loss: 0.009842998860893506!\n",
      "Avg loss: 0.009831503163071223!\n",
      "Avg loss: 0.009843093243367396!\n",
      "Avg loss: 0.009839872338338863!\n",
      "Avg loss: 0.009822956222618208!\n",
      "Avg loss: 0.009820677461411832!\n",
      "Avg loss: 0.009853923457855369!\n",
      "Avg loss: 0.00985792510418984!\n",
      "Avg loss: 0.00986836575663953!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -796     |\n",
      "| time/              |          |\n",
      "|    fps             | 314      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -819     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 306      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 13       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.954    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00647  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 41       |\n",
      "|    policy_objective       | 0.00924  |\n",
      "|    std                    | 0.824    |\n",
      "|    value_loss             | 974      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -776     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 299      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 20       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.917    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00732  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 42       |\n",
      "|    policy_objective       | 0.0109   |\n",
      "|    std                    | 0.822    |\n",
      "|    value_loss             | 1.63e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -749     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 300      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 27       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.95     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00739  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 43       |\n",
      "|    policy_objective       | 0.0159   |\n",
      "|    std                    | 0.812    |\n",
      "|    value_loss             | 956      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -750     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 298      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 34       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.949    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00821  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 44       |\n",
      "|    policy_objective       | 0.00947  |\n",
      "|    std                    | 0.78     |\n",
      "|    value_loss             | 1.08e+03 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1326.5077774971724\n",
      "------------------------------\n",
      "round: 9\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.006106265560568621!\n",
      "Avg loss: 0.007921256992121926!\n",
      "Avg loss: 0.013829384374136377!\n",
      "Avg loss: 0.009995835890464756!\n",
      "Avg loss: 0.006133798222217593!\n",
      "Avg loss: 0.00549706934125273!\n",
      "Avg loss: 0.010202965310115057!\n",
      "Avg loss: 0.006627226791533758!\n",
      "Avg loss: 0.005483214547778819!\n",
      "Avg loss: 0.006196909869092148!\n",
      "Avg loss: 0.007168309868963357!\n",
      "Avg loss: 0.005363166306339432!\n",
      "Avg loss: 0.005504019194837989!\n",
      "Avg loss: 0.006511425761900682!\n",
      "Avg loss: 0.0057885362388666785!\n",
      "Avg loss: 0.005473868753967205!\n",
      "Avg loss: 0.005955542971860268!\n",
      "Avg loss: 0.005721391316474183!\n",
      "Avg loss: 0.005229442318921732!\n",
      "Avg loss: 0.005583235747474949!\n",
      "Avg loss: 0.005683173842292793!\n",
      "Avg loss: 0.005507791838711759!\n",
      "Avg loss: 0.0055656515513055164!\n",
      "Avg loss: 0.005620843717903578!\n",
      "Avg loss: 0.005367375147774661!\n",
      "Avg loss: 0.005571313415728128!\n",
      "Avg loss: 0.005552501094598483!\n",
      "Avg loss: 0.005495766945417321!\n",
      "Avg loss: 0.005436147888063563!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.040160499710958295!\n",
      "Avg loss: 0.02992979367370329!\n",
      "Avg loss: 0.013444830736649843!\n",
      "Avg loss: 0.0086225824552821!\n",
      "Avg loss: 0.010911161888701221!\n",
      "Avg loss: 0.008136322476978724!\n",
      "Avg loss: 0.008729542270424039!\n",
      "Avg loss: 0.010329314268068022!\n",
      "Avg loss: 0.009796601127964094!\n",
      "Avg loss: 0.008890634660104601!\n",
      "Avg loss: 0.009428018018394747!\n",
      "Avg loss: 0.009343795351839313!\n",
      "Avg loss: 0.008954037220731455!\n",
      "Avg loss: 0.009189823613754318!\n",
      "Avg loss: 0.009086335436501638!\n",
      "Avg loss: 0.008613187196739697!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.012758501574086646!\n",
      "Avg loss: 0.008338430028331156!\n",
      "Avg loss: 0.013577839990806145!\n",
      "Avg loss: 0.006962933644889896!\n",
      "Avg loss: 0.008209154941432643!\n",
      "Avg loss: 0.009174403384046551!\n",
      "Avg loss: 0.006977389436409188!\n",
      "Avg loss: 0.0057303104342524116!\n",
      "Avg loss: 0.006255618846395616!\n",
      "Avg loss: 0.007268910175625933!\n",
      "Avg loss: 0.0064800899751086645!\n",
      "Avg loss: 0.00643919199865195!\n",
      "Avg loss: 0.006693645628104908!\n",
      "Avg loss: 0.007018697273597354!\n",
      "Avg loss: 0.006468119402494873!\n",
      "Avg loss: 0.006393225429880355!\n",
      "Avg loss: 0.006571704822587587!\n",
      "Avg loss: 0.006581466755202807!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -715     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -704     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 311      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 13       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.95     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00711  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 46       |\n",
      "|    policy_objective       | 0.011    |\n",
      "|    std                    | 0.732    |\n",
      "|    value_loss             | 1.45e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -715     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 303      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 20       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.966    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00631  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 47       |\n",
      "|    policy_objective       | 0.00926  |\n",
      "|    std                    | 0.708    |\n",
      "|    value_loss             | 904      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -781     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 300      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 27       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.945    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00528  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 48       |\n",
      "|    policy_objective       | 0.017    |\n",
      "|    std                    | 0.716    |\n",
      "|    value_loss             | 1.38e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -826     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 296      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 34       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.972    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00617  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 49       |\n",
      "|    policy_objective       | 0.0122   |\n",
      "|    std                    | 0.72     |\n",
      "|    value_loss             | 985      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1325.5185223177075\n",
      "------------------------------\n",
      "round: 10\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.021980649655452!\n",
      "Avg loss: 0.007814978727061923!\n",
      "Avg loss: 0.005571111208992079!\n",
      "Avg loss: 0.009677671071064348!\n",
      "Avg loss: 0.004246379798654137!\n",
      "Avg loss: 0.006023968775892475!\n",
      "Avg loss: 0.005144398563813108!\n",
      "Avg loss: 0.0047501317229277145!\n",
      "Avg loss: 0.004665938170461838!\n",
      "Avg loss: 0.004026795603276696!\n",
      "Avg loss: 0.004461893031257205!\n",
      "Avg loss: 0.0038483093263736614!\n",
      "Avg loss: 0.0037553237916654325!\n",
      "Avg loss: 0.003873771583021153!\n",
      "Avg loss: 0.003768658143041345!\n",
      "Avg loss: 0.0036353084663884754!\n",
      "Avg loss: 0.0035732655508036257!\n",
      "Avg loss: 0.0036486875684386176!\n",
      "Avg loss: 0.0034295846295268953!\n",
      "Avg loss: 0.003536466662226303!\n",
      "Avg loss: 0.0034987951640747875!\n",
      "Avg loss: 0.003341149108867588!\n",
      "Avg loss: 0.0034095996174983156!\n",
      "Avg loss: 0.003279882094387479!\n",
      "Avg loss: 0.0033470695433788934!\n",
      "Avg loss: 0.0033795632792437877!\n",
      "Avg loss: 0.0033786443391121187!\n",
      "Avg loss: 0.0033218705535515863!\n",
      "Avg loss: 0.003351542077244479!\n",
      "Avg loss: 0.003381431593428109!\n",
      "Avg loss: 0.0031597478847349217!\n",
      "Avg loss: 0.003232708763285146!\n",
      "Avg loss: 0.003209332306754125!\n",
      "Avg loss: 0.003087429340293966!\n",
      "Avg loss: 0.0031859395873774093!\n",
      "Avg loss: 0.0032285352710308265!\n",
      "Avg loss: 0.0033007027178761444!\n",
      "Avg loss: 0.003092287390547123!\n",
      "Avg loss: 0.003072583200500958!\n",
      "Avg loss: 0.002972947488585002!\n",
      "Avg loss: 0.0031686495218915902!\n",
      "Avg loss: 0.0031134856041618755!\n",
      "Avg loss: 0.003269060941420321!\n",
      "Avg loss: 0.003027266964424295!\n",
      "Avg loss: 0.0029848139918613016!\n",
      "Avg loss: 0.002975688643121733!\n",
      "Avg loss: 0.003019916682881103!\n",
      "Avg loss: 0.003026177526523194!\n",
      "Avg loss: 0.0032183524963951033!\n",
      "Avg loss: 0.003071166742972006!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.1287890504262517!\n",
      "Avg loss: 0.12552720840810253!\n",
      "Avg loss: 0.13453861732254155!\n",
      "Avg loss: 0.12463960439378752!\n",
      "Avg loss: 0.12551687666365371!\n",
      "Avg loss: 0.12903968824655748!\n",
      "Avg loss: 0.12682947656488977!\n",
      "Avg loss: 0.12499391015939182!\n",
      "Avg loss: 0.1262289006635304!\n",
      "Avg loss: 0.12671891509574681!\n",
      "Avg loss: 0.12491117682143037!\n",
      "Avg loss: 0.12496444883579898!\n",
      "Avg loss: 0.12616674062627073!\n",
      "Avg loss: 0.12505451649203678!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.008141736958059483!\n",
      "Avg loss: 0.007230280236884331!\n",
      "Avg loss: 0.012518834923685062!\n",
      "Avg loss: 0.007326694450845632!\n",
      "Avg loss: 0.007234293806820157!\n",
      "Avg loss: 0.0062529819570772815!\n",
      "Avg loss: 0.006921035546498994!\n",
      "Avg loss: 0.004934591304269513!\n",
      "Avg loss: 0.005967610980442259!\n",
      "Avg loss: 0.005026836463548534!\n",
      "Avg loss: 0.0058271467895489575!\n",
      "Avg loss: 0.005476655553478243!\n",
      "Avg loss: 0.005264642364879061!\n",
      "Avg loss: 0.005401790251732261!\n",
      "Avg loss: 0.005253644184303994!\n",
      "Avg loss: 0.005003501042519929!\n",
      "Avg loss: 0.0050534603191257094!\n",
      "Avg loss: 0.005170350308029204!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -882     |\n",
      "| time/              |          |\n",
      "|    fps             | 300      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -731     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 286      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 14       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.976    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00758  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 51       |\n",
      "|    policy_objective       | 0.0112   |\n",
      "|    std                    | 0.7      |\n",
      "|    value_loss             | 840      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -756     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 289      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 21       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.961    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00848  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 52       |\n",
      "|    policy_objective       | 0.0249   |\n",
      "|    std                    | 0.708    |\n",
      "|    value_loss             | 1.03e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -754     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 289      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 28       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.973    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00518  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 53       |\n",
      "|    policy_objective       | 0.0205   |\n",
      "|    std                    | 0.715    |\n",
      "|    value_loss             | 914      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -826     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 293      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 34       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.988    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00739  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 54       |\n",
      "|    policy_objective       | 0.0199   |\n",
      "|    std                    | 0.707    |\n",
      "|    value_loss             | 590      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1409.9674675757065\n",
      "------------------------------\n",
      "round: 11\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.01257727831621499!\n",
      "Avg loss: 0.008659438780741767!\n",
      "Avg loss: 0.010814344011887442!\n",
      "Avg loss: 0.005820762286233124!\n",
      "Avg loss: 0.006591249438594483!\n",
      "Avg loss: 0.004296779737063237!\n",
      "Avg loss: 0.0052589676409843375!\n",
      "Avg loss: 0.004229323764611763!\n",
      "Avg loss: 0.00406940784889836!\n",
      "Avg loss: 0.003837413249190528!\n",
      "Avg loss: 0.0037509150746821737!\n",
      "Avg loss: 0.003821650171861014!\n",
      "Avg loss: 0.0034541497043998485!\n",
      "Avg loss: 0.0035479215521384807!\n",
      "Avg loss: 0.003511425889895084!\n",
      "Avg loss: 0.0033383889724548986!\n",
      "Avg loss: 0.003431029869533783!\n",
      "Avg loss: 0.003323828927204886!\n",
      "Avg loss: 0.0033956297201530104!\n",
      "Avg loss: 0.003435232652003227!\n",
      "Avg loss: 0.0033045094799914903!\n",
      "Avg loss: 0.0033380256328503794!\n",
      "Avg loss: 0.0032913602900589466!\n",
      "Avg loss: 0.003296629244559881!\n",
      "Avg loss: 0.0033729006126183474!\n",
      "Avg loss: 0.003300112010374505!\n",
      "Avg loss: 0.00331195282640086!\n",
      "Avg loss: 0.0032468565011852966!\n",
      "Avg loss: 0.0032484823478929076!\n",
      "Avg loss: 0.003262177496083799!\n",
      "Avg loss: 0.003233420319203712!\n",
      "Avg loss: 0.003259149073201115!\n",
      "Avg loss: 0.0031978970623458736!\n",
      "Avg loss: 0.0032253803897522933!\n",
      "Avg loss: 0.003202950130113701!\n",
      "Avg loss: 0.0032747696241858647!\n",
      "Avg loss: 0.0031761495809284196!\n",
      "Avg loss: 0.0032084108684163463!\n",
      "Avg loss: 0.0031850495994876836!\n",
      "Avg loss: 0.003231003116767776!\n",
      "Avg loss: 0.0032173122386908895!\n",
      "Avg loss: 0.0031558399994658735!\n",
      "Avg loss: 0.00316411823919528!\n",
      "Avg loss: 0.0031340976725671983!\n",
      "Avg loss: 0.003213364017525843!\n",
      "Avg loss: 0.003115765532147634!\n",
      "Avg loss: 0.0031619776133447884!\n",
      "Avg loss: 0.003105566129424915!\n",
      "Avg loss: 0.0032130682492788765!\n",
      "Avg loss: 0.0030947961656784175!\n",
      "Avg loss: 0.003188298211195312!\n",
      "Avg loss: 0.0030892704725192744!\n",
      "Avg loss: 0.0031440466811000077!\n",
      "Avg loss: 0.0030946570666856134!\n",
      "Avg loss: 0.0032013810288966243!\n",
      "Avg loss: 0.0030913418390021738!\n",
      "Avg loss: 0.0031291470922587905!\n",
      "Avg loss: 0.0030719904206246915!\n",
      "Avg loss: 0.003108170401562044!\n",
      "Avg loss: 0.003063878503089654!\n",
      "Avg loss: 0.0031392134960151453!\n",
      "Avg loss: 0.0030729347653565735!\n",
      "Avg loss: 0.0031657191637229215!\n",
      "Avg loss: 0.003038471838044643!\n",
      "Avg loss: 0.0031178530078068436!\n",
      "Avg loss: 0.0030538789776983323!\n",
      "Avg loss: 0.003157652837678976!\n",
      "Avg loss: 0.0030518924583157058!\n",
      "Avg loss: 0.003101934145024643!\n",
      "Avg loss: 0.0030131907358615234!\n",
      "Avg loss: 0.003189926915365504!\n",
      "Avg loss: 0.003086360666620749!\n",
      "Avg loss: 0.003278232914835826!\n",
      "Avg loss: 0.003087782113616413!\n",
      "Avg loss: 0.003275280877954477!\n",
      "Avg loss: 0.00315209728472837!\n",
      "Avg loss: 0.0034858552143365766!\n",
      "Avg loss: 0.0033284914282679288!\n",
      "Avg loss: 0.0036374349468921235!\n",
      "Avg loss: 0.0034170966972912236!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.13248339940172932!\n",
      "Avg loss: 0.12273473342395542!\n",
      "Avg loss: 0.130881831307197!\n",
      "Avg loss: 0.12283224915336177!\n",
      "Avg loss: 0.12534268962452189!\n",
      "Avg loss: 0.12370945930973297!\n",
      "Avg loss: 0.1245600630149905!\n",
      "Avg loss: 0.1225894783329871!\n",
      "Avg loss: 0.12238297581643565!\n",
      "Avg loss: 0.12246182731132042!\n",
      "Avg loss: 0.12191230645542722!\n",
      "Avg loss: 0.12140489305901914!\n",
      "Avg loss: 0.12121187231276963!\n",
      "Avg loss: 0.12157785879377722!\n",
      "Avg loss: 0.12101160596161814!\n",
      "Avg loss: 0.12103266559627324!\n",
      "Avg loss: 0.1210413450881318!\n",
      "Avg loss: 0.12084420533306911!\n",
      "Avg loss: 0.12063761351785009!\n",
      "Avg loss: 0.1206869681536591!\n",
      "Avg loss: 0.1205734313417391!\n",
      "Avg loss: 0.12044839187559622!\n",
      "Avg loss: 0.12037142271441856!\n",
      "Avg loss: 0.12023771449609133!\n",
      "Avg loss: 0.12007604436986184!\n",
      "Avg loss: 0.11996368470742103!\n",
      "Avg loss: 0.1198632350664396!\n",
      "Avg loss: 0.11969169341591321!\n",
      "Avg loss: 0.11968802134392717!\n",
      "Avg loss: 0.1196008228674115!\n",
      "Avg loss: 0.11954760859080883!\n",
      "Avg loss: 0.1194771344529848!\n",
      "Avg loss: 0.11930858345756103!\n",
      "Avg loss: 0.11920879554223877!\n",
      "Avg loss: 0.11898954152868403!\n",
      "Avg loss: 0.11896453794182131!\n",
      "Avg loss: 0.11874848175886958!\n",
      "Avg loss: 0.11874260909468225!\n",
      "Avg loss: 0.11858519838224008!\n",
      "Avg loss: 0.1186270460094147!\n",
      "Avg loss: 0.11837493958501455!\n",
      "Avg loss: 0.11825138619512472!\n",
      "Avg loss: 0.11819185163159394!\n",
      "Avg loss: 0.11824693574735193!\n",
      "Avg loss: 0.11830211068665146!\n",
      "Avg loss: 0.11811918202879193!\n",
      "Avg loss: 0.11788309515360955!\n",
      "Avg loss: 0.11780386530848545!\n",
      "Avg loss: 0.11799512199121258!\n",
      "Avg loss: 0.11781324996512012!\n",
      "Avg loss: 0.11784133362578814!\n",
      "Avg loss: 0.11755908640187347!\n",
      "Avg loss: 0.11774150273938176!\n",
      "Avg loss: 0.11757328859047447!\n",
      "Avg loss: 0.11750578896985038!\n",
      "Avg loss: 0.11738179746784681!\n",
      "Avg loss: 0.11737324416990001!\n",
      "Avg loss: 0.11745235100792493!\n",
      "Avg loss: 0.11738782956368292!\n",
      "Avg loss: 0.11730150814413719!\n",
      "Avg loss: 0.11722763901779369!\n",
      "Avg loss: 0.11724366429145902!\n",
      "Avg loss: 0.11744540352555305!\n",
      "Avg loss: 0.11730686948070039!\n",
      "Avg loss: 0.11716717056649562!\n",
      "Avg loss: 0.11708723250437288!\n",
      "Avg loss: 0.11699124054147585!\n",
      "Avg loss: 0.11704391731631811!\n",
      "Avg loss: 0.11721434574681097!\n",
      "Avg loss: 0.11717999500182032!\n",
      "Avg loss: 0.11698024331501794!\n",
      "Avg loss: 0.11692832690485526!\n",
      "Avg loss: 0.11717037901550308!\n",
      "Avg loss: 0.11709459115057598!\n",
      "Avg loss: 0.11674766013739372!\n",
      "Avg loss: 0.11679424263948628!\n",
      "Avg loss: 0.11688797202539718!\n",
      "Avg loss: 0.11685836393604025!\n",
      "Avg loss: 0.11680014687951826!\n",
      "Avg loss: 0.11678526333998888!\n",
      "Avg loss: 0.11693535925775601!\n",
      "Avg loss: 0.1168166511436751!\n",
      "Avg loss: 0.11681677608708772!\n",
      "Avg loss: 0.11663492920602646!\n",
      "Avg loss: 0.11686674091046674!\n",
      "Avg loss: 0.11697329508900718!\n",
      "Avg loss: 0.11693382955039246!\n",
      "Avg loss: 0.11724054969929057!\n",
      "Avg loss: 0.11673242780443692!\n",
      "Avg loss: 0.11670089219968607!\n",
      "Avg loss: 0.11674992846562418!\n",
      "Avg loss: 0.11670953101457296!\n",
      "Avg loss: 0.11680709844205012!\n",
      "Avg loss: 0.11677046969686065!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.019018351160145053!\n",
      "Avg loss: 0.00797478383872658!\n",
      "Avg loss: 0.008698757612534488!\n",
      "Avg loss: 0.00577135563265377!\n",
      "Avg loss: 0.00759795867697297!\n",
      "Avg loss: 0.003936034477786355!\n",
      "Avg loss: 0.00596406288081198!\n",
      "Avg loss: 0.003602930799497699!\n",
      "Avg loss: 0.004094196288303161!\n",
      "Avg loss: 0.0033982705568178064!\n",
      "Avg loss: 0.0031543572330944396!\n",
      "Avg loss: 0.0030986899453985944!\n",
      "Avg loss: 0.003138855328137045!\n",
      "Avg loss: 0.0030598935320449525!\n",
      "Avg loss: 0.003134357822321666!\n",
      "Avg loss: 0.0030936319914205038!\n",
      "Avg loss: 0.0028281935641340777!\n",
      "Avg loss: 0.0027287895012523223!\n",
      "Avg loss: 0.002637371507444186!\n",
      "Avg loss: 0.0026760933958879228!\n",
      "Avg loss: 0.0027093605561731237!\n",
      "Avg loss: 0.002804291076229977!\n",
      "Avg loss: 0.0027999526846239557!\n",
      "Avg loss: 0.002750675108679085!\n",
      "Avg loss: 0.0026797832208558248!\n",
      "Avg loss: 0.002614716626627948!\n",
      "Avg loss: 0.0026315655923705586!\n",
      "Avg loss: 0.002663560020446312!\n",
      "Avg loss: 0.0027060311009548363!\n",
      "Avg loss: 0.0026546656302101233!\n",
      "Avg loss: 0.002633176900963008!\n",
      "Avg loss: 0.002701051944750361!\n",
      "Avg loss: 0.0025957685850638277!\n",
      "Avg loss: 0.0025829728392879284!\n",
      "Avg loss: 0.002653550050890772!\n",
      "Avg loss: 0.0026460798091526763!\n",
      "Avg loss: 0.0027043069799037767!\n",
      "Avg loss: 0.002579010384694508!\n",
      "Avg loss: 0.0026449610293821026!\n",
      "Avg loss: 0.0025945062711374097!\n",
      "Avg loss: 0.0026992513882760248!\n",
      "Avg loss: 0.0026525638955596756!\n",
      "Avg loss: 0.0026872821569365137!\n",
      "Avg loss: 0.002635062422662789!\n",
      "Avg loss: 0.0027307982997323657!\n",
      "Avg loss: 0.0026987320868132277!\n",
      "Avg loss: 0.002753980367148567!\n",
      "Avg loss: 0.0026840852449943973!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -608     |\n",
      "| time/              |          |\n",
      "|    fps             | 320      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -746     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 307      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 13       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.968    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00719  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 56       |\n",
      "|    policy_objective       | 0.0135   |\n",
      "|    std                    | 0.725    |\n",
      "|    value_loss             | 582      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -740     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 301      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 20       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.987    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00639  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 57       |\n",
      "|    policy_objective       | 0.00919  |\n",
      "|    std                    | 0.745    |\n",
      "|    value_loss             | 631      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -756     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 295      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 27       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.964    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00659  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 58       |\n",
      "|    policy_objective       | 0.00847  |\n",
      "|    std                    | 0.707    |\n",
      "|    value_loss             | 533      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -749     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 295      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 34       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.981    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00769  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 59       |\n",
      "|    policy_objective       | 0.0135   |\n",
      "|    std                    | 0.697    |\n",
      "|    value_loss             | 575      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1402.9932578086853\n",
      "------------------------------\n",
      "round: 12\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.0648746537330832!\n",
      "Avg loss: 0.0631939740209297!\n",
      "Avg loss: 0.0655956640924948!\n",
      "Avg loss: 0.059197429323818745!\n",
      "Avg loss: 0.06030452398562678!\n",
      "Avg loss: 0.0580147794875423!\n",
      "Avg loss: 0.0592844162789576!\n",
      "Avg loss: 0.05894231338925844!\n",
      "Avg loss: 0.058320341721887416!\n",
      "Avg loss: 0.05865228130555503!\n",
      "Avg loss: 0.05784940881704339!\n",
      "Avg loss: 0.057939744836379155!\n",
      "Avg loss: 0.057912882989773304!\n",
      "Avg loss: 0.05771728691252065!\n",
      "Avg loss: 0.057932127849596025!\n",
      "Avg loss: 0.05781412240876913!\n",
      "Avg loss: 0.05759967847802424!\n",
      "Avg loss: 0.057778706801518635!\n",
      "Avg loss: 0.057696492049690275!\n",
      "Avg loss: 0.057658540364415485!\n",
      "Avg loss: 0.057739667223771295!\n",
      "Avg loss: 0.057717457820993634!\n",
      "Avg loss: 0.05772858351389004!\n",
      "Avg loss: 0.05766986650859811!\n",
      "Avg loss: 0.05774346883527566!\n",
      "Avg loss: 0.057765926151411504!\n",
      "Avg loss: 0.057679107195532806!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.01829481727637661!\n",
      "Avg loss: 0.01535992482114428!\n",
      "Avg loss: 0.019370491234622023!\n",
      "Avg loss: 0.0147273323078601!\n",
      "Avg loss: 0.014315841336768548!\n",
      "Avg loss: 0.014671962501573337!\n",
      "Avg loss: 0.014258102857517467!\n",
      "Avg loss: 0.013982077481535574!\n",
      "Avg loss: 0.013428090694378624!\n",
      "Avg loss: 0.014053875057882881!\n",
      "Avg loss: 0.0132138612228664!\n",
      "Avg loss: 0.013040687391288278!\n",
      "Avg loss: 0.013334757598552944!\n",
      "Avg loss: 0.012910897755832594!\n",
      "Avg loss: 0.012963292328213355!\n",
      "Avg loss: 0.013094537199725285!\n",
      "Avg loss: 0.012946741336339376!\n",
      "Avg loss: 0.012915216179826529!\n",
      "Avg loss: 0.013012954668198896!\n",
      "Avg loss: 0.012890483199072756!\n",
      "Avg loss: 0.012875973542462968!\n",
      "Avg loss: 0.012981164660770143!\n",
      "Avg loss: 0.012937896547118726!\n",
      "Avg loss: 0.012934405363979143!\n",
      "Avg loss: 0.01293600738823443!\n",
      "Avg loss: 0.01287417193810749!\n",
      "Avg loss: 0.012919066643438176!\n",
      "Avg loss: 0.012950741126336046!\n",
      "Avg loss: 0.01295941887487364!\n",
      "Avg loss: 0.01298427927551226!\n",
      "Avg loss: 0.012973030911768242!\n",
      "Avg loss: 0.012914785290880294!\n",
      "Avg loss: 0.01293915805851005!\n",
      "Avg loss: 0.01295779576896166!\n",
      "Avg loss: 0.013018717981606946!\n",
      "Avg loss: 0.01300771132879163!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.007584278730500955!\n",
      "Avg loss: 0.005496495798421771!\n",
      "Avg loss: 0.01563411468108825!\n",
      "Avg loss: 0.0061559052286490135!\n",
      "Avg loss: 0.005472700967317602!\n",
      "Avg loss: 0.007954433231500389!\n",
      "Avg loss: 0.007110112084895566!\n",
      "Avg loss: 0.004502171644395882!\n",
      "Avg loss: 0.005451981923391335!\n",
      "Avg loss: 0.00655943723929037!\n",
      "Avg loss: 0.0051531056082482485!\n",
      "Avg loss: 0.004949213971194695!\n",
      "Avg loss: 0.0052949075414411104!\n",
      "Avg loss: 0.005155664719334254!\n",
      "Avg loss: 0.004613541820563114!\n",
      "Avg loss: 0.004966847220396933!\n",
      "Avg loss: 0.005399330333852958!\n",
      "Avg loss: 0.004721192006509227!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -756     |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -660     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 284      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 14       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.974    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00624  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 61       |\n",
      "|    policy_objective       | 0.0225   |\n",
      "|    std                    | 0.666    |\n",
      "|    value_loss             | 707      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -756     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 286      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 21       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.97     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00712  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 62       |\n",
      "|    policy_objective       | 0.0159   |\n",
      "|    std                    | 0.669    |\n",
      "|    value_loss             | 644      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -778     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 289      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 28       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.943    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00738  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 63       |\n",
      "|    policy_objective       | 0.0157   |\n",
      "|    std                    | 0.653    |\n",
      "|    value_loss             | 1.46e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -769     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 292      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 35       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.973    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00621  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 64       |\n",
      "|    policy_objective       | 0.0148   |\n",
      "|    std                    | 0.674    |\n",
      "|    value_loss             | 859      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1381.551516917348\n",
      "------------------------------\n",
      "round: 13\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.05849166077537423!\n",
      "Avg loss: 0.057196397103446844!\n",
      "Avg loss: 0.05373598200860821!\n",
      "Avg loss: 0.048740771632683394!\n",
      "Avg loss: 0.05392667478105674!\n",
      "Avg loss: 0.04873376611848168!\n",
      "Avg loss: 0.048296966812431494!\n",
      "Avg loss: 0.04763761951723912!\n",
      "Avg loss: 0.0501176754036472!\n",
      "Avg loss: 0.047606206132246975!\n",
      "Avg loss: 0.04753061716128135!\n",
      "Avg loss: 0.04787568650378186!\n",
      "Avg loss: 0.04805768969410565!\n",
      "Avg loss: 0.04693785611578278!\n",
      "Avg loss: 0.047019567830793675!\n",
      "Avg loss: 0.04727262410471061!\n",
      "Avg loss: 0.046852722990170154!\n",
      "Avg loss: 0.046764770279763376!\n",
      "Avg loss: 0.046961327274748325!\n",
      "Avg loss: 0.04692743167419091!\n",
      "Avg loss: 0.04684390900988243!\n",
      "Avg loss: 0.046887140797462055!\n",
      "Avg loss: 0.046820990781749665!\n",
      "Avg loss: 0.046856461666338875!\n",
      "Avg loss: 0.046829098154897414!\n",
      "Avg loss: 0.046819305155765205!\n",
      "Avg loss: 0.046824751589975525!\n",
      "Avg loss: 0.04680474464623027!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.025673860182869247!\n",
      "Avg loss: 0.020659893777337856!\n",
      "Avg loss: 0.014643450468720403!\n",
      "Avg loss: 0.0077942706533940505!\n",
      "Avg loss: 0.018933027074090204!\n",
      "Avg loss: 0.0073491043502872345!\n",
      "Avg loss: 0.007197622563059364!\n",
      "Avg loss: 0.007289339522685623!\n",
      "Avg loss: 0.009306534121157407!\n",
      "Avg loss: 0.005056946992663142!\n",
      "Avg loss: 0.0051396797441551215!\n",
      "Avg loss: 0.007925159442044484!\n",
      "Avg loss: 0.005650621827741512!\n",
      "Avg loss: 0.0050963864564982945!\n",
      "Avg loss: 0.006558822038059588!\n",
      "Avg loss: 0.005641618237059447!\n",
      "Avg loss: 0.005037466182384378!\n",
      "Avg loss: 0.006127363682292828!\n",
      "Avg loss: 0.005816236818523066!\n",
      "Avg loss: 0.005398170888408155!\n",
      "Avg loss: 0.006061540224548783!\n",
      "Avg loss: 0.005610522043097413!\n",
      "Avg loss: 0.005341302913833109!\n",
      "Avg loss: 0.005857284623725718!\n",
      "Avg loss: 0.005506276043148925!\n",
      "Avg loss: 0.005641237987301793!\n",
      "Avg loss: 0.005801135777710442!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.05769566384376958!\n",
      "Avg loss: 0.052713319973596906!\n",
      "Avg loss: 0.05406945993929791!\n",
      "Avg loss: 0.05049601988825695!\n",
      "Avg loss: 0.05182264043822215!\n",
      "Avg loss: 0.04975969805436459!\n",
      "Avg loss: 0.05157772294706471!\n",
      "Avg loss: 0.050789390423189314!\n",
      "Avg loss: 0.05101746016303878!\n",
      "Avg loss: 0.05050116892775501!\n",
      "Avg loss: 0.050462308146306895!\n",
      "Avg loss: 0.05008949900562129!\n",
      "Avg loss: 0.04988671448722622!\n",
      "Avg loss: 0.04986443173906082!\n",
      "Avg loss: 0.050044248559983844!\n",
      "Avg loss: 0.05007489014572457!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -750     |\n",
      "| time/              |          |\n",
      "|    fps             | 308      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -883     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 301      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 13       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.977    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00726  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 66       |\n",
      "|    policy_objective       | 0.0348   |\n",
      "|    std                    | 0.705    |\n",
      "|    value_loss             | 770      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -755     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 298      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 20       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.979    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00619  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 67       |\n",
      "|    policy_objective       | 0.0188   |\n",
      "|    std                    | 0.719    |\n",
      "|    value_loss             | 484      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -808     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 295      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 27       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.953    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0087   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 68       |\n",
      "|    policy_objective       | 0.00984  |\n",
      "|    std                    | 0.69     |\n",
      "|    value_loss             | 1.54e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -820     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 291      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 35       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.964    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00785  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 69       |\n",
      "|    policy_objective       | 0.0119   |\n",
      "|    std                    | 0.717    |\n",
      "|    value_loss             | 863      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1184.736337767518\n",
      "------------------------------\n",
      "round: 14\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.0086550141795063!\n",
      "Avg loss: 0.004778117137369311!\n",
      "Avg loss: 0.01189879426228193!\n",
      "Avg loss: 0.004424552725383061!\n",
      "Avg loss: 0.0047322452224883215!\n",
      "Avg loss: 0.005890454384534678!\n",
      "Avg loss: 0.006371970304959783!\n",
      "Avg loss: 0.004078530055403462!\n",
      "Avg loss: 0.0039644962339237585!\n",
      "Avg loss: 0.005346670726379064!\n",
      "Avg loss: 0.004405311242621035!\n",
      "Avg loss: 0.003880023371836311!\n",
      "Avg loss: 0.004612385245903473!\n",
      "Avg loss: 0.004819800531407357!\n",
      "Avg loss: 0.004326304439794816!\n",
      "Avg loss: 0.0047420550790654185!\n",
      "Avg loss: 0.004895285439100311!\n",
      "Avg loss: 0.004534711804553808!\n",
      "Avg loss: 0.004775775478762323!\n",
      "Avg loss: 0.005034876788813563!\n",
      "Avg loss: 0.0046923002920205665!\n",
      "Avg loss: 0.004866003801980696!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.010526819705070618!\n",
      "Avg loss: 0.005231901722048254!\n",
      "Avg loss: 0.014555545222247019!\n",
      "Avg loss: 0.0046339725904059985!\n",
      "Avg loss: 0.005881020510811747!\n",
      "Avg loss: 0.0056861744665123596!\n",
      "Avg loss: 0.007340106388170777!\n",
      "Avg loss: 0.004013966795658537!\n",
      "Avg loss: 0.003972937886525567!\n",
      "Avg loss: 0.0057181910244374495!\n",
      "Avg loss: 0.004783134221603784!\n",
      "Avg loss: 0.0036695671672471995!\n",
      "Avg loss: 0.004269866635161937!\n",
      "Avg loss: 0.0050628077121412695!\n",
      "Avg loss: 0.003992983347755701!\n",
      "Avg loss: 0.003973175409228134!\n",
      "Avg loss: 0.004793931017181118!\n",
      "Avg loss: 0.004325547767627238!\n",
      "Avg loss: 0.004063407111195071!\n",
      "Avg loss: 0.004520502785368687!\n",
      "Avg loss: 0.004515209793171379!\n",
      "Avg loss: 0.004183524494001176!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.026124251543466624!\n",
      "Avg loss: 0.008831011724250857!\n",
      "Avg loss: 0.006942801033146679!\n",
      "Avg loss: 0.01106486913204814!\n",
      "Avg loss: 0.006163912941253027!\n",
      "Avg loss: 0.006221317521800908!\n",
      "Avg loss: 0.005908457526941978!\n",
      "Avg loss: 0.006179751872065632!\n",
      "Avg loss: 0.004352210772315933!\n",
      "Avg loss: 0.006106736054540912!\n",
      "Avg loss: 0.006020060199534783!\n",
      "Avg loss: 0.004783854861865014!\n",
      "Avg loss: 0.004934197462486433!\n",
      "Avg loss: 0.005981316955245954!\n",
      "Avg loss: 0.005227863900733307!\n",
      "Avg loss: 0.005158707318805682!\n",
      "Avg loss: 0.005554519110398057!\n",
      "Avg loss: 0.005367245324796386!\n",
      "Avg loss: 0.005203733757389273!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -828     |\n",
      "| time/              |          |\n",
      "|    fps             | 304      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -754     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 298      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 13       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.968    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00585  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 71       |\n",
      "|    policy_objective       | 0.021    |\n",
      "|    std                    | 0.727    |\n",
      "|    value_loss             | 950      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -636     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 288      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 21       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.973    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00816  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 72       |\n",
      "|    policy_objective       | 0.0135   |\n",
      "|    std                    | 0.712    |\n",
      "|    value_loss             | 1.25e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -715     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 281      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 29       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.966    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00584  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 73       |\n",
      "|    policy_objective       | 0.0162   |\n",
      "|    std                    | 0.715    |\n",
      "|    value_loss             | 1.33e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -686     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 281      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 36       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.968    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0095   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 74       |\n",
      "|    policy_objective       | 0.0137   |\n",
      "|    std                    | 0.724    |\n",
      "|    value_loss             | 874      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1396.0738600399345\n",
      "------------------------------\n",
      "round: 15\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.09232471047334305!\n",
      "Avg loss: 0.08190610966926518!\n",
      "Avg loss: 0.08831865138170542!\n",
      "Avg loss: 0.08202504361874162!\n",
      "Avg loss: 0.0817361601100735!\n",
      "Avg loss: 0.08298590336761359!\n",
      "Avg loss: 0.08166148589853643!\n",
      "Avg loss: 0.08132777576120134!\n",
      "Avg loss: 0.0817868100609879!\n",
      "Avg loss: 0.08174510672231311!\n",
      "Avg loss: 0.08049420920995848!\n",
      "Avg loss: 0.080739194855596!\n",
      "Avg loss: 0.0806998946030338!\n",
      "Avg loss: 0.08056816647605046!\n",
      "Avg loss: 0.08044366155323587!\n",
      "Avg loss: 0.08083255292217775!\n",
      "Avg loss: 0.08077301486965553!\n",
      "Avg loss: 0.08051388350873215!\n",
      "Avg loss: 0.0808593365918917!\n",
      "Avg loss: 0.08069835967537681!\n",
      "Avg loss: 0.08051186646976931!\n",
      "Avg loss: 0.08086220967949885!\n",
      "Avg loss: 0.08070789151242631!\n",
      "Avg loss: 0.08066165127697483!\n",
      "Avg loss: 0.08087656862867637!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.013845885530730205!\n",
      "Avg loss: 0.007919162098755806!\n",
      "Avg loss: 0.015034345430661537!\n",
      "Avg loss: 0.007196248190860691!\n",
      "Avg loss: 0.012050351305272973!\n",
      "Avg loss: 0.008081397134125534!\n",
      "Avg loss: 0.010114717368718024!\n",
      "Avg loss: 0.007558089160738746!\n",
      "Avg loss: 0.008410390730120221!\n",
      "Avg loss: 0.007365880551730394!\n",
      "Avg loss: 0.007349363855795066!\n",
      "Avg loss: 0.0072021523242680515!\n",
      "Avg loss: 0.0072513882192894626!\n",
      "Avg loss: 0.0072900318597673205!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.16290676744649923!\n",
      "Avg loss: 0.16235889843023565!\n",
      "Avg loss: 0.18075327628263038!\n",
      "Avg loss: 0.1625808521254415!\n",
      "Avg loss: 0.1622038120230718!\n",
      "Avg loss: 0.16990155709114332!\n",
      "Avg loss: 0.16541367776702828!\n",
      "Avg loss: 0.15978304824141862!\n",
      "Avg loss: 0.16298496363872422!\n",
      "Avg loss: 0.16487612244008537!\n",
      "Avg loss: 0.16027195663855914!\n",
      "Avg loss: 0.16187493006257378!\n",
      "Avg loss: 0.1641825672091909!\n",
      "Avg loss: 0.16096958077492673!\n",
      "Avg loss: 0.1617963103936078!\n",
      "Avg loss: 0.16301129886032262!\n",
      "Avg loss: 0.16094242110722917!\n",
      "Avg loss: 0.16192725893297544!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -503     |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -632     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 297      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 13       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.973    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00656  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 76       |\n",
      "|    policy_objective       | 0.0212   |\n",
      "|    std                    | 0.697    |\n",
      "|    value_loss             | 755      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -627     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 288      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 21       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.983    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00711  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 77       |\n",
      "|    policy_objective       | 0.0229   |\n",
      "|    std                    | 0.72     |\n",
      "|    value_loss             | 672      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -649     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 284      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 28       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.97     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00593  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 78       |\n",
      "|    policy_objective       | 0.015    |\n",
      "|    std                    | 0.721    |\n",
      "|    value_loss             | 1.59e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -656     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 281      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 36       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.972    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00588  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 79       |\n",
      "|    policy_objective       | 0.0145   |\n",
      "|    std                    | 0.749    |\n",
      "|    value_loss             | 1.17e+03 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1435.708136241883\n",
      "------------------------------\n",
      "round: 16\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.10340063232850905!\n",
      "Avg loss: 0.09040288366969132!\n",
      "Avg loss: 0.1004472711798735!\n",
      "Avg loss: 0.08930260187960812!\n",
      "Avg loss: 0.0926477916300064!\n",
      "Avg loss: 0.091935349679358!\n",
      "Avg loss: 0.09106403769677854!\n",
      "Avg loss: 0.09078576660297889!\n",
      "Avg loss: 0.08945911693761445!\n",
      "Avg loss: 0.0912635271633432!\n",
      "Avg loss: 0.08958000380623465!\n",
      "Avg loss: 0.08976226504249402!\n",
      "Avg loss: 0.08994692117616068!\n",
      "Avg loss: 0.08965418339711807!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.06094935581471266!\n",
      "Avg loss: 0.05872181144603625!\n",
      "Avg loss: 0.06448706201850049!\n",
      "Avg loss: 0.05908751929273422!\n",
      "Avg loss: 0.058893697321567136!\n",
      "Avg loss: 0.06010041950930221!\n",
      "Avg loss: 0.0582238680894443!\n",
      "Avg loss: 0.058089634048240746!\n",
      "Avg loss: 0.05829135924727931!\n",
      "Avg loss: 0.0587746666621509!\n",
      "Avg loss: 0.0581351610320174!\n",
      "Avg loss: 0.05793956204938392!\n",
      "Avg loss: 0.058201787326452176!\n",
      "Avg loss: 0.05756658920809059!\n",
      "Avg loss: 0.05755821066314335!\n",
      "Avg loss: 0.05777974565929678!\n",
      "Avg loss: 0.057387550087350976!\n",
      "Avg loss: 0.057268047100042165!\n",
      "Avg loss: 0.057234907895929915!\n",
      "Avg loss: 0.05687323144185636!\n",
      "Avg loss: 0.056853091510121585!\n",
      "Avg loss: 0.05694499096620954!\n",
      "Avg loss: 0.05686673857585447!\n",
      "Avg loss: 0.05696420714272487!\n",
      "Avg loss: 0.05687865545187378!\n",
      "Avg loss: 0.05682019485919227!\n",
      "Avg loss: 0.05682184523186152!\n",
      "Avg loss: 0.05685214629469556!\n",
      "Avg loss: 0.056885515782738975!\n",
      "Avg loss: 0.05698869324120703!\n",
      "Avg loss: 0.05684980854713104!\n",
      "Avg loss: 0.05699046616400059!\n",
      "Avg loss: 0.056888323339286825!\n",
      "Avg loss: 0.05708067830019597!\n",
      "Avg loss: 0.05696683489365265!\n",
      "Avg loss: 0.057124200878497504!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.1309502078059207!\n",
      "Avg loss: 0.12486457773367875!\n",
      "Avg loss: 0.12319549894435719!\n",
      "Avg loss: 0.12276803772489074!\n",
      "Avg loss: 0.12054794413641502!\n",
      "Avg loss: 0.12147601056596613!\n",
      "Avg loss: 0.1187099844799377!\n",
      "Avg loss: 0.11938178783282638!\n",
      "Avg loss: 0.11896659227447041!\n",
      "Avg loss: 0.11924156958614428!\n",
      "Avg loss: 0.11848712634840619!\n",
      "Avg loss: 0.11928746827366316!\n",
      "Avg loss: 0.1183081213804356!\n",
      "Avg loss: 0.11890815372736445!\n",
      "Avg loss: 0.11887984161596857!\n",
      "Avg loss: 0.11854158979699302!\n",
      "Avg loss: 0.11879440654235926!\n",
      "Avg loss: 0.11866984297573253!\n",
      "Avg loss: 0.11847789467766537!\n",
      "Avg loss: 0.11863246743676427!\n",
      "Avg loss: 0.11857900942672737!\n",
      "Avg loss: 0.11859869400531049!\n",
      "Avg loss: 0.11847396659912798!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -799     |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -895     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 296      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 13       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.98     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0051   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 81       |\n",
      "|    policy_objective       | 0.014    |\n",
      "|    std                    | 0.724    |\n",
      "|    value_loss             | 941      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -960     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 295      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 20       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.965    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00664  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 82       |\n",
      "|    policy_objective       | 0.0151   |\n",
      "|    std                    | 0.726    |\n",
      "|    value_loss             | 627      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -904     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 293      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 27       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.992    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00983  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 83       |\n",
      "|    policy_objective       | 0.013    |\n",
      "|    std                    | 0.721    |\n",
      "|    value_loss             | 168      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -892     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 293      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 34       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.969    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00836  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 84       |\n",
      "|    policy_objective       | 0.013    |\n",
      "|    std                    | 0.724    |\n",
      "|    value_loss             | 752      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1282.1241118505598\n",
      "------------------------------\n",
      "round: 17\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.0355632846209725!\n",
      "Avg loss: 0.03472110572474776!\n",
      "Avg loss: 0.035307567249219574!\n",
      "Avg loss: 0.031837848935247166!\n",
      "Avg loss: 0.031519099469539166!\n",
      "Avg loss: 0.029341277041579208!\n",
      "Avg loss: 0.03172578774608458!\n",
      "Avg loss: 0.03015101184727731!\n",
      "Avg loss: 0.030244567923617374!\n",
      "Avg loss: 0.029777530567589566!\n",
      "Avg loss: 0.03054171104225437!\n",
      "Avg loss: 0.029737197523687656!\n",
      "Avg loss: 0.029647021994848425!\n",
      "Avg loss: 0.029875871705245347!\n",
      "Avg loss: 0.029920362829422325!\n",
      "Avg loss: 0.029620216961105447!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.06994225600879872!\n",
      "Avg loss: 0.06673377875975954!\n",
      "Avg loss: 0.0668404926545918!\n",
      "Avg loss: 0.06608796416318606!\n",
      "Avg loss: 0.06514617825319874!\n",
      "Avg loss: 0.06439773751148702!\n",
      "Avg loss: 0.06470239194629054!\n",
      "Avg loss: 0.06450946777821324!\n",
      "Avg loss: 0.06427930060217477!\n",
      "Avg loss: 0.06427534080406379!\n",
      "Avg loss: 0.06503257873916785!\n",
      "Avg loss: 0.06457106425062799!\n",
      "Avg loss: 0.06446031422868449!\n",
      "Avg loss: 0.0644720500797636!\n",
      "Avg loss: 0.06471661939729983!\n",
      "Avg loss: 0.06457946640894685!\n",
      "Avg loss: 0.06472880851525285!\n",
      "Avg loss: 0.06482032158977442!\n",
      "Avg loss: 0.06496964942436231!\n",
      "Avg loss: 0.06495820077360501!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.013537266202814256!\n",
      "Avg loss: 0.0056292269461603915!\n",
      "Avg loss: 0.009935074274156554!\n",
      "Avg loss: 0.0054257148946150364!\n",
      "Avg loss: 0.007949817566962641!\n",
      "Avg loss: 0.004017359567127035!\n",
      "Avg loss: 0.004528988257031112!\n",
      "Avg loss: 0.004495575856350721!\n",
      "Avg loss: 0.004088321072304097!\n",
      "Avg loss: 0.0036370038026264716!\n",
      "Avg loss: 0.00402461692750876!\n",
      "Avg loss: 0.004102882013175986!\n",
      "Avg loss: 0.003738448685574743!\n",
      "Avg loss: 0.003975400110075498!\n",
      "Avg loss: 0.00361206108130015!\n",
      "Avg loss: 0.0036231421036548757!\n",
      "Avg loss: 0.003579811925269496!\n",
      "Avg loss: 0.0035062077811441367!\n",
      "Avg loss: 0.0036041120540297317!\n",
      "Avg loss: 0.003598265984525521!\n",
      "Avg loss: 0.003534123372276857!\n",
      "Avg loss: 0.003558545708001475!\n",
      "Avg loss: 0.003530051832864653!\n",
      "Avg loss: 0.0034979957757195735!\n",
      "Avg loss: 0.0035715421613834526!\n",
      "Avg loss: 0.0035607895088681594!\n",
      "Avg loss: 0.003533887243738718!\n",
      "Avg loss: 0.003544332671664658!\n",
      "Avg loss: 0.0035200651024767165!\n",
      "Avg loss: 0.003561016697525095!\n",
      "Avg loss: 0.003592849055195681!\n",
      "Avg loss: 0.003567594654241475!\n",
      "Avg loss: 0.0035668114857336755!\n",
      "Avg loss: 0.0035960139030839855!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -891     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -852     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 299      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 13       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.987    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00679  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 86       |\n",
      "|    policy_objective       | 0.0196   |\n",
      "|    std                    | 0.722    |\n",
      "|    value_loss             | 410      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -754     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 303      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 20       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.975    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00565  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 87       |\n",
      "|    policy_objective       | 0.0103   |\n",
      "|    std                    | 0.702    |\n",
      "|    value_loss             | 1.05e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -800     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 298      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 27       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.982    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00669  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 88       |\n",
      "|    policy_objective       | 0.00533  |\n",
      "|    std                    | 0.674    |\n",
      "|    value_loss             | 728      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -798     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 293      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 34       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.961    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00601  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 89       |\n",
      "|    policy_objective       | 0.0141   |\n",
      "|    std                    | 0.676    |\n",
      "|    value_loss             | 1.08e+03 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1429.7167329562828\n",
      "------------------------------\n",
      "round: 18\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.013077127665455919!\n",
      "Avg loss: 0.005242759699661595!\n",
      "Avg loss: 0.015278492182454405!\n",
      "Avg loss: 0.005391795494348723!\n",
      "Avg loss: 0.005923125767343057!\n",
      "Avg loss: 0.007087916978780413!\n",
      "Avg loss: 0.005309231218731536!\n",
      "Avg loss: 0.0038248830690281468!\n",
      "Avg loss: 0.0038256411334737094!\n",
      "Avg loss: 0.005484068637633755!\n",
      "Avg loss: 0.0036918810508116922!\n",
      "Avg loss: 0.0037936751381069675!\n",
      "Avg loss: 0.004395593447358502!\n",
      "Avg loss: 0.004169651297537105!\n",
      "Avg loss: 0.003819198028674388!\n",
      "Avg loss: 0.004016310994751014!\n",
      "Avg loss: 0.004156605175230652!\n",
      "Avg loss: 0.0035605082374725802!\n",
      "Avg loss: 0.0038738613490628872!\n",
      "Avg loss: 0.003925309287278651!\n",
      "Avg loss: 0.003697894189135695!\n",
      "Avg loss: 0.0038762960228655176!\n",
      "Avg loss: 0.0038539817065247916!\n",
      "Avg loss: 0.003935963516220606!\n",
      "Avg loss: 0.003888540291566945!\n",
      "Avg loss: 0.003872960254860421!\n",
      "Avg loss: 0.0038561974615731742!\n",
      "Avg loss: 0.003896088838653971!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.06683886259813637!\n",
      "Avg loss: 0.06876111745810097!\n",
      "Avg loss: 0.07010328151722206!\n",
      "Avg loss: 0.06571227118183742!\n",
      "Avg loss: 0.06733371405904715!\n",
      "Avg loss: 0.06498605277104313!\n",
      "Avg loss: 0.06513374475267483!\n",
      "Avg loss: 0.06460795730054088!\n",
      "Avg loss: 0.06423223314998419!\n",
      "Avg loss: 0.06462810162596724!\n",
      "Avg loss: 0.06408195644022271!\n",
      "Avg loss: 0.06411838639654889!\n",
      "Avg loss: 0.06397241141392442!\n",
      "Avg loss: 0.06375423229967661!\n",
      "Avg loss: 0.06380206522268055!\n",
      "Avg loss: 0.06363834306943318!\n",
      "Avg loss: 0.0633821596053561!\n",
      "Avg loss: 0.06320270924332969!\n",
      "Avg loss: 0.06307027926934097!\n",
      "Avg loss: 0.06310419748426284!\n",
      "Avg loss: 0.06316291701920818!\n",
      "Avg loss: 0.0630935678595597!\n",
      "Avg loss: 0.0629837951183769!\n",
      "Avg loss: 0.06293555015435534!\n",
      "Avg loss: 0.06296976115911093!\n",
      "Avg loss: 0.06298739571488719!\n",
      "Avg loss: 0.06299240512466592!\n",
      "Avg loss: 0.06298125682053675!\n",
      "Avg loss: 0.06296523979499398!\n",
      "Avg loss: 0.06296292105421647!\n",
      "Avg loss: 0.06290891350333672!\n",
      "Avg loss: 0.06283224869854773!\n",
      "Avg loss: 0.06288323366969052!\n",
      "Avg loss: 0.06284246013683817!\n",
      "Avg loss: 0.06268460461161036!\n",
      "Avg loss: 0.06257757097681255!\n",
      "Avg loss: 0.06258272911476222!\n",
      "Avg loss: 0.06258269076407487!\n",
      "Avg loss: 0.06258764983992478!\n",
      "Avg loss: 0.062458144225802245!\n",
      "Avg loss: 0.06236042424731143!\n",
      "Avg loss: 0.06238125539762071!\n",
      "Avg loss: 0.062499063107497935!\n",
      "Avg loss: 0.06244137641425368!\n",
      "Avg loss: 0.06239825663521212!\n",
      "Avg loss: 0.06243942284748149!\n",
      "Avg loss: 0.062486371675610525!\n",
      "Avg loss: 0.06257006224830709!\n",
      "Avg loss: 0.0625205852996199!\n",
      "Avg loss: 0.06239455725462562!\n",
      "Avg loss: 0.06246543934692302!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.01792816083645448!\n",
      "Avg loss: 0.013203373261494561!\n",
      "Avg loss: 0.00794114170234631!\n",
      "Avg loss: 0.009049236206531835!\n",
      "Avg loss: 0.006845113950973125!\n",
      "Avg loss: 0.0067077926251416405!\n",
      "Avg loss: 0.006957519533049587!\n",
      "Avg loss: 0.006647475669663739!\n",
      "Avg loss: 0.0055841514849150065!\n",
      "Avg loss: 0.005951973188760651!\n",
      "Avg loss: 0.005942739121843866!\n",
      "Avg loss: 0.005293961761150664!\n",
      "Avg loss: 0.005492335188428114!\n",
      "Avg loss: 0.005236337018153184!\n",
      "Avg loss: 0.005317337395705787!\n",
      "Avg loss: 0.005411243380146213!\n",
      "Avg loss: 0.005155197559652151!\n",
      "Avg loss: 0.005266786623809215!\n",
      "Avg loss: 0.0052561129827699915!\n",
      "Avg loss: 0.005232459950590662!\n",
      "Avg loss: 0.0053587268402043265!\n",
      "Avg loss: 0.005146710197645916!\n",
      "Avg loss: 0.005186998775937658!\n",
      "Avg loss: 0.00527063912870896!\n",
      "Avg loss: 0.005267586546730551!\n",
      "Avg loss: 0.005338731263054797!\n",
      "Avg loss: 0.005260455101051775!\n",
      "Avg loss: 0.005160171440626679!\n",
      "Avg loss: 0.005140789965598742!\n",
      "Avg loss: 0.005349601879136874!\n",
      "Avg loss: 0.005271815714515166!\n",
      "Avg loss: 0.005334562909759673!\n",
      "Avg loss: 0.005187543712956047!\n",
      "Avg loss: 0.005181985215946649!\n",
      "Avg loss: 0.005200155896278981!\n",
      "Avg loss: 0.005247970186904543!\n",
      "Avg loss: 0.005309023648277768!\n",
      "Avg loss: 0.005211120542326171!\n",
      "Avg loss: 0.005193912991350468!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -874     |\n",
      "| time/              |          |\n",
      "|    fps             | 287      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -821     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 287      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 14       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.986    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.0051   |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 91       |\n",
      "|    policy_objective       | 0.0141   |\n",
      "|    std                    | 0.657    |\n",
      "|    value_loss             | 753      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -825     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 290      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 21       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.961    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00668  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 92       |\n",
      "|    policy_objective       | 0.0193   |\n",
      "|    std                    | 0.657    |\n",
      "|    value_loss             | 1.76e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -870     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 284      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 28       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.989    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00597  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 93       |\n",
      "|    policy_objective       | 0.0195   |\n",
      "|    std                    | 0.648    |\n",
      "|    value_loss             | 287      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -769     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 284      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 35       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.962    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00568  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 94       |\n",
      "|    policy_objective       | 0.0164   |\n",
      "|    std                    | 0.649    |\n",
      "|    value_loss             | 1.45e+03 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1504.14341782704\n",
      "------------------------------\n",
      "round: 19\n",
      "------------------------------\n",
      "client: 0\n",
      "Avg loss: 0.14227512844130008!\n",
      "Avg loss: 0.11422126041202621!\n",
      "Avg loss: 0.1175454410869861!\n",
      "Avg loss: 0.11726499865530438!\n",
      "Avg loss: 0.11338429201690209!\n",
      "Avg loss: 0.11465449042096831!\n",
      "Avg loss: 0.11361729250778202!\n",
      "Avg loss: 0.11588578169956842!\n",
      "Avg loss: 0.11316884753943061!\n",
      "Avg loss: 0.11304683104087114!\n",
      "Avg loss: 0.11391856373404152!\n",
      "Avg loss: 0.11255268355317942!\n",
      "Avg loss: 0.11295233865116946!\n",
      "Avg loss: 0.11360907513520639!\n",
      "Avg loss: 0.11349246055475154!\n",
      "Avg loss: 0.11303601350893056!\n",
      "Avg loss: 0.11321404884446869!\n",
      "Avg loss: 0.11269104178350517!\n",
      "Avg loss: 0.11279678866752031!\n",
      "Avg loss: 0.11329466233112119!\n",
      "Avg loss: 0.11310002207037238!\n",
      "Avg loss: 0.1128775785921971!\n",
      "------------------------------\n",
      "client: 1\n",
      "Avg loss: 0.1346404285157526!\n",
      "Avg loss: 0.13512405919027515!\n",
      "Avg loss: 0.13915064641158095!\n",
      "Avg loss: 0.13121744565238866!\n",
      "Avg loss: 0.131995908995353!\n",
      "Avg loss: 0.13128508343250966!\n",
      "Avg loss: 0.13290490313413708!\n",
      "Avg loss: 0.13327759842900075!\n",
      "Avg loss: 0.13267629580353968!\n",
      "Avg loss: 0.1319753637149673!\n",
      "Avg loss: 0.13322892179821794!\n",
      "Avg loss: 0.13173590612533492!\n",
      "Avg loss: 0.13226756543007773!\n",
      "Avg loss: 0.13294180442197104!\n",
      "------------------------------\n",
      "client: 2\n",
      "Avg loss: 0.01968156572508936!\n",
      "Avg loss: 0.0070700722576293624!\n",
      "Avg loss: 0.013783104695758084!\n",
      "Avg loss: 0.004781938440889159!\n",
      "Avg loss: 0.0054817514357273465!\n",
      "Avg loss: 0.005917914184028632!\n",
      "Avg loss: 0.005121957043835816!\n",
      "Avg loss: 0.004567797109339153!\n",
      "Avg loss: 0.004449126470353804!\n",
      "Avg loss: 0.005219997674478994!\n",
      "Avg loss: 0.004465829260201038!\n",
      "Avg loss: 0.00436189575305131!\n",
      "Avg loss: 0.004378796299891595!\n",
      "Avg loss: 0.004292112104400682!\n",
      "Avg loss: 0.003999083763944024!\n",
      "Avg loss: 0.00411899771085397!\n",
      "Avg loss: 0.004217495108241565!\n",
      "Avg loss: 0.004126428181965214!\n",
      "Avg loss: 0.004154179018951254!\n",
      "Avg loss: 0.0041569341848116895!\n",
      "Avg loss: 0.004089864114927574!\n",
      "Avg loss: 0.004064410703316147!\n",
      "Avg loss: 0.004043329386164866!\n",
      "Avg loss: 0.004039350318095482!\n",
      "Avg loss: 0.0040307966563341326!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -929     |\n",
      "| time/              |          |\n",
      "|    fps             | 322      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -911     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 309      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 13       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.952    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00737  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 96       |\n",
      "|    policy_objective       | 0.0152   |\n",
      "|    std                    | 0.634    |\n",
      "|    value_loss             | 1.84e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -887     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 288      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 21       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.991    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00684  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 97       |\n",
      "|    policy_objective       | 0.0148   |\n",
      "|    std                    | 0.651    |\n",
      "|    value_loss             | 374      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -903     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 286      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 28       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.975    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00728  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 98       |\n",
      "|    policy_objective       | 0.0125   |\n",
      "|    std                    | 0.643    |\n",
      "|    value_loss             | 1.21e+03 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -901     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 287      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 35       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.98     |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00798  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 99       |\n",
      "|    policy_objective       | 0.0232   |\n",
      "|    std                    | 0.642    |\n",
      "|    value_loss             | 1.03e+03 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward in real env:-1493.557737980783\n"
     ]
    }
   ],
   "source": [
    "# initialize the client and server\n",
    "timesteps_real_per_round = 500\n",
    "timesteps_fc_per_round = timesteps_real_per_round * 20\n",
    "epoch_per_round = 100\n",
    "CLIENTS_NUM = 3\n",
    "rounds_num = 20\n",
    "batch_size_env_model = 128\n",
    "\n",
    "env_models = []\n",
    "MB_env = TimeLimit(MB_PendulumEnv(env_models,device), max_episode_steps = 200)\n",
    "\n",
    "# Global_RL = PPO(\"MlpPolicy\", MB_env, verbose=1)\n",
    "Global_RL = TRPO(\"MlpPolicy\", MB_env, verbose=1)\n",
    "\n",
    "env_theta = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "real_envs = []\n",
    "Clients = []\n",
    "for i in range(CLIENTS_NUM):\n",
    "    real_envs.append( TimeLimit(PendulumEnv(), max_episode_steps=200) )\n",
    "    policy_net = Global_RL\n",
    "    agent = SB3Agent(policy_net)\n",
    "    client = FRLClient(real_envs[i], agent, lr = 3e-4, hidden_size = 256, device = device)\n",
    "    Clients.append(client)\n",
    "    env_model = copy.deepcopy(client.model)\n",
    "    env_models.append(env_model)\n",
    "    \n",
    "\n",
    "Global_RL.env.models = env_models\n",
    "\n",
    "\n",
    "rewards_log = []\n",
    "\n",
    "env_models = []\n",
    "for round_idx in range(rounds_num):\n",
    "    print('------------------------------')\n",
    "    print(\"round: \" + str(round_idx))\n",
    "    for client_idx in range(len(Clients)):\n",
    "        print('------------------------------')\n",
    "        print(\"client: \" + str(client_idx))\n",
    "        # update policy\n",
    "        Clients[client_idx].agent.policy_net = Global_RL\n",
    "        # train prediction models\n",
    "        Clients[client_idx].learn(timesteps_real_per_round, epoch_per_round, batch_size_env_model)\n",
    "        #\n",
    "        env_model = Clients[client_idx].get_prediction_model()\n",
    "        env_models.append(env_model)\n",
    "    \n",
    "#     Server.update_env_models(env_models)\n",
    "    Global_RL.env.models = env_models\n",
    "    #\n",
    "    Global_RL.learn(total_timesteps=timesteps_fc_per_round)\n",
    "    \n",
    "#     Server.learn(timesteps_real_per_round = 10000)\n",
    "    # test performance\n",
    "    mean_reward, std_reward = evaluate_policy(Global_RL, real_envs[1], n_eval_episodes=10)\n",
    "    rewards_log.append(mean_reward)\n",
    "    print(\"mean_reward in real env:\" + str(mean_reward))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f748ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs,_ = Clients[0].env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "200357a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.80263555,  0.5964697 , -0.84910995], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02079844",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clients[0].agent.act(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22093d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.30735433], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clients[0].agent.policy_net.predict(obs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bbe53a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1699efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: -93.15121025741101 +/- 109.2765889131137\n"
     ]
    }
   ],
   "source": [
    "# mean_reward, std_reward = evaluate_policy(Global_RL, real_envs[1], n_eval_episodes=10)\n",
    "mean_reward, std_reward = evaluate_policy(Global_RL, MB_env, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9285a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib import TRPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1ac5563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "TRPO_model = TRPO(\"MlpPolicy\", env=real_envs[0], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23e35f65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -829     |\n",
      "| time/              |          |\n",
      "|    fps             | 520      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -847     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 478      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 8        |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.715    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00696  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 50       |\n",
      "|    policy_objective       | 0.0147   |\n",
      "|    std                    | 0.809    |\n",
      "|    value_loss             | 433      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -893     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 481      |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 12       |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.749    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00777  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 51       |\n",
      "|    policy_objective       | 0.0188   |\n",
      "|    std                    | 0.789    |\n",
      "|    value_loss             | 629      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -890     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 470      |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 17       |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.759    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00865  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 52       |\n",
      "|    policy_objective       | 0.0126   |\n",
      "|    std                    | 0.762    |\n",
      "|    value_loss             | 857      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -875     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 470      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 21       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.8      |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00702  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 53       |\n",
      "|    policy_objective       | 0.0123   |\n",
      "|    std                    | 0.769    |\n",
      "|    value_loss             | 679      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -860     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 465      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 26       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.825    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00762  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 54       |\n",
      "|    policy_objective       | 0.0143   |\n",
      "|    std                    | 0.757    |\n",
      "|    value_loss             | 660      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -832     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 467      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 30       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.851    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00773  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 55       |\n",
      "|    policy_objective       | 0.0167   |\n",
      "|    std                    | 0.743    |\n",
      "|    value_loss             | 428      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -808     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 470      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 34       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.881    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00726  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 56       |\n",
      "|    policy_objective       | 0.0213   |\n",
      "|    std                    | 0.72     |\n",
      "|    value_loss             | 291      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -794     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 472      |\n",
      "|    iterations             | 9        |\n",
      "|    time_elapsed           | 39       |\n",
      "|    total_timesteps        | 18432    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.876    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00698  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 57       |\n",
      "|    policy_objective       | 0.0147   |\n",
      "|    std                    | 0.728    |\n",
      "|    value_loss             | 506      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -758     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 471      |\n",
      "|    iterations             | 10       |\n",
      "|    time_elapsed           | 43       |\n",
      "|    total_timesteps        | 20480    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.914    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00761  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 58       |\n",
      "|    policy_objective       | 0.0205   |\n",
      "|    std                    | 0.72     |\n",
      "|    value_loss             | 376      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -734     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 472      |\n",
      "|    iterations             | 11       |\n",
      "|    time_elapsed           | 47       |\n",
      "|    total_timesteps        | 22528    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.883    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00787  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 59       |\n",
      "|    policy_objective       | 0.0231   |\n",
      "|    std                    | 0.698    |\n",
      "|    value_loss             | 250      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -690     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 473      |\n",
      "|    iterations             | 12       |\n",
      "|    time_elapsed           | 51       |\n",
      "|    total_timesteps        | 24576    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.927    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00787  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 60       |\n",
      "|    policy_objective       | 0.0255   |\n",
      "|    std                    | 0.692    |\n",
      "|    value_loss             | 283      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -644     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 473      |\n",
      "|    iterations             | 13       |\n",
      "|    time_elapsed           | 56       |\n",
      "|    total_timesteps        | 26624    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.928    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00833  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 61       |\n",
      "|    policy_objective       | 0.0195   |\n",
      "|    std                    | 0.681    |\n",
      "|    value_loss             | 334      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -604     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 473      |\n",
      "|    iterations             | 14       |\n",
      "|    time_elapsed           | 60       |\n",
      "|    total_timesteps        | 28672    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.884    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00801  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 62       |\n",
      "|    policy_objective       | 0.0296   |\n",
      "|    std                    | 0.677    |\n",
      "|    value_loss             | 282      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -550     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 474      |\n",
      "|    iterations             | 15       |\n",
      "|    time_elapsed           | 64       |\n",
      "|    total_timesteps        | 30720    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.927    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00836  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 63       |\n",
      "|    policy_objective       | 0.0263   |\n",
      "|    std                    | 0.654    |\n",
      "|    value_loss             | 260      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -499     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 474      |\n",
      "|    iterations             | 16       |\n",
      "|    time_elapsed           | 69       |\n",
      "|    total_timesteps        | 32768    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.926    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00848  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 64       |\n",
      "|    policy_objective       | 0.0303   |\n",
      "|    std                    | 0.638    |\n",
      "|    value_loss             | 274      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 200      |\n",
      "|    ep_rew_mean            | -445     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 473      |\n",
      "|    iterations             | 17       |\n",
      "|    time_elapsed           | 73       |\n",
      "|    total_timesteps        | 34816    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.954    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00868  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 65       |\n",
      "|    policy_objective       | 0.0229   |\n",
      "|    std                    | 0.639    |\n",
      "|    value_loss             | 202      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mTRPO_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\sb3_contrib\\trpo\\trpo.py:412\u001b[0m, in \u001b[0;36mTRPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTRPO,\n\u001b[0;32m    405\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    410\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    411\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTRPO:\n\u001b[1;32m--> 412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:259\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 259\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:169\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Convert to pytorch tensor or to TensorDict\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     obs_tensor \u001b[38;5;241m=\u001b[39m obs_as_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 169\u001b[0m     actions, values, log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\policies.py:619\u001b[0m, in \u001b[0;36mActorCriticPolicy.forward\u001b[1;34m(self, obs, deterministic)\u001b[0m\n\u001b[0;32m    617\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_features(obs)\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor:\n\u001b[1;32m--> 619\u001b[0m     latent_pi, latent_vf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m     pi_features, vf_features \u001b[38;5;241m=\u001b[39m features\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\torch_layers.py:222\u001b[0m, in \u001b[0;36mMlpExtractor.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[th\u001b[38;5;241m.\u001b[39mTensor, th\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m    :return: latent_policy, latent_value of the specified network.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m        If all layers are shared, then ``latent_policy == latent_value``\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_actor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_critic(features)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\stable_baselines3\\common\\torch_layers.py:225\u001b[0m, in \u001b[0;36mMlpExtractor.forward_actor\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_actor\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\py3.8\\lib\\site-packages\\torch\\nn\\modules\\activation.py:356\u001b[0m, in \u001b[0;36mTanh.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRPO_model.learn(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db1039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
